{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "2095    58.795530\n",
       "2096    58.790394\n",
       "2097    58.785259\n",
       "2098    58.780124\n",
       "2099    58.774988\n",
       "Name: C8, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c8_interpolated_2000_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "1995     0.129908\n",
       "1996     0.451612\n",
       "1997     0.062843\n",
       "1998     0.136335\n",
       "1999     0.650943\n",
       "Name: C8, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2000)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.987115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.774230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.561345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.348459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.200000  0.000298\n",
       "1     87.987115  0.000298\n",
       "2     87.774230  0.000297\n",
       "3     87.561345  0.000297\n",
       "4     87.348459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 85.7336  # Value for C0\n",
    "K0 = -0.0020  # Value for K0\n",
    "K1 = 0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0125    # Value for b\n",
    "c = 2.3008    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.200000    87.987115    87.774230    87.561345    87.348459   \n",
      "351    87.987115    87.774230    87.561345    87.348459    87.135574   \n",
      "352    87.774230    87.561345    87.348459    87.135574    86.922689   \n",
      "353    87.561345    87.348459    87.135574    86.922689    86.709804   \n",
      "354    87.348459    87.135574    86.922689    86.709804    86.496919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.135574    86.922689    86.709804    86.496919    86.294538  ...   \n",
      "351    86.922689    86.709804    86.496919    86.294538    86.221709  ...   \n",
      "352    86.709804    86.496919    86.294538    86.221709    86.148880  ...   \n",
      "353    86.496919    86.294538    86.221709    86.148880    86.076050  ...   \n",
      "354    86.294538    86.221709    86.148880    86.076050    86.003221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   76.094351    0.000263   76.058870    0.000263   76.023389    0.000263   \n",
      "351   76.058870    0.000263   76.023389    0.000263   75.987909    0.000262   \n",
      "352   76.023389    0.000263   75.987909    0.000262   75.952428    0.000262   \n",
      "353   75.987909    0.000262   75.952428    0.000262   75.916947    0.000262   \n",
      "354   75.952428    0.000262   75.916947    0.000262   75.881466    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   75.987909    0.000262   75.952428    0.000262  \n",
      "351   75.952428    0.000262   75.916947    0.000262  \n",
      "352   75.916947    0.000262   75.881466    0.000262  \n",
      "353   75.881466    0.000262   75.845985    0.000262  \n",
      "354   75.845985    0.000262   75.810504    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1550, 1, 251) (1550, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 26ms/step - loss: 4746.7720 - val_loss: 3293.0693\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4642.2881 - val_loss: 3240.6013\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4574.0649 - val_loss: 3187.0618\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4491.9307 - val_loss: 3140.5134\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4424.9409 - val_loss: 3095.1824\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4359.1992 - val_loss: 3050.7600\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4294.6152 - val_loss: 3007.1079\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4231.0142 - val_loss: 2964.1394\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4168.2949 - val_loss: 2921.8032\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 4106.3960 - val_loss: 2880.0667\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4045.2771 - val_loss: 2838.9067\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3984.9089 - val_loss: 2798.3079\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3925.2698 - val_loss: 2758.2554\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3866.3435 - val_loss: 2718.7390\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3808.1140 - val_loss: 2679.7495\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3750.5723 - val_loss: 2641.2778\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3693.7043 - val_loss: 2603.3167\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3637.5017 - val_loss: 2565.8599\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3581.9565 - val_loss: 2528.9009\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3527.0596 - val_loss: 2492.4338\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3472.8040 - val_loss: 2456.4534\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3419.1826 - val_loss: 2420.9539\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3366.1887 - val_loss: 2385.9299\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3313.8154 - val_loss: 2351.3777\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3262.0566 - val_loss: 2317.2913\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3210.9067 - val_loss: 2283.6665\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3160.3594 - val_loss: 2250.4990\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3110.4087 - val_loss: 2217.7839\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3061.0496 - val_loss: 2185.5173\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3012.2764 - val_loss: 2153.6943\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2964.0842 - val_loss: 2122.3113\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2916.4673 - val_loss: 2091.3635\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2869.4204 - val_loss: 2060.8467\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2822.9392 - val_loss: 2030.7546\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2777.0178 - val_loss: 2001.0770\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2731.5325 - val_loss: 1966.8741\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2676.7915 - val_loss: 1932.9498\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2625.9854 - val_loss: 1900.3180\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2577.0110 - val_loss: 1869.0002\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2529.6055 - val_loss: 1838.6730\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2483.4097 - val_loss: 1809.1466\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2438.2170 - val_loss: 1780.3127\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2393.9067 - val_loss: 1752.1030\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2350.4011 - val_loss: 1724.4713\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2307.6438 - val_loss: 1697.3827\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2265.5942 - val_loss: 1670.8115\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2224.2205 - val_loss: 1644.7369\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2183.4971 - val_loss: 1619.1423\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2143.4031 - val_loss: 1594.0132\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2103.9202 - val_loss: 1569.3370\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2065.0337 - val_loss: 1545.1027\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2026.7289 - val_loss: 1521.3013\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1988.9945 - val_loss: 1497.9233\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1951.8192 - val_loss: 1474.9609\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1915.1924 - val_loss: 1452.4072\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1879.1062 - val_loss: 1430.2545\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1843.5496 - val_loss: 1408.4972\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1808.5171 - val_loss: 1387.1289\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1773.9998 - val_loss: 1366.1432\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1739.9901 - val_loss: 1345.5358\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1706.4823 - val_loss: 1325.3008\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1673.4695 - val_loss: 1305.4332\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1640.9442 - val_loss: 1285.9280\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1608.9020 - val_loss: 1266.7810\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1577.3359 - val_loss: 1247.9871\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1546.2411 - val_loss: 1229.5420\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1515.6113 - val_loss: 1211.4413\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1485.4414 - val_loss: 1193.6809\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1455.7262 - val_loss: 1176.2568\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1426.4604 - val_loss: 1159.1644\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1397.6390 - val_loss: 1142.4001\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1369.2577 - val_loss: 1125.9603\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1341.3108 - val_loss: 1109.8406\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1313.7942 - val_loss: 1094.0376\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1286.7030 - val_loss: 1078.5470\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1260.0323 - val_loss: 1063.3660\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1233.7783 - val_loss: 1048.4901\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1207.9363 - val_loss: 1033.9161\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1182.5016 - val_loss: 1019.6406\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1157.4703 - val_loss: 1005.6599\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1132.8376 - val_loss: 991.9705\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1108.6000 - val_loss: 978.5695\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1084.7532 - val_loss: 965.4528\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1061.2925 - val_loss: 952.6173\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1038.2144 - val_loss: 940.0597\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1015.5142 - val_loss: 927.7766\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 993.1890 - val_loss: 915.7649\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 971.2341 - val_loss: 904.0211\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 949.6451 - val_loss: 892.5421\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 928.4185 - val_loss: 881.3248\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 907.5509 - val_loss: 870.3656\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 887.0377 - val_loss: 859.6616\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 866.8755 - val_loss: 849.2099\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 847.0607 - val_loss: 839.0068\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 827.5892 - val_loss: 829.0497\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 808.4574 - val_loss: 819.3355\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 789.6616 - val_loss: 809.8607\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 771.1979 - val_loss: 800.6226\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 753.0633 - val_loss: 791.6179\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 735.2534 - val_loss: 782.8439\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 717.7647 - val_loss: 774.2973\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 700.5941 - val_loss: 765.9752\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 683.7375 - val_loss: 757.8745\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 667.1917 - val_loss: 749.9924\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 650.9528 - val_loss: 742.3257\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 635.0175 - val_loss: 734.8719\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 619.3821 - val_loss: 727.6275\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 604.0430 - val_loss: 720.5898\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 588.9971 - val_loss: 713.7559\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 574.2406 - val_loss: 707.1230\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 559.7707 - val_loss: 700.6881\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 545.5832 - val_loss: 694.4484\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 531.6749 - val_loss: 688.4008\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 518.0427 - val_loss: 682.5427\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 504.6828 - val_loss: 676.8710\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 491.5919 - val_loss: 671.3829\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 478.7670 - val_loss: 666.0758\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 466.2044 - val_loss: 660.9467\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 453.9008 - val_loss: 655.9932\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 441.8532 - val_loss: 651.2116\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 430.0580 - val_loss: 646.5997\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 418.5118 - val_loss: 642.1548\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 407.2116 - val_loss: 637.8740\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 396.1540 - val_loss: 633.7543\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 385.3357 - val_loss: 629.7933\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 374.7537 - val_loss: 625.9881\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 364.4046 - val_loss: 622.3361\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 354.2851 - val_loss: 618.8344\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 344.3922 - val_loss: 615.4802\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 334.7226 - val_loss: 612.2711\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 325.2729 - val_loss: 609.2042\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 316.0403 - val_loss: 606.2768\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 307.0215 - val_loss: 603.4863\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 298.2135 - val_loss: 600.8300\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 289.6131 - val_loss: 598.3052\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 281.2169 - val_loss: 595.9095\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 273.0221 - val_loss: 593.6400\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 265.0256 - val_loss: 591.4941\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 257.2239 - val_loss: 589.4694\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 249.6148 - val_loss: 587.5632\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 242.1945 - val_loss: 585.7728\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 234.9602 - val_loss: 584.0958\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 227.9091 - val_loss: 582.5294\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 221.0378 - val_loss: 581.0714\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 214.3436 - val_loss: 579.7189\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 207.8234 - val_loss: 578.4697\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 201.4743 - val_loss: 577.3210\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 195.2932 - val_loss: 576.2707\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 189.2774 - val_loss: 575.3160\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 183.4239 - val_loss: 574.4545\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 177.7299 - val_loss: 573.6838\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 172.1922 - val_loss: 573.0015\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 166.8083 - val_loss: 572.4052\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 161.5751 - val_loss: 571.8924\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 156.4899 - val_loss: 571.4607\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 151.5498 - val_loss: 571.1080\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 146.7522 - val_loss: 570.8317\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 142.0943 - val_loss: 570.6295\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 137.5732 - val_loss: 570.4993\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 133.1862 - val_loss: 570.4385\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 128.9307 - val_loss: 570.4451\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 124.8039 - val_loss: 570.5167\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 120.8029 - val_loss: 570.6512\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 116.9252 - val_loss: 570.8463\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 113.1684 - val_loss: 571.0998\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 109.5299 - val_loss: 571.4096\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 106.0068 - val_loss: 571.7736\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 102.5966 - val_loss: 572.1897\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 99.2969 - val_loss: 572.6557\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 96.1051 - val_loss: 573.1696\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 93.0188 - val_loss: 573.7293\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 90.0353 - val_loss: 574.3331\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 87.1524 - val_loss: 574.9786\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 84.3677 - val_loss: 575.6639\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 81.6787 - val_loss: 576.3874\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 79.0828 - val_loss: 577.1469\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 76.5781 - val_loss: 577.9406\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 74.1621 - val_loss: 578.7667\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 71.8325 - val_loss: 579.6234\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 69.5870 - val_loss: 580.5088\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 67.4235 - val_loss: 581.4212\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 65.3397 - val_loss: 582.3589\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 63.3334 - val_loss: 583.3202\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 61.4027 - val_loss: 584.3035\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 59.5452 - val_loss: 585.3070\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 57.7590 - val_loss: 586.3292\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 56.0420 - val_loss: 587.3685\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 54.3922 - val_loss: 588.4236\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 52.8077 - val_loss: 589.4927\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 51.2864 - val_loss: 590.5745\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 49.8265 - val_loss: 591.6675\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 48.4260 - val_loss: 592.7704\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 47.0832 - val_loss: 593.8818\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 45.7961 - val_loss: 595.0001\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 44.5632 - val_loss: 596.1246\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 43.3824 - val_loss: 597.2535\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 42.2523 - val_loss: 598.3859\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 41.1709 - val_loss: 599.5206\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 40.1368 - val_loss: 600.6562\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 39.1483 - val_loss: 601.7919\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 38.2038 - val_loss: 602.9264\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 37.3017 - val_loss: 604.0589\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 36.4406 - val_loss: 605.1882\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 35.6190 - val_loss: 606.3133\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 34.8355 - val_loss: 607.4336\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 34.0886 - val_loss: 608.5480\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 33.3768 - val_loss: 609.6556\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 32.6990 - val_loss: 610.7556\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 32.0538 - val_loss: 611.8473\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 31.4400 - val_loss: 612.9298\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 30.8562 - val_loss: 614.0026\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.3014 - val_loss: 615.0649\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 29.7742 - val_loss: 616.1159\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 29.2737 - val_loss: 617.1553\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 28.7986 - val_loss: 618.1826\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 28.3479 - val_loss: 619.1970\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 27.9205 - val_loss: 620.1981\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 27.5155 - val_loss: 621.1854\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 27.1318 - val_loss: 622.1586\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 26.7685 - val_loss: 623.1171\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 26.4247 - val_loss: 624.0606\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 26.0996 - val_loss: 624.9887\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 25.7922 - val_loss: 625.9012\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 25.5017 - val_loss: 626.7978\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 25.2274 - val_loss: 627.6781\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.9685 - val_loss: 628.5418\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 24.7242 - val_loss: 629.3892\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 24.4938 - val_loss: 630.2197\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 24.2766 - val_loss: 631.0333\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 24.0720 - val_loss: 631.8300\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.8793 - val_loss: 632.6093\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.6980 - val_loss: 633.3714\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.5274 - val_loss: 634.1166\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.3670 - val_loss: 634.8442\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.2161 - val_loss: 635.5549\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.0745 - val_loss: 636.2482\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 22.9415 - val_loss: 636.9243\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 22.8166 - val_loss: 637.5832\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 22.6995 - val_loss: 638.2252\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 22.5897 - val_loss: 638.8503\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 22.4866 - val_loss: 639.4586\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.3901 - val_loss: 640.0501\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.2998 - val_loss: 640.6250\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.2152 - val_loss: 641.1833\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 22.1360 - val_loss: 641.7256\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.0620 - val_loss: 642.2518\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.9927 - val_loss: 642.7621\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.9280 - val_loss: 643.2569\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.8675 - val_loss: 643.7362\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.8110 - val_loss: 644.2005\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 21.7582 - val_loss: 644.6497\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 21.7090 - val_loss: 645.0841\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 21.6631 - val_loss: 645.5042\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.6202 - val_loss: 645.9101\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 21.5802 - val_loss: 646.3022\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.5430 - val_loss: 646.6807\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.5082 - val_loss: 647.0458\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.4759 - val_loss: 647.3977\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.4457 - val_loss: 647.7371\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.4176 - val_loss: 648.0638\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.3915 - val_loss: 648.3786\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.3671 - val_loss: 648.6813\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.3445 - val_loss: 648.9724\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.3234 - val_loss: 649.2522\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.3038 - val_loss: 649.5211\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.2856 - val_loss: 649.7792\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.2686 - val_loss: 650.0269\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.2528 - val_loss: 650.2644\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.2382 - val_loss: 650.4921\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.2245 - val_loss: 650.7102\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.2119 - val_loss: 650.9194\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 21.2001 - val_loss: 651.1191\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1892 - val_loss: 651.3105\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1790 - val_loss: 651.4935\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1696 - val_loss: 651.6679\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1608 - val_loss: 651.8348\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1528 - val_loss: 651.9941\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1452 - val_loss: 652.1461\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1382 - val_loss: 652.2910\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1317 - val_loss: 652.4294\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1257 - val_loss: 652.5611\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1201 - val_loss: 652.6863\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1149 - val_loss: 652.8054\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1102 - val_loss: 652.9185\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1057 - val_loss: 653.0262\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.1017 - val_loss: 653.1286\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0979 - val_loss: 653.2255\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0944 - val_loss: 653.3177\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.0911 - val_loss: 653.4047\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0882 - val_loss: 653.4877\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0855 - val_loss: 653.5661\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0829 - val_loss: 653.6403\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0806 - val_loss: 653.7103\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0785 - val_loss: 653.7767\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.0765 - val_loss: 653.8393\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0748 - val_loss: 653.8986\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0731 - val_loss: 653.9542\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0717 - val_loss: 654.0071\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0703 - val_loss: 654.0566\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0691 - val_loss: 654.1034\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0680 - val_loss: 654.1473\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0670 - val_loss: 654.1888\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.0661 - val_loss: 654.2279\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0653 - val_loss: 654.2644\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0646 - val_loss: 654.2986\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0640 - val_loss: 654.3309\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0635 - val_loss: 654.3611\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0630 - val_loss: 654.3895\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.0626 - val_loss: 654.4160\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0623 - val_loss: 654.4406\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0620 - val_loss: 654.4637\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0619 - val_loss: 654.4855\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0617 - val_loss: 654.5057\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0616 - val_loss: 654.5245\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0615 - val_loss: 654.5421\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0615 - val_loss: 654.5583\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0615 - val_loss: 654.5734\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0616 - val_loss: 654.5876\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 21.0617 - val_loss: 654.6008\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0618 - val_loss: 654.6129\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0621 - val_loss: 654.6245\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0622 - val_loss: 654.6347\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0624 - val_loss: 654.6442\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0627 - val_loss: 654.6530\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0629 - val_loss: 654.6610\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0632 - val_loss: 654.6685\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0636 - val_loss: 654.6755\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.0639 - val_loss: 654.6818\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0642 - val_loss: 654.6876\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.0646 - val_loss: 654.6929\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0650 - val_loss: 654.6976\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0654 - val_loss: 654.7020\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0658 - val_loss: 654.7061\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0662 - val_loss: 654.7099\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0666 - val_loss: 654.7133\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0671 - val_loss: 654.7162\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0675 - val_loss: 654.7192\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0679 - val_loss: 654.7212\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0683 - val_loss: 654.7232\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 21.0688 - val_loss: 654.7249\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0693 - val_loss: 654.7264\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0697 - val_loss: 654.7276\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0702 - val_loss: 654.7286\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0707 - val_loss: 654.7296\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0712 - val_loss: 654.7305\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0717 - val_loss: 654.7310\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0722 - val_loss: 654.7316\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0726 - val_loss: 654.7319\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0731 - val_loss: 654.7324\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0736 - val_loss: 654.7325\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0741 - val_loss: 654.7325\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0746 - val_loss: 654.7324\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0750 - val_loss: 654.7320\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0755 - val_loss: 654.7318\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0760 - val_loss: 654.7311\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0765 - val_loss: 654.7308\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0770 - val_loss: 654.7307\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0775 - val_loss: 654.7302\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0779 - val_loss: 654.7296\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.0784 - val_loss: 654.7289\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0789 - val_loss: 654.7282\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0794 - val_loss: 654.7277\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0798 - val_loss: 654.7270\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0803 - val_loss: 654.7264\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0808 - val_loss: 654.7258\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0812 - val_loss: 654.7248\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.0817 - val_loss: 654.7241\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0821 - val_loss: 654.7233\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.0826 - val_loss: 654.7226\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0830 - val_loss: 654.7220\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0834 - val_loss: 654.7211\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.0839 - val_loss: 654.7202\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0843 - val_loss: 654.7194\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0847 - val_loss: 654.7183\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0851 - val_loss: 654.7175\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0856 - val_loss: 654.7168\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.0859 - val_loss: 654.7158\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.0864 - val_loss: 654.7148\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0868 - val_loss: 654.7137\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 21.0872 - val_loss: 654.7130\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.0876 - val_loss: 654.7119\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0880 - val_loss: 654.7111\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0884 - val_loss: 654.7106\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0888 - val_loss: 654.7097\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0891 - val_loss: 654.7089\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0895 - val_loss: 654.7079\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0899 - val_loss: 654.7072\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0903 - val_loss: 654.7061\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0906 - val_loss: 654.7053\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0910 - val_loss: 654.7045\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0913 - val_loss: 654.7034\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0917 - val_loss: 654.7028\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0921 - val_loss: 654.7021\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0924 - val_loss: 654.7014\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.0927 - val_loss: 654.7005\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0931 - val_loss: 654.6995\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.0934 - val_loss: 654.6988\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0937 - val_loss: 654.6983\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 21.0940 - val_loss: 654.6974\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.0943 - val_loss: 654.6964\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0947 - val_loss: 654.6957\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0950 - val_loss: 654.6952\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0953 - val_loss: 654.6945\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0956 - val_loss: 654.6942\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0958 - val_loss: 654.6932\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0961 - val_loss: 654.6926\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0964 - val_loss: 654.6918\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0967 - val_loss: 654.6911\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0970 - val_loss: 654.6902\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0973 - val_loss: 654.6896\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0975 - val_loss: 654.6888\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0978 - val_loss: 654.6884\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0980 - val_loss: 654.6877\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0983 - val_loss: 654.6872\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0986 - val_loss: 654.6865\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0988 - val_loss: 654.6859\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0991 - val_loss: 654.6855\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 21.0993 - val_loss: 654.6848\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.0995 - val_loss: 654.6841\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.0998 - val_loss: 654.6833\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1001 - val_loss: 654.6829\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1003 - val_loss: 654.6826\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1005 - val_loss: 654.6821\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.1007 - val_loss: 654.6816\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1009 - val_loss: 654.6813\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1011 - val_loss: 654.6808\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1013 - val_loss: 654.6802\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1016 - val_loss: 654.6797\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1018 - val_loss: 654.6793\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1020 - val_loss: 654.6788\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1022 - val_loss: 654.6782\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1024 - val_loss: 654.6779\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1025 - val_loss: 654.6772\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1027 - val_loss: 654.6769\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1029 - val_loss: 654.6763\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 21.1031 - val_loss: 654.6758\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1033 - val_loss: 654.6754\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1035 - val_loss: 654.6750\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.1036 - val_loss: 654.6746\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1038 - val_loss: 654.6743\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1040 - val_loss: 654.6738\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1041 - val_loss: 654.6732\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1043 - val_loss: 654.6729\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1045 - val_loss: 654.6726\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1046 - val_loss: 654.6721\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1048 - val_loss: 654.6718\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.1049 - val_loss: 654.6716\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1051 - val_loss: 654.6713\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1052 - val_loss: 654.6710\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1053 - val_loss: 654.6705\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.1055 - val_loss: 654.6703\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1056 - val_loss: 654.6697\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.1058 - val_loss: 654.6693\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.1059 - val_loss: 654.6687\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 21.1061 - val_loss: 654.6685\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1062 - val_loss: 654.6683\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1063 - val_loss: 654.6678\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1064 - val_loss: 654.6677\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1065 - val_loss: 654.6672\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1067 - val_loss: 654.6669\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1069 - val_loss: 654.6668\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.1069 - val_loss: 654.6664\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1070 - val_loss: 654.6661\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1071 - val_loss: 654.6656\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1073 - val_loss: 654.6654\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1074 - val_loss: 654.6652\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1075 - val_loss: 654.6650\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1076 - val_loss: 654.6648\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1076 - val_loss: 654.6643\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1078 - val_loss: 654.6642\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1079 - val_loss: 654.6639\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1080 - val_loss: 654.6639\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1081 - val_loss: 654.6635\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 21.1082 - val_loss: 654.6633\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.1083 - val_loss: 654.6632\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1083 - val_loss: 654.6629\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1084 - val_loss: 654.6628\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1085 - val_loss: 654.6626\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1086 - val_loss: 654.6622\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.1087 - val_loss: 654.6621\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1088 - val_loss: 654.6620\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1089 - val_loss: 654.6617\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1089 - val_loss: 654.6614\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1090 - val_loss: 654.6611\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1091 - val_loss: 654.6608\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1092 - val_loss: 654.6605\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.1092 - val_loss: 654.6602\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.1093 - val_loss: 654.6601\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1094 - val_loss: 654.6598\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1095 - val_loss: 654.6598\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1095 - val_loss: 654.6595\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1096 - val_loss: 654.6594\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 21.1097 - val_loss: 654.6594\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.1097 - val_loss: 654.6593\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1097 - val_loss: 654.6588\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1099 - val_loss: 654.6586\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1099 - val_loss: 654.6584\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.1100 - val_loss: 654.6584\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.1100 - val_loss: 654.6583\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.1101 - val_loss: 654.6583\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(85.7336, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0020, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0125, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3008, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 396ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.51712185e+01, 6.50955882e+01, 6.50199580e+01, 6.49443277e+01,\n",
       "        6.48791317e+01, 6.48287115e+01, 6.47782913e+01, 6.06023788e-01,\n",
       "        1.78536296e-01, 1.06690124e-01, 0.00000000e+00, 4.73489523e-01,\n",
       "        0.00000000e+00, 6.58725140e+01, 6.57930672e+01, 6.57174370e+01,\n",
       "        6.56418067e+01, 6.55666176e+01, 6.54905462e+01, 6.54149160e+01,\n",
       "        6.53392857e+01, 6.52636555e+01, 6.51880252e+01, 6.51123950e+01,\n",
       "        6.50367647e+01, 6.49611345e+01, 6.48903361e+01, 6.48399160e+01,\n",
       "        6.47894958e+01, 6.47390756e+01, 6.46886555e+01, 6.46372353e+01,\n",
       "        6.45868151e+01, 6.45367395e+01, 6.44870148e+01, 6.44365546e+01,\n",
       "        6.43861345e+01, 6.43357143e+01, 6.42901961e+01, 6.42565826e+01,\n",
       "        0.00000000e+00, 3.56669366e-01, 0.00000000e+00, 9.73631144e-01,\n",
       "        0.00000000e+00, 3.91087680e-02, 3.62969339e-01, 6.49779412e+01,\n",
       "        6.49023109e+01, 6.48511204e+01, 6.48007003e+01, 6.47502801e+01,\n",
       "        6.46998599e+01, 6.46494398e+01, 6.45990196e+01, 6.45485994e+01,\n",
       "        6.44981793e+01, 6.44477591e+01, 6.43973389e+01, 6.43469188e+01,\n",
       "        6.42976657e+01, 6.42640523e+01, 6.42304388e+01, 6.41968254e+01,\n",
       "        6.41632120e+01, 6.41295985e+01, 6.40959851e+01, 6.40623716e+01,\n",
       "        6.40287582e+01, 6.39951447e+01, 6.39615313e+01, 6.39279178e+01,\n",
       "        6.38829132e+01, 7.11377106e+01, 3.39660910e-01, 0.00000000e+00,\n",
       "        1.93258580e-01, 2.95780420e-01, 0.00000000e+00, 3.58967070e-01,\n",
       "        5.63342705e+01, 4.92862873e-02, 4.32034671e-01, 0.00000000e+00,\n",
       "        6.21114612e-01, 2.62084723e-01, 3.82058233e-01, 4.72869962e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.63913488e-01, 4.57607925e-01, 6.06830597e-01, 0.00000000e+00,\n",
       "        1.97039664e-01, 0.00000000e+00, 0.00000000e+00, 3.94975320e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59.28339169, 59.2782563 , 59.27312092, 59.26798553, 59.26285014,\n",
       "       59.25771475, 59.25257937, 59.24744398, 59.24230859, 59.2371732 ,\n",
       "       59.23203782, 59.22690243, 59.22176704, 59.21663165, 59.21149627,\n",
       "       59.20636088, 59.20122549, 59.1960901 , 59.19095472, 59.18581933,\n",
       "       59.18068394, 59.17554855, 59.17041317, 59.16527778, 59.16014239,\n",
       "       59.155007  , 59.14987162, 59.14473623, 59.13960084, 59.13446545,\n",
       "       59.12933007, 59.12419468, 59.11905929, 59.1139239 , 59.10878852,\n",
       "       59.10365313, 59.09851774, 59.09338235, 59.08824697, 59.08311158,\n",
       "       59.07797619, 59.0728408 , 59.06770542, 59.06257003, 59.05743464,\n",
       "       59.05229925, 59.04716387, 59.04202848, 59.03689309, 59.0317577 ,\n",
       "       59.02662232, 59.02148693, 59.01635154, 59.01121615, 59.00608077,\n",
       "       59.00094538, 58.99580999, 58.9906746 , 58.98553922, 58.98040383,\n",
       "       58.97526844, 58.97013305, 58.96499767, 58.95986228, 58.95472689,\n",
       "       58.9495915 , 58.94445612, 58.93932073, 58.93418534, 58.92904995,\n",
       "       58.92391457, 58.91877918, 58.91364379, 58.9085084 , 58.90337302,\n",
       "       58.89823763, 58.89310224, 58.88796685, 58.88283147, 58.87769608,\n",
       "       58.87256069, 58.8674253 , 58.86228992, 58.85715453, 58.85201914,\n",
       "       58.84688375, 58.84174837, 58.83661298, 58.83147759, 58.8263422 ,\n",
       "       58.82120682, 58.81607143, 58.81093604, 58.80580065, 58.80066527,\n",
       "       58.79552988, 58.79039449, 58.7852591 , 58.78012372, 58.77498833])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.48115063441084\n",
      "25.83465697980507\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
