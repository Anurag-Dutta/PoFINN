{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "2395    56.237897\n",
       "2396    56.228879\n",
       "2397    56.219861\n",
       "2398    56.210842\n",
       "2399    56.201824\n",
       "Name: C8, Length: 2400, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c8_interpolated_2300_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "2295     0.377998\n",
       "2296     0.507665\n",
       "2297     0.506890\n",
       "2298     0.642052\n",
       "2299     0.000000\n",
       "Name: C8, Length: 2300, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2300)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.987115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.774230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.561345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.348459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.200000  0.000298\n",
       "1     87.987115  0.000298\n",
       "2     87.774230  0.000297\n",
       "3     87.561345  0.000297\n",
       "4     87.348459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 85.7336  # Value for C0\n",
    "K0 = -0.0020  # Value for K0\n",
    "K1 = 0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0125    # Value for b\n",
    "c = 2.3008    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.200000    87.987115    87.774230    87.561345    87.348459   \n",
      "351    87.987115    87.774230    87.561345    87.348459    87.135574   \n",
      "352    87.774230    87.561345    87.348459    87.135574    86.922689   \n",
      "353    87.561345    87.348459    87.135574    86.922689    86.709804   \n",
      "354    87.348459    87.135574    86.922689    86.709804    86.496919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.135574    86.922689    86.709804    86.496919    86.294538  ...   \n",
      "351    86.922689    86.709804    86.496919    86.294538    86.221709  ...   \n",
      "352    86.709804    86.496919    86.294538    86.221709    86.148880  ...   \n",
      "353    86.496919    86.294538    86.221709    86.148880    86.076050  ...   \n",
      "354    86.294538    86.221709    86.148880    86.076050    86.003221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   76.094351    0.000263   76.058870    0.000263   76.023389    0.000263   \n",
      "351   76.058870    0.000263   76.023389    0.000263   75.987909    0.000262   \n",
      "352   76.023389    0.000263   75.987909    0.000262   75.952428    0.000262   \n",
      "353   75.987909    0.000262   75.952428    0.000262   75.916947    0.000262   \n",
      "354   75.952428    0.000262   75.916947    0.000262   75.881466    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   75.987909    0.000262   75.952428    0.000262  \n",
      "351   75.952428    0.000262   75.916947    0.000262  \n",
      "352   75.916947    0.000262   75.881466    0.000262  \n",
      "353   75.881466    0.000262   75.845985    0.000262  \n",
      "354   75.845985    0.000262   75.810504    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1850, 1, 251) (1850, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 3s 26ms/step - loss: 4536.9878 - val_loss: 2739.3040\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4311.3823 - val_loss: 2597.0969\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4153.5640 - val_loss: 2521.0618\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4049.0544 - val_loss: 2448.2493\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3952.1226 - val_loss: 2390.1682\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3860.5627 - val_loss: 2334.2219\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3759.0940 - val_loss: 2261.9607\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3650.9038 - val_loss: 2204.4194\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3558.4607 - val_loss: 2149.8540\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3469.7075 - val_loss: 2097.6121\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3383.7937 - val_loss: 2047.3081\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3300.2568 - val_loss: 1998.7299\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 3218.8330 - val_loss: 1951.7421\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 3139.3533 - val_loss: 1906.2513\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 3061.6970 - val_loss: 1862.1874\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 2985.7744 - val_loss: 1819.4927\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2911.5159 - val_loss: 1778.1215\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2838.8611 - val_loss: 1738.0333\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 2767.7615 - val_loss: 1699.1926\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2698.1729 - val_loss: 1661.5673\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2630.0586 - val_loss: 1625.1290\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2563.3835 - val_loss: 1589.8508\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2498.1155 - val_loss: 1555.7095\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2434.2261 - val_loss: 1522.6915\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2371.6880 - val_loss: 1491.9407\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2310.7402 - val_loss: 1459.8192\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2250.5605 - val_loss: 1429.9812\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2191.9265 - val_loss: 1401.1678\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2134.5483 - val_loss: 1373.3590\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2078.4041 - val_loss: 1346.5358\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 2023.4733 - val_loss: 1320.6798\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 1969.7355 - val_loss: 1295.7722\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1917.1713 - val_loss: 1271.7953\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1865.7618 - val_loss: 1248.7319\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1815.4885 - val_loss: 1226.5646\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1766.3323 - val_loss: 1205.2759\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1718.2761 - val_loss: 1184.8500\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1671.3025 - val_loss: 1165.2695\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1625.3939 - val_loss: 1146.5190\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1580.5336 - val_loss: 1128.5817\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1536.7050 - val_loss: 1111.4425\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1493.8912 - val_loss: 1095.0851\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1452.0765 - val_loss: 1079.4946\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1411.2454 - val_loss: 1064.6549\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1371.3812 - val_loss: 1050.5515\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1332.4694 - val_loss: 1037.1692\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1294.4940 - val_loss: 1024.4927\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1257.4396 - val_loss: 1012.5077\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1221.2916 - val_loss: 1001.1995\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1186.0353 - val_loss: 990.5535\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1151.6558 - val_loss: 980.5554\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1118.1384 - val_loss: 971.1909\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1085.4691 - val_loss: 962.4457\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1053.6337 - val_loss: 954.3061\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1022.6176 - val_loss: 946.7578\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 992.4069 - val_loss: 939.7872\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 962.9882 - val_loss: 933.3807\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 934.3474 - val_loss: 927.5246\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 906.4709 - val_loss: 922.2051\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 879.3456 - val_loss: 917.4092\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 852.9576 - val_loss: 913.1235\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 827.2939 - val_loss: 909.3345\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 802.3416 - val_loss: 906.0294\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 778.0874 - val_loss: 903.1951\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 754.5182 - val_loss: 900.8186\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 731.6213 - val_loss: 898.8871\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 709.3843 - val_loss: 897.3879\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 687.7943 - val_loss: 896.3085\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 666.8386 - val_loss: 895.6360\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 646.5051 - val_loss: 895.3585\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 626.7814 - val_loss: 895.4630\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 607.6554 - val_loss: 895.9377\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 589.1151 - val_loss: 896.7704\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 571.1483 - val_loss: 897.9491\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 553.7429 - val_loss: 899.4617\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 536.8875 - val_loss: 901.2964\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 520.5703 - val_loss: 903.4415\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 504.7794 - val_loss: 905.8855\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 489.5037 - val_loss: 908.6166\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 474.7316 - val_loss: 911.6237\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 460.4519 - val_loss: 914.8952\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 446.6535 - val_loss: 918.4201\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 433.3252 - val_loss: 922.1871\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 420.4560 - val_loss: 926.1441\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 406.6714 - val_loss: 928.4106\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 399.4091 - val_loss: 934.0154\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 385.8565 - val_loss: 939.4442\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 372.8186 - val_loss: 945.0145\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.5789 - val_loss: 950.7214\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 349.0289 - val_loss: 956.5676\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 338.0866 - val_loss: 962.5499\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 327.6956 - val_loss: 968.6620\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 317.8132 - val_loss: 974.8961\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 308.4063 - val_loss: 981.2426\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 299.4470 - val_loss: 987.6929\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 290.9113 - val_loss: 994.2370\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 282.7780 - val_loss: 1000.8660\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 275.0282 - val_loss: 1007.5698\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 267.6443 - val_loss: 1014.3397\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 260.6103 - val_loss: 1021.1661\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 253.9111 - val_loss: 1028.0402\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 247.5325 - val_loss: 1034.9530\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 241.4613 - val_loss: 1041.8962\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 235.6846 - val_loss: 1048.8615\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 230.1902 - val_loss: 1055.8402\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 224.9667 - val_loss: 1062.8253\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 220.0028 - val_loss: 1069.8085\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 215.2880 - val_loss: 1076.7825\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 210.8118 - val_loss: 1083.7410\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 206.5642 - val_loss: 1090.6759\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 202.5359 - val_loss: 1097.5813\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 198.7175 - val_loss: 1104.4508\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 195.1000 - val_loss: 1111.2782\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 191.6749 - val_loss: 1118.0577\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 188.4339 - val_loss: 1124.7844\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 185.3687 - val_loss: 1131.4532\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 182.4717 - val_loss: 1138.0623\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 179.7354 - val_loss: 1144.4950\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 177.1524 - val_loss: 1150.9562\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 174.7157 - val_loss: 1157.3381\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 172.4183 - val_loss: 1163.6381\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 170.2541 - val_loss: 1169.8519\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 168.2164 - val_loss: 1175.9766\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 166.2991 - val_loss: 1182.0074\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 164.4965 - val_loss: 1187.9426\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 162.8029 - val_loss: 1193.7781\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 161.2126 - val_loss: 1199.5118\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 159.7206 - val_loss: 1205.1417\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 158.3216 - val_loss: 1210.6650\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 157.0109 - val_loss: 1216.0806\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 155.7837 - val_loss: 1221.3850\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 154.6357 - val_loss: 1226.5791\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 153.5623 - val_loss: 1231.6593\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 152.5596 - val_loss: 1236.6260\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 151.6236 - val_loss: 1241.4774\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.7504 - val_loss: 1246.2144\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 149.9365 - val_loss: 1250.8341\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 149.1784 - val_loss: 1255.3385\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 148.4728 - val_loss: 1259.7258\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 147.8165 - val_loss: 1263.9974\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 147.2066 - val_loss: 1268.1526\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 146.6403 - val_loss: 1272.1923\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 146.1147 - val_loss: 1276.1163\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 145.6274 - val_loss: 1279.9260\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 145.1758 - val_loss: 1283.6221\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 144.7578 - val_loss: 1287.2052\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 144.3709 - val_loss: 1290.6766\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 144.0133 - val_loss: 1294.0375\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 143.6829 - val_loss: 1297.2898\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 143.3779 - val_loss: 1300.4341\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 143.0965 - val_loss: 1303.4727\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 142.8370 - val_loss: 1306.4061\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 142.5981 - val_loss: 1309.2369\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 142.3781 - val_loss: 1311.9664\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 142.1757 - val_loss: 1314.5975\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 141.9896 - val_loss: 1317.1311\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 141.8186 - val_loss: 1319.5690\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 141.6617 - val_loss: 1321.9136\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 141.5177 - val_loss: 1324.1677\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 141.3856 - val_loss: 1326.3324\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 141.2646 - val_loss: 1328.4099\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 141.1538 - val_loss: 1330.4033\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 141.0523 - val_loss: 1332.3132\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.9595 - val_loss: 1334.1439\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.8746 - val_loss: 1335.8960\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.7971 - val_loss: 1337.5725\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.7263 - val_loss: 1339.1753\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.6615 - val_loss: 1340.7076\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.6026 - val_loss: 1342.1700\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.5488 - val_loss: 1343.5656\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.4997 - val_loss: 1344.8965\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 140.4550 - val_loss: 1346.1650\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.4142 - val_loss: 1347.3729\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.3772 - val_loss: 1348.5223\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.3434 - val_loss: 1349.6158\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.3127 - val_loss: 1350.6560\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.2848 - val_loss: 1351.6433\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.2594 - val_loss: 1352.5804\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.2364 - val_loss: 1353.4706\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.2155 - val_loss: 1354.3138\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.1964 - val_loss: 1355.1127\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1792 - val_loss: 1355.8700\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.1635 - val_loss: 1356.5859\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1493 - val_loss: 1357.2633\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1365 - val_loss: 1357.9028\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.1248 - val_loss: 1358.5076\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1143 - val_loss: 1359.0785\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1047 - val_loss: 1359.6172\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0961 - val_loss: 1360.1250\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0883 - val_loss: 1360.6024\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0814 - val_loss: 1361.0525\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0750 - val_loss: 1361.4761\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0694 - val_loss: 1361.8741\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0642 - val_loss: 1362.2485\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0597 - val_loss: 1362.6002\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0556 - val_loss: 1362.9297\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0520 - val_loss: 1363.2397\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0487 - val_loss: 1363.5299\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0458 - val_loss: 1363.8019\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0433 - val_loss: 1364.0555\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 140.0410 - val_loss: 1364.2943\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0390 - val_loss: 1364.5164\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0374 - val_loss: 1364.7250\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0359 - val_loss: 1364.9189\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0346 - val_loss: 1365.1005\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0336 - val_loss: 1365.2693\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0327 - val_loss: 1365.4270\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0320 - val_loss: 1365.5731\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0314 - val_loss: 1365.7098\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0310 - val_loss: 1365.8368\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0307 - val_loss: 1365.9541\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0305 - val_loss: 1366.0638\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0305 - val_loss: 1366.1654\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0305 - val_loss: 1366.2589\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0306 - val_loss: 1366.3464\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0308 - val_loss: 1366.4277\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0310 - val_loss: 1366.5022\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0313 - val_loss: 1366.5712\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0318 - val_loss: 1366.6348\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0322 - val_loss: 1366.6934\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0327 - val_loss: 1366.7477\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0333 - val_loss: 1366.7979\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0339 - val_loss: 1366.8439\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0345 - val_loss: 1366.8857\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0352 - val_loss: 1366.9248\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0359 - val_loss: 1366.9606\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 140.0367 - val_loss: 1366.9935\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0374 - val_loss: 1367.0231\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0382 - val_loss: 1367.0503\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0389 - val_loss: 1367.0752\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0398 - val_loss: 1367.0989\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0405 - val_loss: 1367.1196\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0414 - val_loss: 1367.1381\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0423 - val_loss: 1367.1556\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0431 - val_loss: 1367.1711\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0440 - val_loss: 1367.1853\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0448 - val_loss: 1367.1981\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0456 - val_loss: 1367.2094\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0466 - val_loss: 1367.2196\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0475 - val_loss: 1367.2288\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0483 - val_loss: 1367.2372\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0492 - val_loss: 1367.2452\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0501 - val_loss: 1367.2516\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0509 - val_loss: 1367.2573\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0518 - val_loss: 1367.2620\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0526 - val_loss: 1367.2667\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0535 - val_loss: 1367.2698\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0544 - val_loss: 1367.2737\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0552 - val_loss: 1367.2764\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0560 - val_loss: 1367.2792\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0569 - val_loss: 1367.2814\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0577 - val_loss: 1367.2827\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 140.0585 - val_loss: 1367.2837\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 140.0593 - val_loss: 1367.2847\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0601 - val_loss: 1367.2856\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0609 - val_loss: 1367.2864\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0616 - val_loss: 1367.2864\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0625 - val_loss: 1367.2864\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0632 - val_loss: 1367.2864\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0639 - val_loss: 1367.2861\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0647 - val_loss: 1367.2858\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0654 - val_loss: 1367.2847\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0661 - val_loss: 1367.2843\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0669 - val_loss: 1367.2839\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0675 - val_loss: 1367.2834\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0683 - val_loss: 1367.2825\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0689 - val_loss: 1367.2809\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0696 - val_loss: 1367.2800\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0703 - val_loss: 1367.2787\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0708 - val_loss: 1367.2776\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0715 - val_loss: 1367.2767\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0721 - val_loss: 1367.2750\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0728 - val_loss: 1367.2734\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0734 - val_loss: 1367.2722\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0740 - val_loss: 1367.2709\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0746 - val_loss: 1367.2697\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0751 - val_loss: 1367.2679\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0757 - val_loss: 1367.2664\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0763 - val_loss: 1367.2653\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 140.0768 - val_loss: 1367.2644\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.0773 - val_loss: 1367.2627\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0779 - val_loss: 1367.2615\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0784 - val_loss: 1367.2598\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0789 - val_loss: 1367.2584\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0794 - val_loss: 1367.2566\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0799 - val_loss: 1367.2554\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0804 - val_loss: 1367.2539\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0808 - val_loss: 1367.2526\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0813 - val_loss: 1367.2513\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0818 - val_loss: 1367.2499\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0822 - val_loss: 1367.2485\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0826 - val_loss: 1367.2474\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0830 - val_loss: 1367.2461\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0835 - val_loss: 1367.2456\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.0838 - val_loss: 1367.2435\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 140.0843 - val_loss: 1367.2422\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0847 - val_loss: 1367.2412\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0851 - val_loss: 1367.2400\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0854 - val_loss: 1367.2386\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0858 - val_loss: 1367.2378\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0862 - val_loss: 1367.2369\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0865 - val_loss: 1367.2356\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0869 - val_loss: 1367.2345\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0872 - val_loss: 1367.2329\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 140.0876 - val_loss: 1367.2319\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0879 - val_loss: 1367.2312\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0882 - val_loss: 1367.2305\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0885 - val_loss: 1367.2292\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0888 - val_loss: 1367.2285\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0891 - val_loss: 1367.2274\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0895 - val_loss: 1367.2268\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0897 - val_loss: 1367.2261\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0900 - val_loss: 1367.2252\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0903 - val_loss: 1367.2246\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0905 - val_loss: 1367.2233\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0908 - val_loss: 1367.2228\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0911 - val_loss: 1367.2219\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0913 - val_loss: 1367.2211\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0916 - val_loss: 1367.2205\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0918 - val_loss: 1367.2196\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 140.0921 - val_loss: 1367.2189\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 140.0923 - val_loss: 1367.2179\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0925 - val_loss: 1367.2169\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.0928 - val_loss: 1367.2164\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0929 - val_loss: 1367.2151\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0931 - val_loss: 1367.2145\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0934 - val_loss: 1367.2140\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0936 - val_loss: 1367.2128\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0938 - val_loss: 1367.2125\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0940 - val_loss: 1367.2122\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0941 - val_loss: 1367.2113\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0943 - val_loss: 1367.2103\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0946 - val_loss: 1367.2097\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0947 - val_loss: 1367.2091\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0949 - val_loss: 1367.2084\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0951 - val_loss: 1367.2079\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0952 - val_loss: 1367.2075\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0954 - val_loss: 1367.2078\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0956 - val_loss: 1367.2074\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0957 - val_loss: 1367.2074\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0958 - val_loss: 1367.2062\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0960 - val_loss: 1367.2059\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0962 - val_loss: 1367.2053\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 140.0963 - val_loss: 1367.2050\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0964 - val_loss: 1367.2043\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0966 - val_loss: 1367.2039\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0967 - val_loss: 1367.2032\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0968 - val_loss: 1367.2032\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0970 - val_loss: 1367.2028\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0971 - val_loss: 1367.2028\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0973 - val_loss: 1367.2024\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0974 - val_loss: 1367.2026\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0974 - val_loss: 1367.2018\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0975 - val_loss: 1367.2012\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0977 - val_loss: 1367.2003\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0978 - val_loss: 1367.2003\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0978 - val_loss: 1367.1996\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0980 - val_loss: 1367.1992\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0981 - val_loss: 1367.1990\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0982 - val_loss: 1367.1986\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0982 - val_loss: 1367.1980\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0984 - val_loss: 1367.1980\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0985 - val_loss: 1367.1979\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0985 - val_loss: 1367.1975\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0986 - val_loss: 1367.1969\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 140.0988 - val_loss: 1367.1969\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.0988 - val_loss: 1367.1968\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.0989 - val_loss: 1367.1967\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0990 - val_loss: 1367.1967\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0991 - val_loss: 1367.1969\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0992 - val_loss: 1367.1967\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0992 - val_loss: 1367.1958\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0993 - val_loss: 1367.1956\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0994 - val_loss: 1367.1954\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0995 - val_loss: 1367.1956\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0995 - val_loss: 1367.1951\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0996 - val_loss: 1367.1947\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0996 - val_loss: 1367.1940\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.0997 - val_loss: 1367.1934\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0997 - val_loss: 1367.1931\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0997 - val_loss: 1367.1926\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0999 - val_loss: 1367.1926\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0999 - val_loss: 1367.1920\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1000 - val_loss: 1367.1920\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1001 - val_loss: 1367.1923\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1001 - val_loss: 1367.1920\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1001 - val_loss: 1367.1920\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.1002 - val_loss: 1367.1920\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.1003 - val_loss: 1367.1920\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 140.1003 - val_loss: 1367.1918\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1003 - val_loss: 1367.1918\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.1004 - val_loss: 1367.1914\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1005 - val_loss: 1367.1914\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1005 - val_loss: 1367.1915\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1006 - val_loss: 1367.1915\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1006 - val_loss: 1367.1918\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1006 - val_loss: 1367.1920\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1006 - val_loss: 1367.1920\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1007 - val_loss: 1367.1920\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1008 - val_loss: 1367.1920\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1008 - val_loss: 1367.1923\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1008 - val_loss: 1367.1921\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1009 - val_loss: 1367.1924\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1008 - val_loss: 1367.1926\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1009 - val_loss: 1367.1924\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1008 - val_loss: 1367.1920\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1009 - val_loss: 1367.1912\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1010 - val_loss: 1367.1887\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1010 - val_loss: 1367.1882\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1011 - val_loss: 1367.1877\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1011 - val_loss: 1367.1876\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 140.1012 - val_loss: 1367.1881\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1012 - val_loss: 1367.1882\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.1012 - val_loss: 1367.1882\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1013 - val_loss: 1367.1880\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1013 - val_loss: 1367.1875\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1013 - val_loss: 1367.1869\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1013 - val_loss: 1367.1869\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1013 - val_loss: 1367.1869\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1014 - val_loss: 1367.1866\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1014 - val_loss: 1367.1865\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1014 - val_loss: 1367.1865\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1014 - val_loss: 1367.1863\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1014 - val_loss: 1367.1860\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1015 - val_loss: 1367.1860\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1015 - val_loss: 1367.1860\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.1015 - val_loss: 1367.1863\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1016 - val_loss: 1367.1864\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1016 - val_loss: 1367.1865\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1016 - val_loss: 1367.1865\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1016 - val_loss: 1367.1868\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1016 - val_loss: 1367.1862\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1016 - val_loss: 1367.1860\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 140.1016 - val_loss: 1367.1860\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1017 - val_loss: 1367.1858\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.1017 - val_loss: 1367.1860\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1017 - val_loss: 1367.1860\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1017 - val_loss: 1367.1863\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 140.1017 - val_loss: 1367.1869\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1017 - val_loss: 1367.1874\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1017 - val_loss: 1367.1874\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1017 - val_loss: 1367.1876\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1017 - val_loss: 1367.1876\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1018 - val_loss: 1367.1876\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1018 - val_loss: 1367.1879\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1018 - val_loss: 1367.1880\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1017 - val_loss: 1367.1874\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1018 - val_loss: 1367.1874\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1018 - val_loss: 1367.1869\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1019 - val_loss: 1367.1868\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1019 - val_loss: 1367.1865\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.1019 - val_loss: 1367.1865\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1019 - val_loss: 1367.1865\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1019 - val_loss: 1367.1868\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 140.1019 - val_loss: 1367.1871\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.1019 - val_loss: 1367.1874\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1019 - val_loss: 1367.1875\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1019 - val_loss: 1367.1875\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1020 - val_loss: 1367.1875\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1019 - val_loss: 1367.1875\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1019 - val_loss: 1367.1875\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1019 - val_loss: 1367.1876\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.1019 - val_loss: 1367.1879\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.1020 - val_loss: 1367.1882\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1020 - val_loss: 1367.1885\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1020 - val_loss: 1367.1884\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1020 - val_loss: 1367.1884\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1020 - val_loss: 1367.1882\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1020 - val_loss: 1367.1882\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1020 - val_loss: 1367.1879\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1020 - val_loss: 1367.1874\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1020 - val_loss: 1367.1874\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1875\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1879\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 140.1021 - val_loss: 1367.1879\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.1021 - val_loss: 1367.1879\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1020 - val_loss: 1367.1873\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1871\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1871\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1870\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1865\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1862\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.1021 - val_loss: 1367.1862\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1859\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1859\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1854\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1854\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1852\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.1021 - val_loss: 1367.1852\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1852\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1852\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1852\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1852\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1852\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1852\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 140.1021 - val_loss: 1367.1852\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1852\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1852\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1852\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.1021 - val_loss: 1367.1852\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(85.7336, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0020, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0125, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3008, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 464ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[65.5978999 , 65.3728992 , 65.1460084 , 64.9191177 , 71.9575653 ,\n",
       "         0.        ,  0.        ,  0.4493719 ,  0.71703196,  0.        ,\n",
       "         0.19309656,  1.32399821,  0.        , 64.010084  , 63.9764706 ,\n",
       "        63.9428571 , 63.9092437 , 63.8268908 , 66.5998716 , 66.3603758 ,\n",
       "        66.12088   , 65.8813842 , 65.6502101 , 65.4233193 , 65.1964286 ,\n",
       "        64.9695378 , 64.795098  ,  0.15382946,  0.        , 65.7426471 ,\n",
       "        65.5157563 , 65.2888655 , 65.0619748 , 64.8567227 , 64.7054622 ,\n",
       "        64.5534202 , 64.4029412 , 64.2677871 ,  0.        ,  0.        ,\n",
       "         0.        ,  0.10806386,  0.68836278,  0.52911431,  0.21096653,\n",
       "         0.45161235,  0.65094316, 65.019958  , 64.8287115 ,  0.1785363 ,\n",
       "         0.47348952, 65.7930672 , 65.5666176 , 65.3392857 , 65.112395  ,\n",
       "        64.8903361 , 64.7390756 , 64.5868151 , 64.4365546 , 64.2901961 ,\n",
       "         0.35666937,  0.        , 64.9779412 , 64.8007003 , 64.6494398 ,\n",
       "        64.4981793 , 64.3469188 , 64.2304388 , 64.1295985 , 64.0287582 ,\n",
       "        63.9279178 ,  0.33966091,  0.29578042, 56.3342705 ,  0.        ,\n",
       "         0.38205823,  0.        ,  0.66391349,  0.        ,  0.        ,\n",
       "        63.93919373,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.01741445,  0.54856676,  0.        ,  0.18916638,  0.09965372,\n",
       "         0.32861182,  0.        ,  0.        ,  0.        ,  0.07284653,\n",
       "         0.50684118,  0.82598943,  0.        ,  0.37545803,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([57.09463005, 57.08561181, 57.07659356, 57.06757532, 57.05855708,\n",
       "       57.04953884, 57.0405206 , 57.03150236, 57.02248412, 57.01346587,\n",
       "       57.00444763, 56.99542939, 56.98641115, 56.97739291, 56.96837467,\n",
       "       56.95935643, 56.95033818, 56.94131994, 56.9323017 , 56.92328346,\n",
       "       56.91426522, 56.90524698, 56.89622874, 56.88721049, 56.87819225,\n",
       "       56.86917401, 56.86015577, 56.85113753, 56.84211929, 56.83310105,\n",
       "       56.8240828 , 56.81506456, 56.80604632, 56.79702808, 56.78800984,\n",
       "       56.7789916 , 56.76997336, 56.76095511, 56.75193687, 56.74291863,\n",
       "       56.73390039, 56.72488215, 56.71586391, 56.70684567, 56.69782742,\n",
       "       56.68880918, 56.67979094, 56.6707727 , 56.66175446, 56.65273622,\n",
       "       56.64371797, 56.63469973, 56.62568149, 56.61666325, 56.60764501,\n",
       "       56.59862677, 56.58960853, 56.58059028, 56.57157204, 56.5625538 ,\n",
       "       56.55353556, 56.54451732, 56.53549908, 56.52648084, 56.51746259,\n",
       "       56.50844435, 56.49942611, 56.49040787, 56.48138963, 56.47237139,\n",
       "       56.46335315, 56.4543349 , 56.44531666, 56.43629842, 56.42728018,\n",
       "       56.41826194, 56.4092437 , 56.40022546, 56.39120721, 56.38218897,\n",
       "       56.37317073, 56.36415249, 56.35513425, 56.34611601, 56.33709777,\n",
       "       56.32807952, 56.31906128, 56.31004304, 56.3010248 , 56.29200656,\n",
       "       56.28298832, 56.27397008, 56.26495183, 56.25593359, 56.24691535,\n",
       "       56.23789711, 56.22887887, 56.21986063, 56.21084239, 56.20182414])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.24113481370974\n",
      "32.20526739401909\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
