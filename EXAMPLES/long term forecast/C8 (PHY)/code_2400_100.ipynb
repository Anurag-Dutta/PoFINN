{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "2495    55.336073\n",
       "2496    55.327055\n",
       "2497    55.318036\n",
       "2498    55.309018\n",
       "2499    55.300000\n",
       "Name: C8, Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c8_interpolated_2400_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "2395     0.506841\n",
       "2396     0.825989\n",
       "2397     0.000000\n",
       "2398     0.375458\n",
       "2399     0.000000\n",
       "Name: C8, Length: 2400, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2400)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.987115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.774230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.561345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.348459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.200000  0.000298\n",
       "1     87.987115  0.000298\n",
       "2     87.774230  0.000297\n",
       "3     87.561345  0.000297\n",
       "4     87.348459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 85.7336  # Value for C0\n",
    "K0 = -0.0020  # Value for K0\n",
    "K1 = 0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0125    # Value for b\n",
    "c = 2.3008    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.200000    87.987115    87.774230    87.561345    87.348459   \n",
      "351    87.987115    87.774230    87.561345    87.348459    87.135574   \n",
      "352    87.774230    87.561345    87.348459    87.135574    86.922689   \n",
      "353    87.561345    87.348459    87.135574    86.922689    86.709804   \n",
      "354    87.348459    87.135574    86.922689    86.709804    86.496919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.135574    86.922689    86.709804    86.496919    86.294538  ...   \n",
      "351    86.922689    86.709804    86.496919    86.294538    86.221709  ...   \n",
      "352    86.709804    86.496919    86.294538    86.221709    86.148880  ...   \n",
      "353    86.496919    86.294538    86.221709    86.148880    86.076050  ...   \n",
      "354    86.294538    86.221709    86.148880    86.076050    86.003221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   76.094351    0.000263   76.058870    0.000263   76.023389    0.000263   \n",
      "351   76.058870    0.000263   76.023389    0.000263   75.987909    0.000262   \n",
      "352   76.023389    0.000263   75.987909    0.000262   75.952428    0.000262   \n",
      "353   75.987909    0.000262   75.952428    0.000262   75.916947    0.000262   \n",
      "354   75.952428    0.000262   75.916947    0.000262   75.881466    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   75.987909    0.000262   75.952428    0.000262  \n",
      "351   75.952428    0.000262   75.916947    0.000262  \n",
      "352   75.916947    0.000262   75.881466    0.000262  \n",
      "353   75.881466    0.000262   75.845985    0.000262  \n",
      "354   75.845985    0.000262   75.810504    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950, 1, 251) (1950, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "25/25 [==============================] - 4s 33ms/step - loss: 4397.0640 - val_loss: 2537.0745\n",
      "Epoch 2/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 4167.4917 - val_loss: 2399.0735\n",
      "Epoch 3/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3976.6812 - val_loss: 2294.9041\n",
      "Epoch 4/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 3839.9045 - val_loss: 2218.8533\n",
      "Epoch 5/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3711.9856 - val_loss: 2144.5427\n",
      "Epoch 6/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3591.5706 - val_loss: 2076.8330\n",
      "Epoch 7/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3477.3267 - val_loss: 2012.6656\n",
      "Epoch 8/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3367.5144 - val_loss: 1951.4880\n",
      "Epoch 9/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3261.4561 - val_loss: 1892.9672\n",
      "Epoch 10/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3158.7725 - val_loss: 1836.9771\n",
      "Epoch 11/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3059.1660 - val_loss: 1783.5590\n",
      "Epoch 12/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 2962.4753 - val_loss: 1732.2380\n",
      "Epoch 13/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 2868.5547 - val_loss: 1683.0573\n",
      "Epoch 14/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 2777.2888 - val_loss: 1635.9446\n",
      "Epoch 15/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 2688.5835 - val_loss: 1590.8206\n",
      "Epoch 16/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2602.3555 - val_loss: 1547.5664\n",
      "Epoch 17/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 2518.5164 - val_loss: 1505.8080\n",
      "Epoch 18/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2437.0981 - val_loss: 1467.3995\n",
      "Epoch 19/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2357.8384 - val_loss: 1429.8131\n",
      "Epoch 20/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2280.8533 - val_loss: 1393.9666\n",
      "Epoch 21/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2206.0371 - val_loss: 1359.8138\n",
      "Epoch 22/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2133.3389 - val_loss: 1327.3112\n",
      "Epoch 23/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2062.7107 - val_loss: 1296.4146\n",
      "Epoch 24/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1994.1064 - val_loss: 1267.0790\n",
      "Epoch 25/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1927.4817 - val_loss: 1238.8284\n",
      "Epoch 26/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1858.8949 - val_loss: 1209.9050\n",
      "Epoch 27/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1790.4591 - val_loss: 1183.2411\n",
      "Epoch 28/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1725.3833 - val_loss: 1158.5801\n",
      "Epoch 29/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1663.1382 - val_loss: 1135.6633\n",
      "Epoch 30/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1603.3180 - val_loss: 1114.3424\n",
      "Epoch 31/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1545.6974 - val_loss: 1094.5171\n",
      "Epoch 32/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1490.1292 - val_loss: 1076.1113\n",
      "Epoch 33/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1436.5055 - val_loss: 1059.0614\n",
      "Epoch 34/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1384.7418 - val_loss: 1043.3113\n",
      "Epoch 35/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1334.7659 - val_loss: 1028.8110\n",
      "Epoch 36/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1286.5153 - val_loss: 1015.5133\n",
      "Epoch 37/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1239.9338 - val_loss: 1003.3742\n",
      "Epoch 38/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1194.9696 - val_loss: 992.3514\n",
      "Epoch 39/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1151.5739 - val_loss: 982.4050\n",
      "Epoch 40/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1109.7012 - val_loss: 973.4957\n",
      "Epoch 41/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1069.3091 - val_loss: 965.5859\n",
      "Epoch 42/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1030.3553 - val_loss: 958.6388\n",
      "Epoch 43/500\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 992.7997 - val_loss: 952.6185\n",
      "Epoch 44/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 956.6043 - val_loss: 947.4901\n",
      "Epoch 45/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 921.7316 - val_loss: 943.2192\n",
      "Epoch 46/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 888.1449 - val_loss: 939.7726\n",
      "Epoch 47/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 855.8087 - val_loss: 937.1166\n",
      "Epoch 48/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 824.6882 - val_loss: 935.2196\n",
      "Epoch 49/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 794.7500 - val_loss: 934.0497\n",
      "Epoch 50/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 765.9603 - val_loss: 933.5756\n",
      "Epoch 51/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 738.2869 - val_loss: 933.7669\n",
      "Epoch 52/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 711.6981 - val_loss: 934.5936\n",
      "Epoch 53/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 686.1622 - val_loss: 936.0259\n",
      "Epoch 54/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 661.6492 - val_loss: 938.0350\n",
      "Epoch 55/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 638.1283 - val_loss: 940.5927\n",
      "Epoch 56/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 615.5701 - val_loss: 943.6705\n",
      "Epoch 57/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 593.9456 - val_loss: 947.2413\n",
      "Epoch 58/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 573.2266 - val_loss: 951.2782\n",
      "Epoch 59/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 553.3845 - val_loss: 955.7548\n",
      "Epoch 60/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 534.3921 - val_loss: 960.6452\n",
      "Epoch 61/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 516.2223 - val_loss: 965.9239\n",
      "Epoch 62/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 498.8486 - val_loss: 971.5663\n",
      "Epoch 63/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 482.2448 - val_loss: 977.5480\n",
      "Epoch 64/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 466.3855 - val_loss: 983.8453\n",
      "Epoch 65/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 451.2455 - val_loss: 990.4352\n",
      "Epoch 66/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 436.8001 - val_loss: 997.2947\n",
      "Epoch 67/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 423.0253 - val_loss: 1004.4017\n",
      "Epoch 68/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 409.8974 - val_loss: 1011.7349\n",
      "Epoch 69/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 397.3935 - val_loss: 1019.2734\n",
      "Epoch 70/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 385.4904 - val_loss: 1026.9963\n",
      "Epoch 71/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 374.1664 - val_loss: 1034.8838\n",
      "Epoch 72/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 363.3996 - val_loss: 1042.9174\n",
      "Epoch 73/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 353.1685 - val_loss: 1051.0775\n",
      "Epoch 74/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 343.4527 - val_loss: 1059.3466\n",
      "Epoch 75/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 334.2318 - val_loss: 1067.7067\n",
      "Epoch 76/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 325.4861 - val_loss: 1076.1412\n",
      "Epoch 77/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 317.1960 - val_loss: 1084.6339\n",
      "Epoch 78/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 309.3430 - val_loss: 1093.1691\n",
      "Epoch 79/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 301.9088 - val_loss: 1101.7313\n",
      "Epoch 80/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 294.8753 - val_loss: 1110.3062\n",
      "Epoch 81/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 288.2254 - val_loss: 1118.8801\n",
      "Epoch 82/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 281.9421 - val_loss: 1127.4391\n",
      "Epoch 83/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 276.0092 - val_loss: 1135.9717\n",
      "Epoch 84/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 270.4105 - val_loss: 1144.4646\n",
      "Epoch 85/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 265.1309 - val_loss: 1152.9072\n",
      "Epoch 86/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 260.1552 - val_loss: 1161.2877\n",
      "Epoch 87/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 255.4692 - val_loss: 1169.5964\n",
      "Epoch 88/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 251.0588 - val_loss: 1177.8237\n",
      "Epoch 89/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 246.9105 - val_loss: 1185.9608\n",
      "Epoch 90/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 243.0112 - val_loss: 1193.9983\n",
      "Epoch 91/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 239.3484 - val_loss: 1201.9291\n",
      "Epoch 92/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 235.9100 - val_loss: 1209.7450\n",
      "Epoch 93/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 232.6842 - val_loss: 1217.4402\n",
      "Epoch 94/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 229.6599 - val_loss: 1225.0072\n",
      "Epoch 95/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 226.8263 - val_loss: 1232.4412\n",
      "Epoch 96/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 224.1730 - val_loss: 1239.7365\n",
      "Epoch 97/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 221.6901 - val_loss: 1246.8892\n",
      "Epoch 98/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3679 - val_loss: 1253.8938\n",
      "Epoch 99/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 217.1975 - val_loss: 1260.7478\n",
      "Epoch 100/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 215.1702 - val_loss: 1267.4471\n",
      "Epoch 101/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 213.2775 - val_loss: 1273.9900\n",
      "Epoch 102/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 211.5116 - val_loss: 1280.3730\n",
      "Epoch 103/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 209.8648 - val_loss: 1286.5952\n",
      "Epoch 104/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 208.3301 - val_loss: 1292.6547\n",
      "Epoch 105/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 206.9005 - val_loss: 1298.5498\n",
      "Epoch 106/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 205.5695 - val_loss: 1304.2809\n",
      "Epoch 107/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.3309 - val_loss: 1309.8472\n",
      "Epoch 108/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 203.1789 - val_loss: 1315.2485\n",
      "Epoch 109/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 202.1079 - val_loss: 1320.4857\n",
      "Epoch 110/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 201.1128 - val_loss: 1325.5596\n",
      "Epoch 111/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 200.1883 - val_loss: 1330.4697\n",
      "Epoch 112/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 199.3301 - val_loss: 1335.2198\n",
      "Epoch 113/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 198.5334 - val_loss: 1339.8086\n",
      "Epoch 114/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 197.7945 - val_loss: 1344.2394\n",
      "Epoch 115/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 197.1091 - val_loss: 1348.5145\n",
      "Epoch 116/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 196.4736 - val_loss: 1352.6359\n",
      "Epoch 117/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 195.8845 - val_loss: 1356.6051\n",
      "Epoch 118/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 195.3387 - val_loss: 1360.4250\n",
      "Epoch 119/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 194.8330 - val_loss: 1364.0995\n",
      "Epoch 120/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 194.3647 - val_loss: 1367.6295\n",
      "Epoch 121/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 193.9310 - val_loss: 1371.0200\n",
      "Epoch 122/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 193.5295 - val_loss: 1374.2726\n",
      "Epoch 123/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 193.1577 - val_loss: 1377.3915\n",
      "Epoch 124/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 192.8137 - val_loss: 1380.3790\n",
      "Epoch 125/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 192.4953 - val_loss: 1383.2391\n",
      "Epoch 126/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 192.2007 - val_loss: 1385.9749\n",
      "Epoch 127/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 191.9281 - val_loss: 1388.5902\n",
      "Epoch 128/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 191.6758 - val_loss: 1391.0895\n",
      "Epoch 129/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 191.4424 - val_loss: 1393.4744\n",
      "Epoch 130/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 191.2264 - val_loss: 1395.7494\n",
      "Epoch 131/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 191.0264 - val_loss: 1397.9185\n",
      "Epoch 132/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 190.8416 - val_loss: 1399.9832\n",
      "Epoch 133/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 190.6704 - val_loss: 1401.9493\n",
      "Epoch 134/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 190.5121 - val_loss: 1403.8198\n",
      "Epoch 135/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 190.3655 - val_loss: 1405.5979\n",
      "Epoch 136/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 190.2298 - val_loss: 1407.2865\n",
      "Epoch 137/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 190.1042 - val_loss: 1408.8894\n",
      "Epoch 138/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 189.9880 - val_loss: 1410.4103\n",
      "Epoch 139/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 189.8804 - val_loss: 1411.8516\n",
      "Epoch 140/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 189.7807 - val_loss: 1413.2173\n",
      "Epoch 141/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 189.6885 - val_loss: 1414.5109\n",
      "Epoch 142/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 189.6031 - val_loss: 1415.7343\n",
      "Epoch 143/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 189.5240 - val_loss: 1416.8907\n",
      "Epoch 144/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 189.4507 - val_loss: 1417.9845\n",
      "Epoch 145/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 189.3829 - val_loss: 1419.0170\n",
      "Epoch 146/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 189.3200 - val_loss: 1419.9913\n",
      "Epoch 147/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 189.2618 - val_loss: 1420.9105\n",
      "Epoch 148/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 189.2079 - val_loss: 1421.7765\n",
      "Epoch 149/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 189.1580 - val_loss: 1422.5929\n",
      "Epoch 150/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 189.1117 - val_loss: 1423.3618\n",
      "Epoch 151/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 189.0688 - val_loss: 1424.0845\n",
      "Epoch 152/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 189.0291 - val_loss: 1424.7644\n",
      "Epoch 153/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 188.9925 - val_loss: 1425.4036\n",
      "Epoch 154/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.9584 - val_loss: 1426.0031\n",
      "Epoch 155/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.9270 - val_loss: 1426.5665\n",
      "Epoch 156/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.8979 - val_loss: 1427.0948\n",
      "Epoch 157/500\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 188.8709 - val_loss: 1427.5906\n",
      "Epoch 158/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.8460 - val_loss: 1428.0547\n",
      "Epoch 159/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.8230 - val_loss: 1428.4902\n",
      "Epoch 160/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.8017 - val_loss: 1428.8972\n",
      "Epoch 161/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.7820 - val_loss: 1429.2782\n",
      "Epoch 162/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.7638 - val_loss: 1429.6348\n",
      "Epoch 163/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.7470 - val_loss: 1429.9672\n",
      "Epoch 164/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.7315 - val_loss: 1430.2787\n",
      "Epoch 165/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.7173 - val_loss: 1430.5685\n",
      "Epoch 166/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.7041 - val_loss: 1430.8391\n",
      "Epoch 167/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6921 - val_loss: 1431.0923\n",
      "Epoch 168/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6809 - val_loss: 1431.3279\n",
      "Epoch 169/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 188.6707 - val_loss: 1431.5465\n",
      "Epoch 170/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6613 - val_loss: 1431.7509\n",
      "Epoch 171/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6527 - val_loss: 1431.9406\n",
      "Epoch 172/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6448 - val_loss: 1432.1174\n",
      "Epoch 173/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6376 - val_loss: 1432.2822\n",
      "Epoch 174/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6310 - val_loss: 1432.4346\n",
      "Epoch 175/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6250 - val_loss: 1432.5768\n",
      "Epoch 176/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6194 - val_loss: 1432.7085\n",
      "Epoch 177/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6145 - val_loss: 1432.8303\n",
      "Epoch 178/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6100 - val_loss: 1432.9441\n",
      "Epoch 179/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6059 - val_loss: 1433.0492\n",
      "Epoch 180/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6022 - val_loss: 1433.1470\n",
      "Epoch 181/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5988 - val_loss: 1433.2371\n",
      "Epoch 182/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5958 - val_loss: 1433.3203\n",
      "Epoch 183/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5932 - val_loss: 1433.3977\n",
      "Epoch 184/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5907 - val_loss: 1433.4688\n",
      "Epoch 185/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5886 - val_loss: 1433.5349\n",
      "Epoch 186/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5867 - val_loss: 1433.5959\n",
      "Epoch 187/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.5850 - val_loss: 1433.6522\n",
      "Epoch 188/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.5836 - val_loss: 1433.7045\n",
      "Epoch 189/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5823 - val_loss: 1433.7521\n",
      "Epoch 190/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5812 - val_loss: 1433.7963\n",
      "Epoch 191/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5804 - val_loss: 1433.8367\n",
      "Epoch 192/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5796 - val_loss: 1433.8745\n",
      "Epoch 193/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5790 - val_loss: 1433.9089\n",
      "Epoch 194/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5784 - val_loss: 1433.9414\n",
      "Epoch 195/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5780 - val_loss: 1433.9705\n",
      "Epoch 196/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5777 - val_loss: 1433.9976\n",
      "Epoch 197/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5776 - val_loss: 1434.0226\n",
      "Epoch 198/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5774 - val_loss: 1434.0457\n",
      "Epoch 199/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5774 - val_loss: 1434.0665\n",
      "Epoch 200/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5775 - val_loss: 1434.0857\n",
      "Epoch 201/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5776 - val_loss: 1434.1034\n",
      "Epoch 202/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5778 - val_loss: 1434.1195\n",
      "Epoch 203/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5780 - val_loss: 1434.1346\n",
      "Epoch 204/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.5782 - val_loss: 1434.1477\n",
      "Epoch 205/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.5786 - val_loss: 1434.1604\n",
      "Epoch 206/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.5789 - val_loss: 1434.1715\n",
      "Epoch 207/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 188.5793 - val_loss: 1434.1823\n",
      "Epoch 208/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.5797 - val_loss: 1434.1910\n",
      "Epoch 209/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5802 - val_loss: 1434.2002\n",
      "Epoch 210/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5807 - val_loss: 1434.2075\n",
      "Epoch 211/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5812 - val_loss: 1434.2152\n",
      "Epoch 212/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5816 - val_loss: 1434.2217\n",
      "Epoch 213/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5822 - val_loss: 1434.2273\n",
      "Epoch 214/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5827 - val_loss: 1434.2332\n",
      "Epoch 215/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 188.5833 - val_loss: 1434.2383\n",
      "Epoch 216/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5838 - val_loss: 1434.2427\n",
      "Epoch 217/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5844 - val_loss: 1434.2469\n",
      "Epoch 218/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5850 - val_loss: 1434.2501\n",
      "Epoch 219/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5856 - val_loss: 1434.2532\n",
      "Epoch 220/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5861 - val_loss: 1434.2566\n",
      "Epoch 221/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5867 - val_loss: 1434.2594\n",
      "Epoch 222/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5873 - val_loss: 1434.2612\n",
      "Epoch 223/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5879 - val_loss: 1434.2639\n",
      "Epoch 224/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5885 - val_loss: 1434.2657\n",
      "Epoch 225/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.5890 - val_loss: 1434.2675\n",
      "Epoch 226/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5896 - val_loss: 1434.2688\n",
      "Epoch 227/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5902 - val_loss: 1434.2695\n",
      "Epoch 228/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5907 - val_loss: 1434.2714\n",
      "Epoch 229/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5913 - val_loss: 1434.2722\n",
      "Epoch 230/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5918 - val_loss: 1434.2737\n",
      "Epoch 231/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5923 - val_loss: 1434.2748\n",
      "Epoch 232/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.5929 - val_loss: 1434.2750\n",
      "Epoch 233/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5935 - val_loss: 1434.2758\n",
      "Epoch 234/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5939 - val_loss: 1434.2766\n",
      "Epoch 235/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5945 - val_loss: 1434.2772\n",
      "Epoch 236/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5950 - val_loss: 1434.2777\n",
      "Epoch 237/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5955 - val_loss: 1434.2778\n",
      "Epoch 238/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5959 - val_loss: 1434.2781\n",
      "Epoch 239/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5964 - val_loss: 1434.2782\n",
      "Epoch 240/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 188.5969 - val_loss: 1434.2782\n",
      "Epoch 241/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 188.5974 - val_loss: 1434.2783\n",
      "Epoch 242/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.5979 - val_loss: 1434.2783\n",
      "Epoch 243/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5983 - val_loss: 1434.2786\n",
      "Epoch 244/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.5988 - val_loss: 1434.2786\n",
      "Epoch 245/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.5992 - val_loss: 1434.2787\n",
      "Epoch 246/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.5996 - val_loss: 1434.2787\n",
      "Epoch 247/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6000 - val_loss: 1434.2786\n",
      "Epoch 248/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6005 - val_loss: 1434.2786\n",
      "Epoch 249/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6009 - val_loss: 1434.2786\n",
      "Epoch 250/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6012 - val_loss: 1434.2781\n",
      "Epoch 251/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6017 - val_loss: 1434.2783\n",
      "Epoch 252/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6020 - val_loss: 1434.2786\n",
      "Epoch 253/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6024 - val_loss: 1434.2782\n",
      "Epoch 254/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6028 - val_loss: 1434.2782\n",
      "Epoch 255/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.6031 - val_loss: 1434.2781\n",
      "Epoch 256/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.6034 - val_loss: 1434.2778\n",
      "Epoch 257/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 188.6038 - val_loss: 1434.2776\n",
      "Epoch 258/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.6041 - val_loss: 1434.2772\n",
      "Epoch 259/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.6045 - val_loss: 1434.2773\n",
      "Epoch 260/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6048 - val_loss: 1434.2773\n",
      "Epoch 261/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.6051 - val_loss: 1434.2770\n",
      "Epoch 262/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.6054 - val_loss: 1434.2761\n",
      "Epoch 263/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6057 - val_loss: 1434.2761\n",
      "Epoch 264/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6061 - val_loss: 1434.2758\n",
      "Epoch 265/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6063 - val_loss: 1434.2751\n",
      "Epoch 266/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6066 - val_loss: 1434.2750\n",
      "Epoch 267/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 188.6069 - val_loss: 1434.2751\n",
      "Epoch 268/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6071 - val_loss: 1434.2753\n",
      "Epoch 269/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6073 - val_loss: 1434.2750\n",
      "Epoch 270/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 188.6077 - val_loss: 1434.2747\n",
      "Epoch 271/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6079 - val_loss: 1434.2745\n",
      "Epoch 272/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6082 - val_loss: 1434.2745\n",
      "Epoch 273/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6084 - val_loss: 1434.2745\n",
      "Epoch 274/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6087 - val_loss: 1434.2745\n",
      "Epoch 275/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6089 - val_loss: 1434.2745\n",
      "Epoch 276/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6091 - val_loss: 1434.2745\n",
      "Epoch 277/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6093 - val_loss: 1434.2732\n",
      "Epoch 278/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6095 - val_loss: 1434.2737\n",
      "Epoch 279/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6097 - val_loss: 1434.2732\n",
      "Epoch 280/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6100 - val_loss: 1434.2732\n",
      "Epoch 281/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6101 - val_loss: 1434.2732\n",
      "Epoch 282/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6104 - val_loss: 1434.2732\n",
      "Epoch 283/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6106 - val_loss: 1434.2732\n",
      "Epoch 284/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6107 - val_loss: 1434.2731\n",
      "Epoch 285/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6108 - val_loss: 1434.2729\n",
      "Epoch 286/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 188.6110 - val_loss: 1434.2729\n",
      "Epoch 287/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 188.6112 - val_loss: 1434.2729\n",
      "Epoch 288/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6114 - val_loss: 1434.2727\n",
      "Epoch 289/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6115 - val_loss: 1434.2725\n",
      "Epoch 290/500\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 188.6117 - val_loss: 1434.2725\n",
      "Epoch 291/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.6119 - val_loss: 1434.2725\n",
      "Epoch 292/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6121 - val_loss: 1434.2726\n",
      "Epoch 293/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6122 - val_loss: 1434.2725\n",
      "Epoch 294/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6123 - val_loss: 1434.2726\n",
      "Epoch 295/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6125 - val_loss: 1434.2727\n",
      "Epoch 296/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6126 - val_loss: 1434.2727\n",
      "Epoch 297/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6127 - val_loss: 1434.2726\n",
      "Epoch 298/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6128 - val_loss: 1434.2726\n",
      "Epoch 299/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6130 - val_loss: 1434.2726\n",
      "Epoch 300/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6131 - val_loss: 1434.2721\n",
      "Epoch 301/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6132 - val_loss: 1434.2721\n",
      "Epoch 302/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6133 - val_loss: 1434.2720\n",
      "Epoch 303/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6134 - val_loss: 1434.2719\n",
      "Epoch 304/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6136 - val_loss: 1434.2716\n",
      "Epoch 305/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6137 - val_loss: 1434.2715\n",
      "Epoch 306/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6138 - val_loss: 1434.2714\n",
      "Epoch 307/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6139 - val_loss: 1434.2714\n",
      "Epoch 308/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6140 - val_loss: 1434.2711\n",
      "Epoch 309/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6141 - val_loss: 1434.2709\n",
      "Epoch 310/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6143 - val_loss: 1434.2710\n",
      "Epoch 311/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6143 - val_loss: 1434.2706\n",
      "Epoch 312/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6145 - val_loss: 1434.2706\n",
      "Epoch 313/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6145 - val_loss: 1434.2704\n",
      "Epoch 314/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6146 - val_loss: 1434.2704\n",
      "Epoch 315/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 188.6147 - val_loss: 1434.2697\n",
      "Epoch 316/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6148 - val_loss: 1434.2697\n",
      "Epoch 317/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6149 - val_loss: 1434.2701\n",
      "Epoch 318/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6150 - val_loss: 1434.2706\n",
      "Epoch 319/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6150 - val_loss: 1434.2706\n",
      "Epoch 320/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6151 - val_loss: 1434.2710\n",
      "Epoch 321/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6152 - val_loss: 1434.2709\n",
      "Epoch 322/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6152 - val_loss: 1434.2705\n",
      "Epoch 323/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6153 - val_loss: 1434.2706\n",
      "Epoch 324/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6154 - val_loss: 1434.2699\n",
      "Epoch 325/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6155 - val_loss: 1434.2699\n",
      "Epoch 326/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6155 - val_loss: 1434.2700\n",
      "Epoch 327/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6156 - val_loss: 1434.2700\n",
      "Epoch 328/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6157 - val_loss: 1434.2697\n",
      "Epoch 329/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6157 - val_loss: 1434.2700\n",
      "Epoch 330/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6158 - val_loss: 1434.2701\n",
      "Epoch 331/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6158 - val_loss: 1434.2701\n",
      "Epoch 332/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6159 - val_loss: 1434.2700\n",
      "Epoch 333/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6159 - val_loss: 1434.2706\n",
      "Epoch 334/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6160 - val_loss: 1434.2697\n",
      "Epoch 335/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6160 - val_loss: 1434.2695\n",
      "Epoch 336/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6161 - val_loss: 1434.2693\n",
      "Epoch 337/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6162 - val_loss: 1434.2694\n",
      "Epoch 338/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6162 - val_loss: 1434.2694\n",
      "Epoch 339/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6162 - val_loss: 1434.2695\n",
      "Epoch 340/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6163 - val_loss: 1434.2695\n",
      "Epoch 341/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6164 - val_loss: 1434.2695\n",
      "Epoch 342/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 188.6164 - val_loss: 1434.2697\n",
      "Epoch 343/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6164 - val_loss: 1434.2699\n",
      "Epoch 344/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6164 - val_loss: 1434.2699\n",
      "Epoch 345/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6165 - val_loss: 1434.2704\n",
      "Epoch 346/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6165 - val_loss: 1434.2701\n",
      "Epoch 347/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6165 - val_loss: 1434.2705\n",
      "Epoch 348/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6166 - val_loss: 1434.2704\n",
      "Epoch 349/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6166 - val_loss: 1434.2699\n",
      "Epoch 350/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6167 - val_loss: 1434.2700\n",
      "Epoch 351/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6167 - val_loss: 1434.2704\n",
      "Epoch 352/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6168 - val_loss: 1434.2706\n",
      "Epoch 353/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6169 - val_loss: 1434.2715\n",
      "Epoch 354/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6169 - val_loss: 1434.2726\n",
      "Epoch 355/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6169 - val_loss: 1434.2737\n",
      "Epoch 356/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6169 - val_loss: 1434.2883\n",
      "Epoch 357/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6136 - val_loss: 1431.2141\n",
      "Epoch 358/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6175 - val_loss: 1434.2760\n",
      "Epoch 359/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6167 - val_loss: 1434.2737\n",
      "Epoch 360/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6168 - val_loss: 1434.2729\n",
      "Epoch 361/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6169 - val_loss: 1434.2727\n",
      "Epoch 362/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6169 - val_loss: 1434.2722\n",
      "Epoch 363/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6170 - val_loss: 1434.2721\n",
      "Epoch 364/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.6170 - val_loss: 1434.2715\n",
      "Epoch 365/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6171 - val_loss: 1434.2706\n",
      "Epoch 366/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6171 - val_loss: 1434.2704\n",
      "Epoch 367/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6171 - val_loss: 1434.2704\n",
      "Epoch 368/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6171 - val_loss: 1434.2700\n",
      "Epoch 369/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6171 - val_loss: 1434.2694\n",
      "Epoch 370/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6172 - val_loss: 1434.2693\n",
      "Epoch 371/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 188.6173 - val_loss: 1434.2693\n",
      "Epoch 372/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6174 - val_loss: 1434.2695\n",
      "Epoch 373/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6174 - val_loss: 1434.2695\n",
      "Epoch 374/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6174 - val_loss: 1434.2695\n",
      "Epoch 375/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6174 - val_loss: 1434.2695\n",
      "Epoch 376/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6174 - val_loss: 1434.2693\n",
      "Epoch 377/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6174 - val_loss: 1434.2693\n",
      "Epoch 378/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6174 - val_loss: 1434.2690\n",
      "Epoch 379/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6174 - val_loss: 1434.2688\n",
      "Epoch 380/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6174 - val_loss: 1434.2681\n",
      "Epoch 381/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6175 - val_loss: 1434.2676\n",
      "Epoch 382/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6176 - val_loss: 1434.2676\n",
      "Epoch 383/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6176 - val_loss: 1434.2676\n",
      "Epoch 384/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6176 - val_loss: 1434.2679\n",
      "Epoch 385/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6176 - val_loss: 1434.2679\n",
      "Epoch 386/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6176 - val_loss: 1434.2679\n",
      "Epoch 387/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6176 - val_loss: 1434.2681\n",
      "Epoch 388/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6177 - val_loss: 1434.2684\n",
      "Epoch 389/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6177 - val_loss: 1434.2686\n",
      "Epoch 390/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6177 - val_loss: 1434.2689\n",
      "Epoch 391/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6177 - val_loss: 1434.2690\n",
      "Epoch 392/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6177 - val_loss: 1434.2694\n",
      "Epoch 393/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6177 - val_loss: 1434.2695\n",
      "Epoch 394/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 188.6177 - val_loss: 1434.2695\n",
      "Epoch 395/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6177 - val_loss: 1434.2695\n",
      "Epoch 396/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6177 - val_loss: 1434.2694\n",
      "Epoch 397/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6177 - val_loss: 1434.2694\n",
      "Epoch 398/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6177 - val_loss: 1434.2690\n",
      "Epoch 399/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6178 - val_loss: 1434.2690\n",
      "Epoch 400/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6178 - val_loss: 1434.2690\n",
      "Epoch 401/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6178 - val_loss: 1434.2690\n",
      "Epoch 402/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6178 - val_loss: 1434.2689\n",
      "Epoch 403/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6178 - val_loss: 1434.2688\n",
      "Epoch 404/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6178 - val_loss: 1434.2683\n",
      "Epoch 405/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6178 - val_loss: 1434.2683\n",
      "Epoch 406/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6178 - val_loss: 1434.2676\n",
      "Epoch 407/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6179 - val_loss: 1434.2673\n",
      "Epoch 408/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6179 - val_loss: 1434.2673\n",
      "Epoch 409/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6179 - val_loss: 1434.2667\n",
      "Epoch 410/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6179 - val_loss: 1434.2665\n",
      "Epoch 411/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2664\n",
      "Epoch 412/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6180 - val_loss: 1434.2665\n",
      "Epoch 413/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2670\n",
      "Epoch 414/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2676\n",
      "Epoch 415/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2679\n",
      "Epoch 416/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2681\n",
      "Epoch 417/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 188.6180 - val_loss: 1434.2681\n",
      "Epoch 418/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2684\n",
      "Epoch 419/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2684\n",
      "Epoch 420/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 188.6180 - val_loss: 1434.2686\n",
      "Epoch 421/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6180 - val_loss: 1434.2686\n",
      "Epoch 422/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2688\n",
      "Epoch 423/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6180 - val_loss: 1434.2688\n",
      "Epoch 424/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2688\n",
      "Epoch 425/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 188.6180 - val_loss: 1434.2688\n",
      "Epoch 426/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6180 - val_loss: 1434.2686\n",
      "Epoch 427/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2684\n",
      "Epoch 428/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2681\n",
      "Epoch 429/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2683\n",
      "Epoch 430/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 188.6180 - val_loss: 1434.2681\n",
      "Epoch 431/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2681\n",
      "Epoch 432/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2681\n",
      "Epoch 433/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2681\n",
      "Epoch 434/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2681\n",
      "Epoch 435/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2683\n",
      "Epoch 436/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2683\n",
      "Epoch 437/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2683\n",
      "Epoch 438/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2686\n",
      "Epoch 439/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6181 - val_loss: 1434.2690\n",
      "Epoch 440/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2690\n",
      "Epoch 441/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 188.6181 - val_loss: 1434.2694\n",
      "Epoch 442/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2700\n",
      "Epoch 443/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2700\n",
      "Epoch 444/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2705\n",
      "Epoch 445/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6180 - val_loss: 1434.2709\n",
      "Epoch 446/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2710\n",
      "Epoch 447/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6180 - val_loss: 1434.2710\n",
      "Epoch 448/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2710\n",
      "Epoch 449/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2710\n",
      "Epoch 450/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2710\n",
      "Epoch 451/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2710\n",
      "Epoch 452/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2710\n",
      "Epoch 453/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2709\n",
      "Epoch 454/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2706\n",
      "Epoch 455/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2704\n",
      "Epoch 456/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2699\n",
      "Epoch 457/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2700\n",
      "Epoch 458/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2697\n",
      "Epoch 459/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6180 - val_loss: 1434.2695\n",
      "Epoch 460/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2694\n",
      "Epoch 461/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2686\n",
      "Epoch 462/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 188.6181 - val_loss: 1434.2684\n",
      "Epoch 463/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6181 - val_loss: 1434.2684\n",
      "Epoch 464/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2684\n",
      "Epoch 465/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2681\n",
      "Epoch 466/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2683\n",
      "Epoch 467/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2683\n",
      "Epoch 468/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2683\n",
      "Epoch 469/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2683\n",
      "Epoch 470/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2683\n",
      "Epoch 471/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2683\n",
      "Epoch 472/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2683\n",
      "Epoch 473/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2683\n",
      "Epoch 474/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2683\n",
      "Epoch 475/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2683\n",
      "Epoch 476/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2683\n",
      "Epoch 477/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2683\n",
      "Epoch 478/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2683\n",
      "Epoch 479/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2683\n",
      "Epoch 480/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6182 - val_loss: 1434.2686\n",
      "Epoch 481/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2688\n",
      "Epoch 482/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2689\n",
      "Epoch 483/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 188.6181 - val_loss: 1434.2689\n",
      "Epoch 484/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.6181 - val_loss: 1434.2689\n",
      "Epoch 485/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6181 - val_loss: 1434.2689\n",
      "Epoch 486/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2686\n",
      "Epoch 487/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2686\n",
      "Epoch 488/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2686\n",
      "Epoch 489/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2686\n",
      "Epoch 490/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2684\n",
      "Epoch 491/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2681\n",
      "Epoch 492/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2681\n",
      "Epoch 493/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6182 - val_loss: 1434.2678\n",
      "Epoch 494/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2676\n",
      "Epoch 495/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2671\n",
      "Epoch 496/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6182 - val_loss: 1434.2670\n",
      "Epoch 497/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 188.6183 - val_loss: 1434.2670\n",
      "Epoch 498/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6183 - val_loss: 1434.2670\n",
      "Epoch 499/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6183 - val_loss: 1434.2670\n",
      "Epoch 500/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 188.6183 - val_loss: 1434.2670\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(85.7336, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0020, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0125, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3008, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 411ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.48063025e+01, 6.46540420e+01, 6.45037815e+01, 6.43525210e+01,\n",
       "        7.15446396e+01, 6.63190544e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.16340378e-01, 0.00000000e+00, 4.67840314e-01, 0.00000000e+00,\n",
       "        6.28426300e-02, 6.51712185e+01, 6.49443277e+01, 6.47782913e+01,\n",
       "        1.06690124e-01, 0.00000000e+00, 6.57174370e+01, 6.54905462e+01,\n",
       "        6.52636555e+01, 6.50367647e+01, 6.48399160e+01, 6.46886555e+01,\n",
       "        6.45367395e+01, 6.43861345e+01, 6.42565826e+01, 0.00000000e+00,\n",
       "        3.91087680e-02, 6.49023109e+01, 6.47502801e+01, 6.45990196e+01,\n",
       "        6.44477591e+01, 6.42976657e+01, 6.41968254e+01, 6.40959851e+01,\n",
       "        6.39951447e+01, 6.38829132e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.92862870e-02, 6.21114612e-01, 4.72869962e-01, 0.00000000e+00,\n",
       "        4.57607925e-01, 1.97039664e-01, 3.94975320e-02, 6.44197479e+01,\n",
       "        6.42789916e+01, 2.35125870e-01, 5.59358600e-01, 6.49527311e+01,\n",
       "        6.47838936e+01, 6.46326330e+01, 6.44813726e+01, 6.43301120e+01,\n",
       "        6.42192344e+01, 6.41183940e+01, 6.40175537e+01, 6.39167134e+01,\n",
       "        1.88807100e-01, 3.26987240e-01, 6.43917367e+01, 6.42603175e+01,\n",
       "        6.41594771e+01, 6.40586368e+01, 6.39577964e+01, 6.67063142e+01,\n",
       "        6.59869827e+01, 6.52972689e+01, 7.51617130e-01, 8.36256800e-02,\n",
       "        2.29679850e-01, 4.71513557e+01, 2.47511060e-01, 0.00000000e+00,\n",
       "        5.60107830e-01, 3.49309740e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.44304352e+01, 0.00000000e+00, 3.66888016e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.95783377e-01, 0.00000000e+00, 6.26665592e-01,\n",
       "        1.54029548e-01, 5.12148976e-01, 2.14294210e-01, 6.84244707e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.79634213e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56.1928059 , 56.18378766, 56.17476942, 56.16575118, 56.15673294,\n",
       "       56.1477147 , 56.13869645, 56.12967821, 56.12065997, 56.11164173,\n",
       "       56.10262349, 56.09360525, 56.08458701, 56.07556876, 56.06655052,\n",
       "       56.05753228, 56.04851404, 56.0394958 , 56.03047756, 56.02145932,\n",
       "       56.01244107, 56.00342283, 55.99440459, 55.98538635, 55.97636811,\n",
       "       55.96734987, 55.95833163, 55.94931338, 55.94029514, 55.9312769 ,\n",
       "       55.92225866, 55.91324042, 55.90422218, 55.89520394, 55.88618569,\n",
       "       55.87716745, 55.86814921, 55.85913097, 55.85011273, 55.84109449,\n",
       "       55.83207625, 55.823058  , 55.81403976, 55.80502152, 55.79600328,\n",
       "       55.78698504, 55.7779668 , 55.76894856, 55.75993031, 55.75091207,\n",
       "       55.74189383, 55.73287559, 55.72385735, 55.71483911, 55.70582086,\n",
       "       55.69680262, 55.68778438, 55.67876614, 55.6697479 , 55.66072966,\n",
       "       55.65171142, 55.64269317, 55.63367493, 55.62465669, 55.61563845,\n",
       "       55.60662021, 55.59760197, 55.58858373, 55.57956548, 55.57054724,\n",
       "       55.561529  , 55.55251076, 55.54349252, 55.53447428, 55.52545604,\n",
       "       55.51643779, 55.50741955, 55.49840131, 55.48938307, 55.48036483,\n",
       "       55.47134659, 55.46232835, 55.4533101 , 55.44429186, 55.43527362,\n",
       "       55.42625538, 55.41723714, 55.4082189 , 55.39920066, 55.39018241,\n",
       "       55.38116417, 55.37214593, 55.36312769, 55.35410945, 55.34509121,\n",
       "       55.33607297, 55.32705472, 55.31803648, 55.30901824, 55.3       ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.86062718644854\n",
      "33.59448687886574\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
