{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "1995    61.474265\n",
       "1996    61.447654\n",
       "1997    61.421043\n",
       "1998    61.394433\n",
       "1999    61.367822\n",
       "Name: C2, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c2_interpolated_1900_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "1895     0.000000\n",
       "1896     0.000000\n",
       "1897     0.506575\n",
       "1898     0.206388\n",
       "1899     0.150158\n",
       "Name: C2, Length: 1900, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1900)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.500000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.275910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.051821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.827731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.603641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     90.500000  0.000298\n",
       "1     90.275910  0.000298\n",
       "2     90.051821  0.000297\n",
       "3     89.827731  0.000297\n",
       "4     89.603641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.1552  # Value for C0\n",
    "K0 = -0.0026  # Value for K0\n",
    "K1 = -0.0004  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0102    # Value for b\n",
    "c = 2.8734    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    90.500000    90.275910    90.051821    89.827731    89.603641   \n",
      "351    90.275910    90.051821    89.827731    89.603641    89.379552   \n",
      "352    90.051821    89.827731    89.603641    89.379552    89.155462   \n",
      "353    89.827731    89.603641    89.379552    89.155462    88.931373   \n",
      "354    89.603641    89.379552    89.155462    88.931373    88.707283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.379552    89.155462    88.931373    88.707283    88.494958  ...   \n",
      "351    89.155462    88.931373    88.707283    88.494958    88.427731  ...   \n",
      "352    88.931373    88.707283    88.494958    88.427731    88.360504  ...   \n",
      "353    88.707283    88.494958    88.427731    88.360504    88.293277  ...   \n",
      "354    88.494958    88.427731    88.360504    88.293277    88.226050  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.071008    0.000263   79.054202    0.000263   79.037395    0.000263   \n",
      "351   79.054202    0.000263   79.037395    0.000263   79.020588    0.000262   \n",
      "352   79.037395    0.000263   79.020588    0.000262   79.003782    0.000262   \n",
      "353   79.020588    0.000262   79.003782    0.000262   78.986975    0.000262   \n",
      "354   79.003782    0.000262   78.986975    0.000262   78.970168    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.020588    0.000262   79.003782    0.000262  \n",
      "351   79.003782    0.000262   78.986975    0.000262  \n",
      "352   78.986975    0.000262   78.970168    0.000262  \n",
      "353   78.970168    0.000262   78.953361    0.000262  \n",
      "354   78.953361    0.000262   78.936555    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1450, 1, 251) (1450, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 2s 26ms/step - loss: 5492.3105 - val_loss: 3864.4014\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5422.4683 - val_loss: 3815.1443\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5353.6523 - val_loss: 3754.9082\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5275.1143 - val_loss: 3703.8267\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5197.1328 - val_loss: 3638.4111\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5114.9541 - val_loss: 3582.7424\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5041.5063 - val_loss: 3528.7627\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4959.4844 - val_loss: 3464.5100\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4881.9722 - val_loss: 3409.7068\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4808.8667 - val_loss: 3356.3997\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4737.4575 - val_loss: 3304.3044\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4667.4175 - val_loss: 3253.2239\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4598.5439 - val_loss: 3203.0417\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4530.7104 - val_loss: 3153.6812\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4463.8350 - val_loss: 3105.0920\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4397.8628 - val_loss: 3057.2349\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4332.7515 - val_loss: 3010.0833\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4268.4653 - val_loss: 2963.6123\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4204.9805 - val_loss: 2917.8035\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4142.2739 - val_loss: 2872.6409\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4080.3289 - val_loss: 2828.1118\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4019.1277 - val_loss: 2784.2024\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3958.6577 - val_loss: 2740.9028\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3898.9043 - val_loss: 2698.2036\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3839.8577 - val_loss: 2656.0947\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3781.5078 - val_loss: 2614.5684\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3723.8440 - val_loss: 2573.6172\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3666.8582 - val_loss: 2533.2334\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3610.5413 - val_loss: 2493.4102\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3554.8860 - val_loss: 2454.1406\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3499.8840 - val_loss: 2415.4187\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3445.5286 - val_loss: 2377.2383\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3391.8135 - val_loss: 2339.5940\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3338.7302 - val_loss: 2302.4790\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3286.2732 - val_loss: 2265.8887\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3234.4370 - val_loss: 2229.8167\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3183.2139 - val_loss: 2194.2595\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3132.6001 - val_loss: 2159.2104\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3082.5881 - val_loss: 2124.6655\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3033.1731 - val_loss: 2090.6187\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2984.3486 - val_loss: 2057.0657\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 2936.1106 - val_loss: 2024.0028\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2888.4526 - val_loss: 1991.4237\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2841.3701 - val_loss: 1959.3248\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2794.8574 - val_loss: 1927.7018\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2748.9106 - val_loss: 1896.5493\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2703.5229 - val_loss: 1865.8635\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2658.6907 - val_loss: 1835.6396\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2614.4089 - val_loss: 1805.8741\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2570.6736 - val_loss: 1776.5620\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2527.4778 - val_loss: 1747.7000\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2484.8188 - val_loss: 1719.2832\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2442.6924 - val_loss: 1691.3075\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2401.0920 - val_loss: 1663.7689\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2360.0146 - val_loss: 1636.6636\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2319.4551 - val_loss: 1609.9871\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2279.4089 - val_loss: 1583.7361\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2239.8723 - val_loss: 1557.9066\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2200.8408 - val_loss: 1532.4944\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2162.3098 - val_loss: 1507.4950\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2124.2751 - val_loss: 1482.9058\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2086.7327 - val_loss: 1458.7225\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2049.6782 - val_loss: 1434.9412\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2013.1080 - val_loss: 1411.5581\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1977.0168 - val_loss: 1388.5690\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1941.4015 - val_loss: 1365.9712\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1906.2576 - val_loss: 1343.7611\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1871.5822 - val_loss: 1321.9343\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1837.3696 - val_loss: 1300.4873\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1803.6167 - val_loss: 1279.4169\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1770.3196 - val_loss: 1258.7189\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1737.4745 - val_loss: 1238.3901\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1705.0768 - val_loss: 1218.4269\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1673.1233 - val_loss: 1198.8259\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1641.6101 - val_loss: 1179.5836\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1610.5333 - val_loss: 1160.6963\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1579.8890 - val_loss: 1142.1604\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1549.6727 - val_loss: 1123.9727\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1519.8821 - val_loss: 1106.1299\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1490.5127 - val_loss: 1088.6284\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1461.5613 - val_loss: 1071.4651\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1433.0243 - val_loss: 1054.6362\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1404.8973 - val_loss: 1038.1384\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1377.1765 - val_loss: 1021.9683\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1349.8590 - val_loss: 1006.1225\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1322.9409 - val_loss: 990.5977\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1296.4180 - val_loss: 975.3909\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1270.2874 - val_loss: 960.4984\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1244.5460 - val_loss: 945.9171\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1219.1897 - val_loss: 931.6442\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1194.2151 - val_loss: 917.6755\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1169.6185 - val_loss: 904.0083\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1145.3967 - val_loss: 890.6392\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1121.5459 - val_loss: 877.5650\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1098.0630 - val_loss: 864.7826\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1074.9442 - val_loss: 852.2887\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1052.1862 - val_loss: 840.0801\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1029.7856 - val_loss: 828.1534\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1007.7391 - val_loss: 816.5059\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 986.0439 - val_loss: 805.1342\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 964.6954 - val_loss: 794.0347\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 943.6906 - val_loss: 783.2053\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 923.0269 - val_loss: 772.6419\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 902.7003 - val_loss: 762.3419\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 882.7076 - val_loss: 752.3016\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 863.0455 - val_loss: 742.5186\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 843.7112 - val_loss: 732.9893\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 824.7009 - val_loss: 723.7109\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 806.0109 - val_loss: 714.6799\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 787.6384 - val_loss: 705.8940\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 769.5805 - val_loss: 697.3491\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 751.8334 - val_loss: 689.0432\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 734.3943 - val_loss: 680.9724\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 717.2596 - val_loss: 673.1342\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 700.4267 - val_loss: 665.5251\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 683.8917 - val_loss: 658.1423\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 667.6514 - val_loss: 650.9831\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 651.7032 - val_loss: 644.0436\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 636.0433 - val_loss: 637.3218\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 620.6693 - val_loss: 630.8141\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 605.5775 - val_loss: 624.5176\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 590.7648 - val_loss: 618.4295\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 576.2281 - val_loss: 612.5465\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 561.9644 - val_loss: 606.8658\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 547.9703 - val_loss: 601.3846\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 534.2430 - val_loss: 596.0997\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 520.7795 - val_loss: 591.0082\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 507.5765 - val_loss: 586.1072\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 494.6309 - val_loss: 581.3936\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 481.9397 - val_loss: 576.8649\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 469.4999 - val_loss: 572.5176\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 457.3081 - val_loss: 568.3491\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 445.3619 - val_loss: 564.3564\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 433.6577 - val_loss: 560.5367\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 422.1930 - val_loss: 556.8871\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 410.9642 - val_loss: 553.4045\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 399.9687 - val_loss: 550.0863\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 389.2032 - val_loss: 546.9293\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 378.6649 - val_loss: 543.9309\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 368.3507 - val_loss: 541.0883\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 358.2578 - val_loss: 538.3983\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 348.3830 - val_loss: 535.8582\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 338.7235 - val_loss: 533.4655\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 329.2764 - val_loss: 531.2169\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 320.0388 - val_loss: 529.1099\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 311.0081 - val_loss: 527.1418\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 302.1807 - val_loss: 525.3093\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 293.5540 - val_loss: 523.6100\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 285.1248 - val_loss: 522.0411\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 276.8908 - val_loss: 520.5997\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 268.8485 - val_loss: 519.2832\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 260.9958 - val_loss: 518.0888\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 253.3294 - val_loss: 517.0137\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 245.8465 - val_loss: 516.0552\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 238.5442 - val_loss: 515.2106\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 231.4197 - val_loss: 514.4773\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 224.4702 - val_loss: 513.8526\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 217.6929 - val_loss: 513.3337\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 211.0854 - val_loss: 512.9180\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 204.6447 - val_loss: 512.6030\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 198.3681 - val_loss: 512.3859\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 192.2523 - val_loss: 512.2641\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 186.2952 - val_loss: 512.2351\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 180.4939 - val_loss: 512.2962\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 174.8459 - val_loss: 512.4451\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.3483 - val_loss: 512.6788\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 163.9984 - val_loss: 512.9952\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 158.7937 - val_loss: 513.3916\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 153.7311 - val_loss: 513.8654\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 148.8085 - val_loss: 514.4142\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 144.0235 - val_loss: 515.0356\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 139.3729 - val_loss: 515.7272\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 134.8543 - val_loss: 516.4866\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 130.4651 - val_loss: 517.3113\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 126.2029 - val_loss: 518.1989\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 122.0653 - val_loss: 519.1470\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 118.0498 - val_loss: 520.1535\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 114.1537 - val_loss: 521.2159\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 110.3744 - val_loss: 522.3319\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 106.7100 - val_loss: 523.4993\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 103.1577 - val_loss: 524.7159\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 99.7150 - val_loss: 525.9796\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 96.3799 - val_loss: 527.2878\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 93.1498 - val_loss: 528.6387\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 90.0226 - val_loss: 530.0298\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 86.9958 - val_loss: 531.4595\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 84.0670 - val_loss: 532.9255\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 81.2339 - val_loss: 534.4254\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 78.4947 - val_loss: 535.9577\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 75.8466 - val_loss: 537.5201\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 73.2879 - val_loss: 539.1108\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 70.8161 - val_loss: 540.7278\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 68.4290 - val_loss: 542.3693\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 66.1246 - val_loss: 544.0333\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 63.9010 - val_loss: 545.7177\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 61.7561 - val_loss: 547.4209\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 59.6877 - val_loss: 549.1413\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 57.6937 - val_loss: 550.8773\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 55.7721 - val_loss: 552.6267\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 53.9212 - val_loss: 554.3882\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52.1388 - val_loss: 556.1602\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 50.4233 - val_loss: 557.9405\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 48.7725 - val_loss: 559.7285\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.1846 - val_loss: 561.5219\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 45.6580 - val_loss: 563.3193\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 44.1907 - val_loss: 565.1196\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 42.7811 - val_loss: 566.9209\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 41.4274 - val_loss: 568.7222\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 40.1279 - val_loss: 570.5219\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 38.8810 - val_loss: 572.3192\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 37.6848 - val_loss: 574.1124\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 36.5378 - val_loss: 575.9001\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 35.4386 - val_loss: 577.6815\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 34.3855 - val_loss: 579.4551\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33.3771 - val_loss: 581.2200\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 32.4118 - val_loss: 582.9748\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 31.4883 - val_loss: 584.7191\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.6049 - val_loss: 586.4513\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.7604 - val_loss: 588.1708\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 28.9534 - val_loss: 589.8766\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 28.1826 - val_loss: 591.5676\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 27.4466 - val_loss: 593.2431\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 26.7443 - val_loss: 594.9020\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 26.0744 - val_loss: 596.5443\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 25.4356 - val_loss: 598.1686\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 24.8267 - val_loss: 599.7744\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 24.2467 - val_loss: 601.3608\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 23.6943 - val_loss: 602.9276\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 23.1686 - val_loss: 604.4742\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 22.6684 - val_loss: 606.0000\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.1928 - val_loss: 607.5040\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.7407 - val_loss: 608.9865\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.3110 - val_loss: 610.4460\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.9032 - val_loss: 611.8830\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5160 - val_loss: 613.2972\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.1486 - val_loss: 614.6876\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.8002 - val_loss: 616.0541\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.4699 - val_loss: 617.3969\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.1569 - val_loss: 618.7150\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.8606 - val_loss: 620.0090\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.5800 - val_loss: 621.2783\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 18.3145 - val_loss: 622.5229\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.0634 - val_loss: 623.7422\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.8260 - val_loss: 624.9368\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.6016 - val_loss: 626.1060\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.3898 - val_loss: 627.2502\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.1897 - val_loss: 628.3693\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.0009 - val_loss: 629.4630\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.8228 - val_loss: 630.5316\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.6550 - val_loss: 631.5756\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.4967 - val_loss: 632.5946\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.3476 - val_loss: 633.5884\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.2072 - val_loss: 634.5581\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.0750 - val_loss: 635.5027\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.9506 - val_loss: 636.4234\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.8336 - val_loss: 637.3199\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.7236 - val_loss: 638.1923\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.6203 - val_loss: 639.0414\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.5231 - val_loss: 639.8668\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.4318 - val_loss: 640.6687\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.3463 - val_loss: 641.4480\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2659 - val_loss: 642.2041\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.1905 - val_loss: 642.9382\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.1198 - val_loss: 643.6503\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.0535 - val_loss: 644.3409\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.9913 - val_loss: 645.0099\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.9331 - val_loss: 645.6578\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.8785 - val_loss: 646.2852\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.8275 - val_loss: 646.8926\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.7796 - val_loss: 647.4799\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 14.7349 - val_loss: 648.0474\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6930 - val_loss: 648.5959\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6538 - val_loss: 649.1260\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6172 - val_loss: 649.6373\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5829 - val_loss: 650.1308\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5508 - val_loss: 650.6064\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.5209 - val_loss: 651.0648\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.4929 - val_loss: 651.5061\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.4668 - val_loss: 651.9313\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.4424 - val_loss: 652.3406\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.4196 - val_loss: 652.7345\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3982 - val_loss: 653.1130\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3783 - val_loss: 653.4766\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3598 - val_loss: 653.8260\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3424 - val_loss: 654.1614\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3262 - val_loss: 654.4835\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3111 - val_loss: 654.7916\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2970 - val_loss: 655.0872\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2838 - val_loss: 655.3702\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2716 - val_loss: 655.6418\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2601 - val_loss: 655.9019\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2494 - val_loss: 656.1496\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2394 - val_loss: 656.3871\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2301 - val_loss: 656.6136\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2215 - val_loss: 656.8302\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2133 - val_loss: 657.0366\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2059 - val_loss: 657.2336\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1988 - val_loss: 657.4216\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1923 - val_loss: 657.6006\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 14.1862 - val_loss: 657.7710\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.1805 - val_loss: 657.9337\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1752 - val_loss: 658.0880\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1703 - val_loss: 658.2347\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1657 - val_loss: 658.3747\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1615 - val_loss: 658.5073\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1575 - val_loss: 658.6328\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1539 - val_loss: 658.7525\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1504 - val_loss: 658.8653\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1472 - val_loss: 658.9724\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1443 - val_loss: 659.0737\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1416 - val_loss: 659.1702\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.1391 - val_loss: 659.2606\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1367 - val_loss: 659.3466\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1346 - val_loss: 659.4278\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1326 - val_loss: 659.5042\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1308 - val_loss: 659.5763\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1291 - val_loss: 659.6445\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1276 - val_loss: 659.7090\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.1261 - val_loss: 659.7695\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1248 - val_loss: 659.8260\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1237 - val_loss: 659.8798\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1226 - val_loss: 659.9304\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1216 - val_loss: 659.9776\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1207 - val_loss: 660.0219\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1199 - val_loss: 660.0630\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1192 - val_loss: 660.1022\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1186 - val_loss: 660.1390\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1180 - val_loss: 660.1731\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 14.1175 - val_loss: 660.2047\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1171 - val_loss: 660.2346\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1167 - val_loss: 660.2622\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1164 - val_loss: 660.2878\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1162 - val_loss: 660.3121\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1160 - val_loss: 660.3346\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1158 - val_loss: 660.3550\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1158 - val_loss: 660.3749\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1157 - val_loss: 660.3932\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.1156 - val_loss: 660.4095\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1156 - val_loss: 660.4250\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1157 - val_loss: 660.4392\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1157 - val_loss: 660.4517\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1159 - val_loss: 660.4639\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1159 - val_loss: 660.4745\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.1161 - val_loss: 660.4846\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1163 - val_loss: 660.4938\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1166 - val_loss: 660.5025\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1168 - val_loss: 660.5098\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1170 - val_loss: 660.5168\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1173 - val_loss: 660.5232\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1175 - val_loss: 660.5289\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.1179 - val_loss: 660.5346\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1182 - val_loss: 660.5392\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1185 - val_loss: 660.5430\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1189 - val_loss: 660.5469\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1192 - val_loss: 660.5500\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1196 - val_loss: 660.5531\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 14.1199 - val_loss: 660.5555\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.1203 - val_loss: 660.5582\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1207 - val_loss: 660.5599\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1211 - val_loss: 660.5616\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1215 - val_loss: 660.5630\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.1219 - val_loss: 660.5638\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1223 - val_loss: 660.5646\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1228 - val_loss: 660.5653\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1232 - val_loss: 660.5656\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1237 - val_loss: 660.5659\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1241 - val_loss: 660.5659\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1245 - val_loss: 660.5659\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1250 - val_loss: 660.5659\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1254 - val_loss: 660.5654\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1259 - val_loss: 660.5650\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1263 - val_loss: 660.5645\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1267 - val_loss: 660.5636\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1272 - val_loss: 660.5628\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1276 - val_loss: 660.5617\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1281 - val_loss: 660.5607\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1286 - val_loss: 660.5599\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1290 - val_loss: 660.5589\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1295 - val_loss: 660.5580\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1299 - val_loss: 660.5569\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1304 - val_loss: 660.5556\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1309 - val_loss: 660.5547\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 14.1313 - val_loss: 660.5533\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1317 - val_loss: 660.5519\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1322 - val_loss: 660.5502\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1326 - val_loss: 660.5492\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.1330 - val_loss: 660.5474\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1335 - val_loss: 660.5463\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1339 - val_loss: 660.5448\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1344 - val_loss: 660.5432\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1348 - val_loss: 660.5416\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1353 - val_loss: 660.5402\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1357 - val_loss: 660.5388\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1361 - val_loss: 660.5370\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1366 - val_loss: 660.5354\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1370 - val_loss: 660.5345\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1374 - val_loss: 660.5328\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1378 - val_loss: 660.5312\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1382 - val_loss: 660.5296\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1387 - val_loss: 660.5278\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1391 - val_loss: 660.5264\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1395 - val_loss: 660.5245\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1399 - val_loss: 660.5228\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1404 - val_loss: 660.5214\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1407 - val_loss: 660.5200\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 14.1411 - val_loss: 660.5184\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1416 - val_loss: 660.5170\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1419 - val_loss: 660.5153\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1424 - val_loss: 660.5140\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1427 - val_loss: 660.5123\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1432 - val_loss: 660.5112\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1435 - val_loss: 660.5099\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1439 - val_loss: 660.5086\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1443 - val_loss: 660.5076\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1446 - val_loss: 660.5062\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1450 - val_loss: 660.5049\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1454 - val_loss: 660.5035\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1457 - val_loss: 660.5021\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1461 - val_loss: 660.5008\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1464 - val_loss: 660.4991\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1468 - val_loss: 660.4983\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1471 - val_loss: 660.4969\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1475 - val_loss: 660.4960\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1478 - val_loss: 660.4944\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1481 - val_loss: 660.4929\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1485 - val_loss: 660.4920\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1488 - val_loss: 660.4906\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1491 - val_loss: 660.4892\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1495 - val_loss: 660.4882\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1498 - val_loss: 660.4866\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1501 - val_loss: 660.4859\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.1504 - val_loss: 660.4848\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1507 - val_loss: 660.4834\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1510 - val_loss: 660.4824\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 14.1513 - val_loss: 660.4813\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1516 - val_loss: 660.4801\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1519 - val_loss: 660.4789\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1522 - val_loss: 660.4776\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.1526 - val_loss: 660.4769\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1528 - val_loss: 660.4754\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1531 - val_loss: 660.4744\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1534 - val_loss: 660.4734\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1536 - val_loss: 660.4723\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1539 - val_loss: 660.4714\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1542 - val_loss: 660.4703\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1545 - val_loss: 660.4694\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1547 - val_loss: 660.4678\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1550 - val_loss: 660.4665\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.1553 - val_loss: 660.4653\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1556 - val_loss: 660.4648\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1558 - val_loss: 660.4642\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1560 - val_loss: 660.4629\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1563 - val_loss: 660.4624\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1565 - val_loss: 660.4612\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1567 - val_loss: 660.4604\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1569 - val_loss: 660.4593\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1572 - val_loss: 660.4584\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1574 - val_loss: 660.4579\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1576 - val_loss: 660.4570\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1578 - val_loss: 660.4556\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 14.1581 - val_loss: 660.4547\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1583 - val_loss: 660.4538\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1585 - val_loss: 660.4532\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1587 - val_loss: 660.4525\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1589 - val_loss: 660.4520\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1591 - val_loss: 660.4510\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1593 - val_loss: 660.4506\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1595 - val_loss: 660.4497\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1597 - val_loss: 660.4489\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1599 - val_loss: 660.4481\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1601 - val_loss: 660.4474\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1603 - val_loss: 660.4465\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1605 - val_loss: 660.4459\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1607 - val_loss: 660.4451\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1609 - val_loss: 660.4445\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1610 - val_loss: 660.4437\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1612 - val_loss: 660.4431\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1613 - val_loss: 660.4420\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.1616 - val_loss: 660.4417\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1617 - val_loss: 660.4409\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1619 - val_loss: 660.4401\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.1621 - val_loss: 660.4398\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1622 - val_loss: 660.4392\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1624 - val_loss: 660.4387\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.1625 - val_loss: 660.4382\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1626 - val_loss: 660.4376\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1628 - val_loss: 660.4371\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1630 - val_loss: 660.4361\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1631 - val_loss: 660.4354\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1632 - val_loss: 660.4351\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1634 - val_loss: 660.4348\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1635 - val_loss: 660.4341\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1636 - val_loss: 660.4329\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1638 - val_loss: 660.4326\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1640 - val_loss: 660.4322\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1641 - val_loss: 660.4315\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.1642 - val_loss: 660.4312\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.1643 - val_loss: 660.4305\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.1645 - val_loss: 660.4301\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.1646 - val_loss: 660.4295\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.1552, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0026, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0004, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0102, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.8734, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 324ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.87403361e+01, 6.86955182e+01, 6.86507003e+01, 6.86058824e+01,\n",
       "        6.85610644e+01, 6.85162465e+01, 6.84714286e+01, 6.84266106e+01,\n",
       "        6.83817927e+01, 6.83369748e+01, 6.82975490e+01, 6.82835434e+01,\n",
       "        6.82695378e+01, 6.40200747e+01, 6.39482026e+01, 6.38893791e+01,\n",
       "        6.38305556e+01, 6.37717320e+01, 6.37129085e+01, 6.36540850e+01,\n",
       "        6.35952614e+01, 6.35364379e+01, 6.34776144e+01, 6.34187909e+01,\n",
       "        6.33599673e+01, 6.33011438e+01, 6.32258403e+01, 6.31502101e+01,\n",
       "        6.30745798e+01, 6.29989496e+01, 6.29233193e+01, 6.28476891e+01,\n",
       "        6.27720588e+01, 6.26964286e+01, 6.26207983e+01, 6.25451681e+01,\n",
       "        6.24695378e+01, 6.23993231e+01, 6.23909197e+01, 6.23825163e+01,\n",
       "        0.00000000e+00, 2.04218550e-01, 6.10286120e-01, 2.83368770e-01,\n",
       "        2.70685550e-01, 0.00000000e+00, 2.27903160e-01, 7.09064986e+01,\n",
       "        7.08808823e+01, 7.08556723e+01, 7.08304622e+01, 7.08052521e+01,\n",
       "        7.07800420e+01, 7.07548319e+01, 7.07296219e+01, 7.07044118e+01,\n",
       "        7.06792017e+01, 7.06539916e+01, 7.06287815e+01, 7.06035714e+01,\n",
       "        7.05495098e+01, 7.04906863e+01, 7.04318627e+01, 7.03730392e+01,\n",
       "        7.03142157e+01, 7.02553922e+01, 7.01965686e+01, 7.01377451e+01,\n",
       "        7.00789216e+01, 7.00200980e+01, 6.99612745e+01, 6.99024510e+01,\n",
       "        6.97711485e+01, 7.57085190e+01, 1.18381113e-01, 9.45959151e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.86436070e-02,\n",
       "        5.33801384e+01, 1.49050057e-01, 0.00000000e+00, 2.16671780e-01,\n",
       "        2.55974114e-01, 3.50399256e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.01462406e-01, 0.00000000e+00, 6.80849791e-01, 4.23700124e-01,\n",
       "        5.59692264e-01, 1.21249773e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63.9405929 , 63.91725023, 63.89390756, 63.87056489, 63.84722222,\n",
       "       63.82387955, 63.80053688, 63.77719421, 63.75385154, 63.73050887,\n",
       "       63.7071662 , 63.68382353, 63.66048086, 63.63713819, 63.61379552,\n",
       "       63.59045285, 63.56711018, 63.54376751, 63.52042484, 63.49667367,\n",
       "       63.47006303, 63.44345238, 63.41684174, 63.39023109, 63.36362045,\n",
       "       63.3370098 , 63.31039916, 63.28378852, 63.25717787, 63.23056723,\n",
       "       63.20395658, 63.17734594, 63.15073529, 63.12412465, 63.09751401,\n",
       "       63.07090336, 63.04429272, 63.01768207, 62.99107143, 62.96446078,\n",
       "       62.93785014, 62.9112395 , 62.88462885, 62.85801821, 62.83140756,\n",
       "       62.80479692, 62.77818627, 62.75157563, 62.72496499, 62.69835434,\n",
       "       62.6717437 , 62.64513305, 62.61852241, 62.59191176, 62.56530112,\n",
       "       62.53869048, 62.51207983, 62.48546919, 62.45885854, 62.4322479 ,\n",
       "       62.40563725, 62.37902661, 62.35241597, 62.32580532, 62.29919468,\n",
       "       62.27258403, 62.24597339, 62.21936275, 62.1927521 , 62.16614146,\n",
       "       62.13953081, 62.11292017, 62.08630952, 62.05969888, 62.03308824,\n",
       "       62.00647759, 61.97986695, 61.9532563 , 61.92664566, 61.90003501,\n",
       "       61.87342437, 61.84681373, 61.82020308, 61.79359244, 61.76698179,\n",
       "       61.74037115, 61.7137605 , 61.68714986, 61.66053922, 61.63392857,\n",
       "       61.60731793, 61.58070728, 61.55409664, 61.52748599, 61.50087535,\n",
       "       61.47426471, 61.44765406, 61.42104342, 61.39443277, 61.36782213])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.25858142948999\n",
      "22.764632721086738\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
