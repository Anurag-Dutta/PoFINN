{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "2395    53.720004\n",
       "2396    53.704427\n",
       "2397    53.688850\n",
       "2398    53.673273\n",
       "2399    53.657696\n",
       "Name: C2, Length: 2400, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c2_interpolated_2300_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "2295     0.273064\n",
       "2296     0.000000\n",
       "2297     0.139488\n",
       "2298     0.000000\n",
       "2299     0.000000\n",
       "Name: C2, Length: 2300, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2300)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.500000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.275910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.051821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.827731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.603641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     90.500000  0.000298\n",
       "1     90.275910  0.000298\n",
       "2     90.051821  0.000297\n",
       "3     89.827731  0.000297\n",
       "4     89.603641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.1552  # Value for C0\n",
    "K0 = -0.0026  # Value for K0\n",
    "K1 = -0.0004  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0102    # Value for b\n",
    "c = 2.8734    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    90.500000    90.275910    90.051821    89.827731    89.603641   \n",
      "351    90.275910    90.051821    89.827731    89.603641    89.379552   \n",
      "352    90.051821    89.827731    89.603641    89.379552    89.155462   \n",
      "353    89.827731    89.603641    89.379552    89.155462    88.931373   \n",
      "354    89.603641    89.379552    89.155462    88.931373    88.707283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.379552    89.155462    88.931373    88.707283    88.494958  ...   \n",
      "351    89.155462    88.931373    88.707283    88.494958    88.427731  ...   \n",
      "352    88.931373    88.707283    88.494958    88.427731    88.360504  ...   \n",
      "353    88.707283    88.494958    88.427731    88.360504    88.293277  ...   \n",
      "354    88.494958    88.427731    88.360504    88.293277    88.226050  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.071008    0.000263   79.054202    0.000263   79.037395    0.000263   \n",
      "351   79.054202    0.000263   79.037395    0.000263   79.020588    0.000262   \n",
      "352   79.037395    0.000263   79.020588    0.000262   79.003782    0.000262   \n",
      "353   79.020588    0.000262   79.003782    0.000262   78.986975    0.000262   \n",
      "354   79.003782    0.000262   78.986975    0.000262   78.970168    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.020588    0.000262   79.003782    0.000262  \n",
      "351   79.003782    0.000262   78.986975    0.000262  \n",
      "352   78.986975    0.000262   78.970168    0.000262  \n",
      "353   78.970168    0.000262   78.953361    0.000262  \n",
      "354   78.953361    0.000262   78.936555    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1850, 1, 251) (1850, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 2s 20ms/step - loss: 5107.8657 - val_loss: 3037.5212\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4868.8682 - val_loss: 2900.9631\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4729.5566 - val_loss: 2826.4521\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4629.5698 - val_loss: 2767.0540\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4534.5981 - val_loss: 2709.2195\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4442.7754 - val_loss: 2655.1995\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 4353.3413 - val_loss: 2601.8708\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4265.9126 - val_loss: 2549.9871\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4180.2666 - val_loss: 2499.4202\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4096.2617 - val_loss: 2450.1008\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4013.7983 - val_loss: 2401.9712\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3932.8071 - val_loss: 2355.5042\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3853.2290 - val_loss: 2309.1487\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3775.0210 - val_loss: 2264.3682\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3698.1445 - val_loss: 2220.6438\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3622.5684 - val_loss: 2177.9534\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3548.2634 - val_loss: 2136.2761\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3475.2036 - val_loss: 2095.5935\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3403.3677 - val_loss: 2055.8872\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3332.7341 - val_loss: 2017.1409\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3263.2832 - val_loss: 1979.3385\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3194.9954 - val_loss: 1942.4648\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3127.8533 - val_loss: 1906.5065\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 3061.8408 - val_loss: 1871.4486\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2996.9421 - val_loss: 1837.2799\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2933.1411 - val_loss: 1804.0017\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2870.4229 - val_loss: 1768.9678\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2791.7202 - val_loss: 1728.5885\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2724.1196 - val_loss: 1694.7693\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2659.2437 - val_loss: 1662.6022\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2596.5774 - val_loss: 1631.7567\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2535.6724 - val_loss: 1602.0594\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2476.2903 - val_loss: 1573.4111\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2418.2910 - val_loss: 1545.7449\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2361.5813 - val_loss: 1519.0138\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2306.0940 - val_loss: 1493.1805\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2251.7771 - val_loss: 1468.2140\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2198.5891 - val_loss: 1444.0894\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2146.4949 - val_loss: 1420.7830\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2095.4651 - val_loss: 1398.2749\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2045.4723 - val_loss: 1376.5465\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1996.4939 - val_loss: 1355.5806\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1948.5081 - val_loss: 1335.3608\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1901.4946 - val_loss: 1315.8715\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1855.4341 - val_loss: 1297.1012\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1810.3060 - val_loss: 1278.8184\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1762.9662 - val_loss: 1259.3219\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1715.0443 - val_loss: 1240.8999\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1668.5023 - val_loss: 1223.4845\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1623.5558 - val_loss: 1207.1460\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1580.0032 - val_loss: 1191.5575\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1537.7054 - val_loss: 1176.7677\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1496.5659 - val_loss: 1162.7351\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1456.5157 - val_loss: 1149.4257\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1417.5012 - val_loss: 1136.8124\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1379.4790 - val_loss: 1124.8707\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1342.4121 - val_loss: 1113.5795\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1306.2700 - val_loss: 1102.9189\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1271.0247 - val_loss: 1092.8713\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1236.6515 - val_loss: 1083.4197\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1203.1278 - val_loss: 1074.5481\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1170.4329 - val_loss: 1066.2419\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1138.5474 - val_loss: 1058.4865\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1107.4532 - val_loss: 1051.2679\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1077.1327 - val_loss: 1044.5726\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1047.5703 - val_loss: 1038.3877\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1018.7498 - val_loss: 1032.7006\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 990.6562 - val_loss: 1027.4988\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 963.2755 - val_loss: 1022.7702\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 936.5930 - val_loss: 1018.5032\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 910.5955 - val_loss: 1014.6857\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 885.2698 - val_loss: 1011.3065\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 860.6030 - val_loss: 1008.3544\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 836.5827 - val_loss: 1005.8182\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 813.1963 - val_loss: 1003.6870\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 790.4318 - val_loss: 1001.9500\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 768.2778 - val_loss: 1000.5966\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 746.7223 - val_loss: 999.6163\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 725.7540 - val_loss: 998.9987\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 705.3617 - val_loss: 998.7332\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 685.5346 - val_loss: 998.8099\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 666.2616 - val_loss: 999.2188\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 647.5318 - val_loss: 999.9499\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 629.3351 - val_loss: 1000.9932\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 611.6609 - val_loss: 1002.3391\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 594.4988 - val_loss: 1003.9775\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 577.8386 - val_loss: 1005.8994\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 561.6703 - val_loss: 1008.0948\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 545.9843 - val_loss: 1010.5544\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 530.7703 - val_loss: 1013.2693\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 516.0189 - val_loss: 1016.2297\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 501.7204 - val_loss: 1019.4265\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 487.8654 - val_loss: 1022.8510\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 474.4441 - val_loss: 1026.4939\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 461.4476 - val_loss: 1030.3467\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 448.8667 - val_loss: 1034.4001\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 436.6922 - val_loss: 1038.6458\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 424.9151 - val_loss: 1043.0748\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.5265 - val_loss: 1047.6788\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 402.5174 - val_loss: 1052.4495\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 391.8792 - val_loss: 1057.3782\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 381.6034 - val_loss: 1062.4569\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 371.6812 - val_loss: 1067.6774\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 362.1045 - val_loss: 1073.0316\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 352.8647 - val_loss: 1078.5115\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 343.9533 - val_loss: 1084.1095\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 335.3625 - val_loss: 1089.8173\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 327.0842 - val_loss: 1095.6279\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 319.1102 - val_loss: 1101.5334\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 311.4326 - val_loss: 1107.5265\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 304.0437 - val_loss: 1113.5997\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 296.9358 - val_loss: 1119.7461\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 290.1013 - val_loss: 1125.9584\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 283.5326 - val_loss: 1132.2296\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 277.2225 - val_loss: 1138.5531\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 271.1633 - val_loss: 1144.9220\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 265.3481 - val_loss: 1151.3298\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 259.7697 - val_loss: 1157.7703\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 254.4212 - val_loss: 1164.2365\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 249.2955 - val_loss: 1170.7222\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 244.3861 - val_loss: 1177.2220\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 239.6858 - val_loss: 1183.7297\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 235.1885 - val_loss: 1190.2395\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 230.8875 - val_loss: 1196.7460\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 226.7766 - val_loss: 1203.2433\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 222.8493 - val_loss: 1209.7264\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 219.0996 - val_loss: 1216.1898\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 215.5214 - val_loss: 1222.6288\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 212.1088 - val_loss: 1229.0382\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 208.8560 - val_loss: 1235.4138\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 205.7573 - val_loss: 1241.7505\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 202.8073 - val_loss: 1248.0441\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 200.0002 - val_loss: 1254.2906\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 197.3308 - val_loss: 1260.4855\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 194.7940 - val_loss: 1266.6255\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 192.3845 - val_loss: 1272.7059\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 190.0976 - val_loss: 1278.7244\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 187.9282 - val_loss: 1284.6765\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 185.8715 - val_loss: 1290.5594\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 183.9231 - val_loss: 1296.3698\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 182.0785 - val_loss: 1302.1050\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 180.3331 - val_loss: 1307.7617\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 178.6829 - val_loss: 1313.3381\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 177.1235 - val_loss: 1318.8311\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 175.6512 - val_loss: 1324.2389\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 174.2617 - val_loss: 1329.5596\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 172.9515 - val_loss: 1334.7910\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 171.7168 - val_loss: 1339.9310\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 170.5541 - val_loss: 1344.9788\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 169.4600 - val_loss: 1349.9321\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 168.4311 - val_loss: 1354.7897\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 167.4643 - val_loss: 1359.5515\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 166.5563 - val_loss: 1364.2156\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 165.7043 - val_loss: 1368.7806\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 164.9054 - val_loss: 1373.2478\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 164.1568 - val_loss: 1377.6149\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 163.4559 - val_loss: 1381.8818\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 162.8000 - val_loss: 1386.0492\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 162.1867 - val_loss: 1390.1155\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6138 - val_loss: 1394.0814\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.0789 - val_loss: 1397.9475\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 160.5799 - val_loss: 1401.7133\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 160.1147 - val_loss: 1405.3794\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 159.6813 - val_loss: 1408.9464\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 159.2778 - val_loss: 1412.4148\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 158.9026 - val_loss: 1415.7858\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 158.5538 - val_loss: 1419.0591\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 158.2298 - val_loss: 1422.2362\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 157.9291 - val_loss: 1425.3177\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 157.6503 - val_loss: 1428.3054\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.3919 - val_loss: 1431.2006\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.1525 - val_loss: 1434.0027\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 156.9311 - val_loss: 1436.7157\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 156.7262 - val_loss: 1439.3384\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 156.5369 - val_loss: 1441.8740\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 156.3621 - val_loss: 1444.3236\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 156.2009 - val_loss: 1446.6879\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 156.0520 - val_loss: 1448.9695\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 155.9150 - val_loss: 1451.1685\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 155.7888 - val_loss: 1453.2891\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 155.6726 - val_loss: 1455.3309\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 155.5658 - val_loss: 1457.2959\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 155.4675 - val_loss: 1459.1865\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 155.3774 - val_loss: 1461.0045\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 155.2946 - val_loss: 1462.7513\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 155.2187 - val_loss: 1464.4286\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 155.1491 - val_loss: 1466.0382\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 155.0853 - val_loss: 1467.5823\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 155.0269 - val_loss: 1469.0620\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.9735 - val_loss: 1470.4797\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.9247 - val_loss: 1471.8376\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.8800 - val_loss: 1473.1370\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.8392 - val_loss: 1474.3795\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.8020 - val_loss: 1475.5673\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.7681 - val_loss: 1476.7020\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.7371 - val_loss: 1477.7855\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.7089 - val_loss: 1478.8196\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.6832 - val_loss: 1479.8058\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.6597 - val_loss: 1480.7452\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.6384 - val_loss: 1481.6405\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.6191 - val_loss: 1482.4933\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.6014 - val_loss: 1483.3037\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5855 - val_loss: 1484.0750\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5710 - val_loss: 1484.8085\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5578 - val_loss: 1485.5044\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5458 - val_loss: 1486.1652\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5351 - val_loss: 1486.7931\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5253 - val_loss: 1487.3878\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5164 - val_loss: 1487.9519\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.5084 - val_loss: 1488.4863\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5012 - val_loss: 1488.9921\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4947 - val_loss: 1489.4702\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4889 - val_loss: 1489.9229\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4836 - val_loss: 1490.3507\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4789 - val_loss: 1490.7559\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 154.4745 - val_loss: 1491.1377\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4708 - val_loss: 1491.4969\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4675 - val_loss: 1491.8373\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4644 - val_loss: 1492.1583\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4617 - val_loss: 1492.4595\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4594 - val_loss: 1492.7438\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4573 - val_loss: 1493.0116\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4554 - val_loss: 1493.2635\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4538 - val_loss: 1493.5001\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4525 - val_loss: 1493.7222\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4512 - val_loss: 1493.9309\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4503 - val_loss: 1494.1273\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4495 - val_loss: 1494.3115\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4487 - val_loss: 1494.3993\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.2038 - val_loss: 1492.0604\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5241 - val_loss: 1492.3685\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5142 - val_loss: 1492.7306\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5041 - val_loss: 1493.0564\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4970 - val_loss: 1493.3500\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4918 - val_loss: 1493.6163\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4878 - val_loss: 1493.8608\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4845 - val_loss: 1494.0854\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4818 - val_loss: 1494.2922\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4796 - val_loss: 1494.4829\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4778 - val_loss: 1494.6598\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4762 - val_loss: 1494.8226\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4749 - val_loss: 1494.9727\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 154.4740 - val_loss: 1495.1119\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4729 - val_loss: 1495.2395\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4724 - val_loss: 1495.3586\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4718 - val_loss: 1495.4688\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4714 - val_loss: 1495.5699\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4710 - val_loss: 1495.6633\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4709 - val_loss: 1495.7500\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4707 - val_loss: 1495.8297\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4707 - val_loss: 1495.9033\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 154.4707 - val_loss: 1495.9713\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4709 - val_loss: 1496.0338\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4710 - val_loss: 1496.0923\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4711 - val_loss: 1496.1453\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4714 - val_loss: 1496.1941\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4717 - val_loss: 1496.2394\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4721 - val_loss: 1496.2809\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4724 - val_loss: 1496.3186\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4727 - val_loss: 1496.3534\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4732 - val_loss: 1496.3859\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4737 - val_loss: 1496.4159\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4741 - val_loss: 1496.4431\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.4745 - val_loss: 1496.4679\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4751 - val_loss: 1496.4908\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4755 - val_loss: 1496.5114\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4760 - val_loss: 1496.5308\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4765 - val_loss: 1496.5487\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 154.4771 - val_loss: 1496.5656\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 154.4776 - val_loss: 1496.5804\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4781 - val_loss: 1496.5933\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4786 - val_loss: 1496.6056\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4792 - val_loss: 1496.6169\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4798 - val_loss: 1496.6277\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4803 - val_loss: 1496.6372\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4808 - val_loss: 1496.6454\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4814 - val_loss: 1496.6536\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4819 - val_loss: 1496.6603\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4824 - val_loss: 1496.6663\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4830 - val_loss: 1496.6718\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4835 - val_loss: 1496.6766\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4840 - val_loss: 1496.6818\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4845 - val_loss: 1496.6854\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4849 - val_loss: 1496.6888\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4856 - val_loss: 1496.6919\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4860 - val_loss: 1496.6951\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4865 - val_loss: 1496.6978\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4870 - val_loss: 1496.6993\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4875 - val_loss: 1496.7017\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4880 - val_loss: 1496.7037\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4885 - val_loss: 1496.7050\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4890 - val_loss: 1496.7059\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4894 - val_loss: 1496.7076\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4899 - val_loss: 1496.7081\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4904 - val_loss: 1496.7096\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4908 - val_loss: 1496.7103\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4912 - val_loss: 1496.7113\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 154.4915 - val_loss: 1496.7112\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4921 - val_loss: 1496.7122\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4925 - val_loss: 1496.7125\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4928 - val_loss: 1496.7122\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4933 - val_loss: 1496.7123\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4936 - val_loss: 1496.7120\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4940 - val_loss: 1496.7120\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4944 - val_loss: 1496.7120\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4949 - val_loss: 1496.7118\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4951 - val_loss: 1496.7117\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4955 - val_loss: 1496.7113\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4959 - val_loss: 1496.7114\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4962 - val_loss: 1496.7112\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4966 - val_loss: 1496.7112\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4969 - val_loss: 1496.7108\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4972 - val_loss: 1496.7096\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4976 - val_loss: 1496.7098\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4979 - val_loss: 1496.7091\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4982 - val_loss: 1496.7090\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4985 - val_loss: 1496.7086\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4988 - val_loss: 1496.7085\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4991 - val_loss: 1496.7081\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4994 - val_loss: 1496.7076\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4996 - val_loss: 1496.7065\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.4999 - val_loss: 1496.7065\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 154.5002 - val_loss: 1496.7061\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5004 - val_loss: 1496.7051\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5008 - val_loss: 1496.7054\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5009 - val_loss: 1496.7042\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5013 - val_loss: 1496.7037\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5015 - val_loss: 1496.7037\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5018 - val_loss: 1496.7035\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5020 - val_loss: 1496.7035\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5022 - val_loss: 1496.7029\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5024 - val_loss: 1496.7021\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5026 - val_loss: 1496.7017\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5028 - val_loss: 1496.7013\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5030 - val_loss: 1496.7007\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5032 - val_loss: 1496.7006\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5035 - val_loss: 1496.7000\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5036 - val_loss: 1496.6998\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5038 - val_loss: 1496.6991\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5040 - val_loss: 1496.6978\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5042 - val_loss: 1496.6984\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5044 - val_loss: 1496.6976\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5045 - val_loss: 1496.6973\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5048 - val_loss: 1496.6968\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5049 - val_loss: 1496.6959\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5050 - val_loss: 1496.6956\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5052 - val_loss: 1496.6946\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 154.5054 - val_loss: 1496.6942\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 154.5055 - val_loss: 1496.6941\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5057 - val_loss: 1496.6941\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.5058 - val_loss: 1496.6937\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5060 - val_loss: 1496.6934\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5062 - val_loss: 1496.6929\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5063 - val_loss: 1496.6926\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5065 - val_loss: 1496.6926\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5065 - val_loss: 1496.6918\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5067 - val_loss: 1496.6915\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5067 - val_loss: 1496.6909\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5069 - val_loss: 1496.6907\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5070 - val_loss: 1496.6906\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5071 - val_loss: 1496.6906\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.5072 - val_loss: 1496.6898\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.5074 - val_loss: 1496.6898\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5075 - val_loss: 1496.6898\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5076 - val_loss: 1496.6896\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5077 - val_loss: 1496.6893\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5078 - val_loss: 1496.6888\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5079 - val_loss: 1496.6882\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5080 - val_loss: 1496.6882\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5081 - val_loss: 1496.6885\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5082 - val_loss: 1496.6875\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 154.5083 - val_loss: 1496.6871\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5084 - val_loss: 1496.6871\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5084 - val_loss: 1496.6868\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5085 - val_loss: 1496.6860\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5087 - val_loss: 1496.6863\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5087 - val_loss: 1496.6862\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5088 - val_loss: 1496.6854\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5088 - val_loss: 1496.6852\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5089 - val_loss: 1496.6848\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5090 - val_loss: 1496.6844\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5091 - val_loss: 1496.6843\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5092 - val_loss: 1496.6843\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5092 - val_loss: 1496.6841\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.5093 - val_loss: 1496.6841\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5093 - val_loss: 1496.6838\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5094 - val_loss: 1496.6838\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5095 - val_loss: 1496.6836\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5096 - val_loss: 1496.6840\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5096 - val_loss: 1496.6840\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5096 - val_loss: 1496.6838\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5096 - val_loss: 1496.6827\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5097 - val_loss: 1496.6816\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5098 - val_loss: 1496.6808\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5098 - val_loss: 1496.6797\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 154.5099 - val_loss: 1496.6794\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5100 - val_loss: 1496.6794\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5100 - val_loss: 1496.6794\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5101 - val_loss: 1496.6801\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5101 - val_loss: 1496.6797\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5102 - val_loss: 1496.6801\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5103 - val_loss: 1496.6804\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5103 - val_loss: 1496.6802\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5104 - val_loss: 1496.6799\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5104 - val_loss: 1496.6799\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5104 - val_loss: 1496.6799\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5105 - val_loss: 1496.6794\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5105 - val_loss: 1496.6791\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5106 - val_loss: 1496.6786\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5105 - val_loss: 1496.6781\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5107 - val_loss: 1496.6781\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5107 - val_loss: 1496.6781\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5106 - val_loss: 1496.6772\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5107 - val_loss: 1496.6766\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5107 - val_loss: 1496.6766\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5108 - val_loss: 1496.6765\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5108 - val_loss: 1496.6765\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5108 - val_loss: 1496.6761\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5109 - val_loss: 1496.6764\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 154.5110 - val_loss: 1496.6769\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5110 - val_loss: 1496.6774\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5110 - val_loss: 1496.6777\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5110 - val_loss: 1496.6781\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5111 - val_loss: 1496.6782\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5110 - val_loss: 1496.6781\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5111 - val_loss: 1496.6781\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5111 - val_loss: 1496.6779\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5111 - val_loss: 1496.6775\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5111 - val_loss: 1496.6774\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5112 - val_loss: 1496.6772\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5112 - val_loss: 1496.6772\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5112 - val_loss: 1496.6765\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5112 - val_loss: 1496.6752\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5112 - val_loss: 1496.6748\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5113 - val_loss: 1496.6742\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5113 - val_loss: 1496.6740\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5114 - val_loss: 1496.6743\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 154.5114 - val_loss: 1496.6747\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5115 - val_loss: 1496.6750\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5115 - val_loss: 1496.6759\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5114 - val_loss: 1496.6760\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.5114 - val_loss: 1496.6761\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 154.5114 - val_loss: 1496.6761\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5114 - val_loss: 1496.6764\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5114 - val_loss: 1496.6761\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5115 - val_loss: 1496.6755\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5114 - val_loss: 1496.6752\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5115 - val_loss: 1496.6747\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5115 - val_loss: 1496.6743\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5115 - val_loss: 1496.6738\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5115 - val_loss: 1496.6730\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5115 - val_loss: 1496.6721\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5115 - val_loss: 1496.6716\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5116 - val_loss: 1496.6713\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5116 - val_loss: 1496.6708\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5116 - val_loss: 1496.6704\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5117 - val_loss: 1496.6703\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5116 - val_loss: 1496.6700\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5118 - val_loss: 1496.6700\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5117 - val_loss: 1496.6700\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5117 - val_loss: 1496.6699\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5117 - val_loss: 1496.6696\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5117 - val_loss: 1496.6689\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5117 - val_loss: 1496.6687\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.5117 - val_loss: 1496.6681\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 154.5118 - val_loss: 1496.6682\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5118 - val_loss: 1496.6677\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5118 - val_loss: 1496.6674\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5118 - val_loss: 1496.6674\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5117 - val_loss: 1496.6672\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5117 - val_loss: 1496.6669\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5117 - val_loss: 1496.6664\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5117 - val_loss: 1496.6655\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5117 - val_loss: 1496.6649\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5117 - val_loss: 1496.6642\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5117 - val_loss: 1496.6636\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5118 - val_loss: 1496.6627\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5118 - val_loss: 1496.6616\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5118 - val_loss: 1496.6592\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5118 - val_loss: 1496.6542\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5118 - val_loss: 1496.6372\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5118 - val_loss: 1495.1854\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5393 - val_loss: 1496.8223\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5118 - val_loss: 1496.8221\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5117 - val_loss: 1496.8206\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5117 - val_loss: 1496.8195\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 154.5117 - val_loss: 1496.8192\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5118 - val_loss: 1496.8187\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5118 - val_loss: 1496.8184\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5118 - val_loss: 1496.8182\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5118 - val_loss: 1496.8179\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5118 - val_loss: 1496.8174\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5118 - val_loss: 1496.8164\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5119 - val_loss: 1496.8162\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5119 - val_loss: 1496.8162\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5119 - val_loss: 1496.8162\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5119 - val_loss: 1496.8165\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 154.5119 - val_loss: 1496.8174\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5119 - val_loss: 1496.8174\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.5119 - val_loss: 1496.8173\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.1552, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0026, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0004, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0102, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.8734, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 334ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.30997899e+01, 6.28728992e+01, 6.26460084e+01, 6.24191176e+01,\n",
       "        6.95426636e+01, 1.80712970e-01, 0.00000000e+00, 1.07407700e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.38707200e-01, 9.61624320e-01,\n",
       "        5.06575110e-01, 6.87403361e+01, 6.86058824e+01, 6.84714286e+01,\n",
       "        6.83369748e+01, 6.82695378e+01, 6.38893791e+01, 6.37129085e+01,\n",
       "        6.35364379e+01, 6.33599673e+01, 6.31502101e+01, 6.29233193e+01,\n",
       "        6.26964286e+01, 6.24695378e+01, 6.23825163e+01, 6.10286120e-01,\n",
       "        0.00000000e+00, 7.08808823e+01, 7.08052521e+01, 7.07296219e+01,\n",
       "        7.06539916e+01, 7.05495098e+01, 7.03730392e+01, 7.01965686e+01,\n",
       "        7.00200980e+01, 6.97711485e+01, 9.45959151e-01, 0.00000000e+00,\n",
       "        1.49050057e-01, 2.55974114e-01, 0.00000000e+00, 6.80849791e-01,\n",
       "        1.21249773e-01, 0.00000000e+00, 0.00000000e+00, 6.25199580e+01,\n",
       "        6.23881186e+01, 1.30264850e-01, 0.00000000e+00, 7.08976891e+01,\n",
       "        7.08220588e+01, 7.07464286e+01, 7.06707983e+01, 7.05887255e+01,\n",
       "        7.04122549e+01, 7.02357843e+01, 7.00593137e+01, 6.98607843e+01,\n",
       "        1.86991950e-02, 6.03351235e-01, 7.06259804e+01, 7.04841503e+01,\n",
       "        7.03076797e+01, 7.01312092e+01, 6.99547386e+01, 6.96217554e+01,\n",
       "        6.92183940e+01, 6.88150327e+01, 6.84116713e+01, 0.00000000e+00,\n",
       "        1.36208210e-01, 5.93270264e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.85614920e-01, 0.00000000e+00, 0.00000000e+00, 3.47115099e-01,\n",
       "        7.09015198e+01, 3.28239650e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.95933253e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.60106474e-03, 5.87940335e-01,\n",
       "        0.00000000e+00, 2.69190073e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.95086533e-01, 3.56221586e-01, 5.10593235e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55.19981554, 55.18423857, 55.16866161, 55.15308465, 55.13750769,\n",
       "       55.12193072, 55.10635376, 55.0907768 , 55.07519984, 55.05962287,\n",
       "       55.04404591, 55.02846895, 55.01289199, 54.99731502, 54.98173806,\n",
       "       54.9661611 , 54.95058414, 54.93500717, 54.91943021, 54.90385325,\n",
       "       54.88827629, 54.87269932, 54.85712236, 54.8415454 , 54.82596844,\n",
       "       54.81039147, 54.79481451, 54.77923755, 54.76366059, 54.74808362,\n",
       "       54.73250666, 54.7169297 , 54.70135274, 54.68577577, 54.67019881,\n",
       "       54.65462185, 54.63904489, 54.62346792, 54.60789096, 54.592314  ,\n",
       "       54.57673704, 54.56116007, 54.54558311, 54.53000615, 54.51442919,\n",
       "       54.49885222, 54.48327526, 54.4676983 , 54.45212134, 54.43654437,\n",
       "       54.42096741, 54.40539045, 54.38981349, 54.37423652, 54.35865956,\n",
       "       54.3430826 , 54.32750564, 54.31192867, 54.29635171, 54.28077475,\n",
       "       54.26519779, 54.24962082, 54.23404386, 54.2184669 , 54.20288994,\n",
       "       54.18731297, 54.17173601, 54.15615905, 54.14058209, 54.12500512,\n",
       "       54.10942816, 54.0938512 , 54.07827424, 54.06269727, 54.04712031,\n",
       "       54.03154335, 54.01596639, 54.00038942, 53.98481246, 53.9692355 ,\n",
       "       53.95365854, 53.93808157, 53.92250461, 53.90692765, 53.89135069,\n",
       "       53.87577372, 53.86019676, 53.8446198 , 53.82904284, 53.81346587,\n",
       "       53.79788891, 53.78231195, 53.76673499, 53.75115802, 53.73558106,\n",
       "       53.7200041 , 53.70442714, 53.68885017, 53.67327321, 53.65769625])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.41544193024615\n",
      "33.554235214077806\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
