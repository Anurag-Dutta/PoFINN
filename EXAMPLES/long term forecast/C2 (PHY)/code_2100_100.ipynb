{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "2195    56.835397\n",
       "2196    56.819820\n",
       "2197    56.804243\n",
       "2198    56.788666\n",
       "2199    56.773089\n",
       "Name: C2, Length: 2200, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c2_interpolated_2100_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "2095     0.000000\n",
       "2096     0.014467\n",
       "2097     0.605638\n",
       "2098     0.347115\n",
       "2099     0.376225\n",
       "Name: C2, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2100)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.500000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.275910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.051821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.827731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.603641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     90.500000  0.000298\n",
       "1     90.275910  0.000298\n",
       "2     90.051821  0.000297\n",
       "3     89.827731  0.000297\n",
       "4     89.603641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.1552  # Value for C0\n",
    "K0 = -0.0026  # Value for K0\n",
    "K1 = -0.0004  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0102    # Value for b\n",
    "c = 2.8734    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    90.500000    90.275910    90.051821    89.827731    89.603641   \n",
      "351    90.275910    90.051821    89.827731    89.603641    89.379552   \n",
      "352    90.051821    89.827731    89.603641    89.379552    89.155462   \n",
      "353    89.827731    89.603641    89.379552    89.155462    88.931373   \n",
      "354    89.603641    89.379552    89.155462    88.931373    88.707283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.379552    89.155462    88.931373    88.707283    88.494958  ...   \n",
      "351    89.155462    88.931373    88.707283    88.494958    88.427731  ...   \n",
      "352    88.931373    88.707283    88.494958    88.427731    88.360504  ...   \n",
      "353    88.707283    88.494958    88.427731    88.360504    88.293277  ...   \n",
      "354    88.494958    88.427731    88.360504    88.293277    88.226050  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.071008    0.000263   79.054202    0.000263   79.037395    0.000263   \n",
      "351   79.054202    0.000263   79.037395    0.000263   79.020588    0.000262   \n",
      "352   79.037395    0.000263   79.020588    0.000262   79.003782    0.000262   \n",
      "353   79.020588    0.000262   79.003782    0.000262   78.986975    0.000262   \n",
      "354   79.003782    0.000262   78.986975    0.000262   78.970168    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.020588    0.000262   79.003782    0.000262  \n",
      "351   79.003782    0.000262   78.986975    0.000262  \n",
      "352   78.986975    0.000262   78.970168    0.000262  \n",
      "353   78.970168    0.000262   78.953361    0.000262  \n",
      "354   78.953361    0.000262   78.936555    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 1, 251) (1650, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 3s 30ms/step - loss: 5357.7842 - val_loss: 3458.6621\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5238.1426 - val_loss: 3408.0977\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5161.2109 - val_loss: 3365.4883\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5087.0396 - val_loss: 3323.5898\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5013.9551 - val_loss: 3282.3145\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4941.8418 - val_loss: 3241.5984\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4870.6187 - val_loss: 3201.4075\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4800.2393 - val_loss: 3161.7158\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4730.6768 - val_loss: 3122.5051\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4661.9077 - val_loss: 3083.6082\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4588.5796 - val_loss: 3039.3188\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4511.2710 - val_loss: 2992.8762\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4431.7524 - val_loss: 2948.8367\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4356.6196 - val_loss: 2906.4863\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4283.8286 - val_loss: 2865.4048\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4212.8125 - val_loss: 2825.3171\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4143.2417 - val_loss: 2786.0693\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4074.9253 - val_loss: 2747.5688\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4007.7454 - val_loss: 2709.7529\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3941.6179 - val_loss: 2672.5774\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3876.4849 - val_loss: 2636.0098\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3812.2996 - val_loss: 2600.0232\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3749.0276 - val_loss: 2564.5974\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3686.6379 - val_loss: 2529.7148\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3625.1060 - val_loss: 2495.3613\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3564.4114 - val_loss: 2461.5237\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3504.5352 - val_loss: 2428.1907\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3445.4607 - val_loss: 2395.3518\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3387.1736 - val_loss: 2362.9995\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3329.6614 - val_loss: 2331.1238\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3272.9094 - val_loss: 2299.7175\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3216.9084 - val_loss: 2268.7742\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3161.6467 - val_loss: 2238.2864\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3107.1152 - val_loss: 2208.2483\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3053.3030 - val_loss: 2178.6533\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3000.2019 - val_loss: 2149.4961\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2947.8030 - val_loss: 2120.7712\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2896.0986 - val_loss: 2092.4734\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2845.0803 - val_loss: 2064.5972\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2794.7400 - val_loss: 2037.1381\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2745.0708 - val_loss: 2010.0911\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2696.0645 - val_loss: 1983.4515\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2647.7153 - val_loss: 1957.2152\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2600.0154 - val_loss: 1931.3773\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2552.9583 - val_loss: 1905.9340\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2506.5376 - val_loss: 1880.8802\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2460.7468 - val_loss: 1856.2126\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2415.5793 - val_loss: 1831.9269\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2371.0300 - val_loss: 1808.0189\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2327.0911 - val_loss: 1784.4850\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2283.7573 - val_loss: 1761.3215\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2241.0237 - val_loss: 1738.5237\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2198.8828 - val_loss: 1716.0890\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2157.3298 - val_loss: 1694.0125\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2116.3589 - val_loss: 1672.2915\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2075.9646 - val_loss: 1650.9220\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2036.1409 - val_loss: 1629.9001\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1996.8829 - val_loss: 1609.2231\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1958.1848 - val_loss: 1588.8867\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1920.0420 - val_loss: 1568.8883\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1882.4481 - val_loss: 1549.2236\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1845.3988 - val_loss: 1529.8895\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1808.8887 - val_loss: 1510.8832\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1772.9127 - val_loss: 1492.2001\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1737.4650 - val_loss: 1473.8383\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1702.5408 - val_loss: 1455.7933\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1668.1354 - val_loss: 1438.0629\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1634.2443 - val_loss: 1420.6436\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1600.8623 - val_loss: 1403.5315\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1567.9841 - val_loss: 1386.7245\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1535.6053 - val_loss: 1370.2185\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1503.7211 - val_loss: 1354.0112\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1472.3267 - val_loss: 1338.0992\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1441.4170 - val_loss: 1322.4791\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1410.9877 - val_loss: 1307.1481\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1381.0341 - val_loss: 1292.1033\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1351.5518 - val_loss: 1277.3411\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1322.5348 - val_loss: 1262.8589\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1293.9802 - val_loss: 1248.6539\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1265.8832 - val_loss: 1234.7231\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1238.2384 - val_loss: 1221.0630\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1211.0425 - val_loss: 1207.6714\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1184.2906 - val_loss: 1194.5448\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1157.9771 - val_loss: 1181.6801\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1132.0988 - val_loss: 1169.0750\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1106.6510 - val_loss: 1156.7263\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1081.6299 - val_loss: 1144.6315\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1057.0302 - val_loss: 1132.7871\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1032.8481 - val_loss: 1121.1907\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1009.0795 - val_loss: 1109.8394\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 985.7195 - val_loss: 1098.7302\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 962.7640 - val_loss: 1087.8605\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 940.2092 - val_loss: 1077.2274\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 918.0503 - val_loss: 1066.8284\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 896.2840 - val_loss: 1056.6602\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 874.9048 - val_loss: 1046.7203\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 853.9095 - val_loss: 1037.0057\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 833.2936 - val_loss: 1027.5142\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 813.0529 - val_loss: 1018.2426\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 793.1837 - val_loss: 1009.1885\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 773.6814 - val_loss: 1000.3485\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 754.5424 - val_loss: 991.7209\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 735.7620 - val_loss: 983.3021\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 717.3366 - val_loss: 975.0898\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 699.2623 - val_loss: 967.0817\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 681.5348 - val_loss: 959.2744\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 664.1500 - val_loss: 951.6654\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 647.1038 - val_loss: 944.2524\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 630.3924 - val_loss: 937.0324\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 614.0118 - val_loss: 930.0029\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 597.9581 - val_loss: 923.1609\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 582.2273 - val_loss: 916.5045\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 566.8157 - val_loss: 910.0306\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 551.7192 - val_loss: 903.7365\n",
      "Epoch 115/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 536.9334 - val_loss: 897.6199\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 522.4553 - val_loss: 891.6782\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 508.2803 - val_loss: 885.9083\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 494.4050 - val_loss: 880.3082\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 480.8251 - val_loss: 874.8749\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 467.5373 - val_loss: 869.6061\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 454.5373 - val_loss: 864.4991\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 441.8215 - val_loss: 859.5515\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 429.3860 - val_loss: 854.7607\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 417.2271 - val_loss: 850.1238\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 405.3407 - val_loss: 845.6389\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 393.7231 - val_loss: 841.3027\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 382.3710 - val_loss: 837.1133\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 371.2805 - val_loss: 833.0682\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 360.4475 - val_loss: 829.1645\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 349.8685 - val_loss: 825.3999\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 339.5398 - val_loss: 821.7720\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 329.4577 - val_loss: 818.2781\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 319.6186 - val_loss: 814.9159\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 310.0185 - val_loss: 811.6829\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 300.6539 - val_loss: 808.5766\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 291.5215 - val_loss: 805.5949\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 282.6173 - val_loss: 802.7347\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 273.9376 - val_loss: 799.9940\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 265.4789 - val_loss: 797.3702\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 257.2374 - val_loss: 794.8613\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 249.2102 - val_loss: 792.4644\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 241.3931 - val_loss: 790.1773\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 233.7827 - val_loss: 787.9978\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 226.3755 - val_loss: 785.9233\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 219.1684 - val_loss: 783.9518\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 212.1574 - val_loss: 782.0805\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 205.3390 - val_loss: 780.3073\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 198.7100 - val_loss: 778.6299\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 192.2668 - val_loss: 777.0461\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 186.0060 - val_loss: 775.5532\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 179.9241 - val_loss: 774.1495\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 174.0180 - val_loss: 772.8325\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 168.2840 - val_loss: 771.5998\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 162.7189 - val_loss: 770.4493\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 157.3195 - val_loss: 769.3788\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 152.0824 - val_loss: 768.3863\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 147.0041 - val_loss: 767.4692\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 142.0815 - val_loss: 766.6257\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 137.3116 - val_loss: 765.8535\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 132.6908 - val_loss: 765.1506\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 128.2162 - val_loss: 764.5146\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 123.8845 - val_loss: 763.9438\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 119.6926 - val_loss: 763.4360\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 115.6374 - val_loss: 762.9890\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 111.7159 - val_loss: 762.6010\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 107.9247 - val_loss: 762.2698\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 104.2610 - val_loss: 761.9935\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 100.7220 - val_loss: 761.7701\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 97.3043 - val_loss: 761.5980\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 94.0052 - val_loss: 761.4748\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 90.8219 - val_loss: 761.3989\n",
      "Epoch 172/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 87.7514 - val_loss: 761.3683\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 84.7906 - val_loss: 761.3812\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 81.9369 - val_loss: 761.4359\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 79.1875 - val_loss: 761.5305\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 76.5397 - val_loss: 761.6633\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 73.9907 - val_loss: 761.8325\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 71.5378 - val_loss: 762.0366\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 69.1785 - val_loss: 762.2736\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 66.9100 - val_loss: 762.5421\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 64.7299 - val_loss: 762.8403\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 62.6355 - val_loss: 763.1667\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 60.6243 - val_loss: 763.5199\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 58.6942 - val_loss: 763.8981\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 56.8423 - val_loss: 764.3000\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 55.0663 - val_loss: 764.7241\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 53.3640 - val_loss: 765.1688\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 51.7331 - val_loss: 765.6328\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 50.1712 - val_loss: 766.1150\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 48.6761 - val_loss: 766.6136\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 47.2457 - val_loss: 767.1276\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 45.8777 - val_loss: 767.6557\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 44.5702 - val_loss: 768.1966\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43.3210 - val_loss: 768.7490\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42.1280 - val_loss: 769.3120\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 40.9895 - val_loss: 769.8842\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 39.9033 - val_loss: 770.4645\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 38.8676 - val_loss: 771.0521\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 37.8805 - val_loss: 771.6457\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 36.9403 - val_loss: 772.2442\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 36.0452 - val_loss: 772.8472\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 35.1933 - val_loss: 773.4530\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 34.3833 - val_loss: 774.0613\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 33.6131 - val_loss: 774.6711\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 32.8815 - val_loss: 775.2814\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 32.1866 - val_loss: 775.8916\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 31.5272 - val_loss: 776.5009\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.9016 - val_loss: 777.1082\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.3086 - val_loss: 777.7134\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.7465 - val_loss: 778.3155\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.2144 - val_loss: 778.9138\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 28.7106 - val_loss: 779.5077\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 28.2340 - val_loss: 780.0968\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 27.7834 - val_loss: 780.6807\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 27.3575 - val_loss: 781.2585\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 26.9553 - val_loss: 781.8301\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 26.5756 - val_loss: 782.3947\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 26.2174 - val_loss: 782.9521\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.8796 - val_loss: 783.5021\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.5612 - val_loss: 784.0438\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.2614 - val_loss: 784.5773\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 24.9791 - val_loss: 785.1023\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 24.7135 - val_loss: 785.6183\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 24.4637 - val_loss: 786.1251\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 24.2290 - val_loss: 786.6227\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 24.0083 - val_loss: 787.1105\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.8012 - val_loss: 787.5889\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.6068 - val_loss: 788.0571\n",
      "Epoch 229/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.4245 - val_loss: 788.5155\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.2536 - val_loss: 788.9636\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.0935 - val_loss: 789.4012\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 22.9435 - val_loss: 789.8286\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 22.8032 - val_loss: 790.2457\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 22.6719 - val_loss: 790.6525\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 22.5491 - val_loss: 791.0488\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 22.4342 - val_loss: 791.4349\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 22.3270 - val_loss: 791.8105\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 22.2268 - val_loss: 792.1755\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 22.1334 - val_loss: 792.5304\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 22.0461 - val_loss: 792.8750\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.9648 - val_loss: 793.2094\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.8890 - val_loss: 793.5339\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.8183 - val_loss: 793.8483\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.7524 - val_loss: 794.1528\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.6911 - val_loss: 794.4474\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.6341 - val_loss: 794.7326\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.5810 - val_loss: 795.0081\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.5317 - val_loss: 795.2744\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.4857 - val_loss: 795.5314\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 21.4431 - val_loss: 795.7794\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.4034 - val_loss: 796.0186\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.3665 - val_loss: 796.2490\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.3323 - val_loss: 796.4709\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.3006 - val_loss: 796.6848\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.2710 - val_loss: 796.8903\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.2437 - val_loss: 797.0879\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.2183 - val_loss: 797.2776\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.1947 - val_loss: 797.4598\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.1729 - val_loss: 797.6348\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.1526 - val_loss: 797.8024\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.1337 - val_loss: 797.9630\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.1163 - val_loss: 798.1169\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.1002 - val_loss: 798.2643\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.0852 - val_loss: 798.4053\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.0714 - val_loss: 798.5400\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.0585 - val_loss: 798.6688\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.0465 - val_loss: 798.7917\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.0355 - val_loss: 798.9092\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.0253 - val_loss: 799.0208\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.0158 - val_loss: 799.1274\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.0071 - val_loss: 799.2290\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9990 - val_loss: 799.3255\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9915 - val_loss: 799.4175\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9845 - val_loss: 799.5048\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9782 - val_loss: 799.5879\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9722 - val_loss: 799.6666\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 20.9667 - val_loss: 799.7415\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 20.9617 - val_loss: 799.8125\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9570 - val_loss: 799.8798\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9526 - val_loss: 799.9435\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9487 - val_loss: 800.0041\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9450 - val_loss: 800.0612\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9416 - val_loss: 800.1152\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9385 - val_loss: 800.1661\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9356 - val_loss: 800.2143\n",
      "Epoch 286/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9330 - val_loss: 800.2598\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9306 - val_loss: 800.3026\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9284 - val_loss: 800.3430\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9263 - val_loss: 800.3809\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9245 - val_loss: 800.4166\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9228 - val_loss: 800.4503\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9213 - val_loss: 800.4818\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9199 - val_loss: 800.5115\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9187 - val_loss: 800.5394\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9175 - val_loss: 800.5656\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9165 - val_loss: 800.5898\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9156 - val_loss: 800.6129\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9148 - val_loss: 800.6343\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9141 - val_loss: 800.6542\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9135 - val_loss: 800.6731\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9129 - val_loss: 800.6906\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9125 - val_loss: 800.7072\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 20.9120 - val_loss: 800.7224\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9117 - val_loss: 800.7368\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9114 - val_loss: 800.7499\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9112 - val_loss: 800.7621\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9111 - val_loss: 800.7735\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9109 - val_loss: 800.7841\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9109 - val_loss: 800.7939\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9109 - val_loss: 800.8029\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9109 - val_loss: 800.8113\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9110 - val_loss: 800.8193\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9111 - val_loss: 800.8265\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9111 - val_loss: 800.8329\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9114 - val_loss: 800.8392\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9115 - val_loss: 800.8449\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9117 - val_loss: 800.8499\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9119 - val_loss: 800.8544\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9122 - val_loss: 800.8588\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9125 - val_loss: 800.8627\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9128 - val_loss: 800.8663\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9131 - val_loss: 800.8696\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9134 - val_loss: 800.8726\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9138 - val_loss: 800.8753\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9141 - val_loss: 800.8776\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9145 - val_loss: 800.8798\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9149 - val_loss: 800.8818\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9153 - val_loss: 800.8836\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9157 - val_loss: 800.8853\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 20.9161 - val_loss: 800.8867\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9165 - val_loss: 800.8881\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9169 - val_loss: 800.8893\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9173 - val_loss: 800.8900\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9177 - val_loss: 800.8908\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9182 - val_loss: 800.8917\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9186 - val_loss: 800.8922\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9191 - val_loss: 800.8924\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9195 - val_loss: 800.8930\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9200 - val_loss: 800.8934\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9204 - val_loss: 800.8937\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9209 - val_loss: 800.8939\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9213 - val_loss: 800.8939\n",
      "Epoch 343/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9217 - val_loss: 800.8937\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9222 - val_loss: 800.8937\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9226 - val_loss: 800.8937\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9231 - val_loss: 800.8937\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9235 - val_loss: 800.8935\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9240 - val_loss: 800.8931\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9245 - val_loss: 800.8930\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9249 - val_loss: 800.8927\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 20.9253 - val_loss: 800.8925\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9257 - val_loss: 800.8922\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9262 - val_loss: 800.8918\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9266 - val_loss: 800.8914\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9270 - val_loss: 800.8910\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9274 - val_loss: 800.8906\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9279 - val_loss: 800.8903\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9283 - val_loss: 800.8899\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9287 - val_loss: 800.8894\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9291 - val_loss: 800.8886\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9295 - val_loss: 800.8884\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9299 - val_loss: 800.8879\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9304 - val_loss: 800.8874\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9307 - val_loss: 800.8868\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9311 - val_loss: 800.8863\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9315 - val_loss: 800.8858\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9319 - val_loss: 800.8853\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9323 - val_loss: 800.8848\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9327 - val_loss: 800.8845\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9331 - val_loss: 800.8841\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9334 - val_loss: 800.8837\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 20.9338 - val_loss: 800.8831\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9342 - val_loss: 800.8826\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9345 - val_loss: 800.8823\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9348 - val_loss: 800.8817\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9352 - val_loss: 800.8812\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9355 - val_loss: 800.8808\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9359 - val_loss: 800.8803\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9363 - val_loss: 800.8799\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9366 - val_loss: 800.8795\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9369 - val_loss: 800.8791\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9371 - val_loss: 800.8785\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9375 - val_loss: 800.8781\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9378 - val_loss: 800.8776\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9381 - val_loss: 800.8769\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9385 - val_loss: 800.8767\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9387 - val_loss: 800.8762\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9391 - val_loss: 800.8757\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9393 - val_loss: 800.8754\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9396 - val_loss: 800.8750\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9399 - val_loss: 800.8746\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9402 - val_loss: 800.8740\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9404 - val_loss: 800.8736\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9408 - val_loss: 800.8735\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 20.9410 - val_loss: 800.8729\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9413 - val_loss: 800.8726\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9415 - val_loss: 800.8721\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9418 - val_loss: 800.8719\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9421 - val_loss: 800.8716\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9423 - val_loss: 800.8708\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9425 - val_loss: 800.8705\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9428 - val_loss: 800.8702\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9430 - val_loss: 800.8701\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9432 - val_loss: 800.8697\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9435 - val_loss: 800.8693\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9437 - val_loss: 800.8688\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9439 - val_loss: 800.8685\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9442 - val_loss: 800.8683\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9444 - val_loss: 800.8679\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9446 - val_loss: 800.8675\n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9448 - val_loss: 800.8673\n",
      "Epoch 412/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9449 - val_loss: 800.8669\n",
      "Epoch 413/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9452 - val_loss: 800.8666\n",
      "Epoch 414/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9453 - val_loss: 800.8664\n",
      "Epoch 415/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9455 - val_loss: 800.8659\n",
      "Epoch 416/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9457 - val_loss: 800.8654\n",
      "Epoch 417/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9460 - val_loss: 800.8652\n",
      "Epoch 418/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9461 - val_loss: 800.8647\n",
      "Epoch 419/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9463 - val_loss: 800.8643\n",
      "Epoch 420/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 20.9465 - val_loss: 800.8641\n",
      "Epoch 421/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9467 - val_loss: 800.8636\n",
      "Epoch 422/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9469 - val_loss: 800.8635\n",
      "Epoch 423/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9471 - val_loss: 800.8632\n",
      "Epoch 424/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9472 - val_loss: 800.8632\n",
      "Epoch 425/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9474 - val_loss: 800.8629\n",
      "Epoch 426/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9475 - val_loss: 800.8627\n",
      "Epoch 427/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9476 - val_loss: 800.8623\n",
      "Epoch 428/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9479 - val_loss: 800.8621\n",
      "Epoch 429/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9480 - val_loss: 800.8618\n",
      "Epoch 430/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9481 - val_loss: 800.8614\n",
      "Epoch 431/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9483 - val_loss: 800.8610\n",
      "Epoch 432/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9485 - val_loss: 800.8607\n",
      "Epoch 433/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9486 - val_loss: 800.8607\n",
      "Epoch 434/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9487 - val_loss: 800.8605\n",
      "Epoch 435/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9489 - val_loss: 800.8602\n",
      "Epoch 436/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9490 - val_loss: 800.8599\n",
      "Epoch 437/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9491 - val_loss: 800.8599\n",
      "Epoch 438/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9493 - val_loss: 800.8597\n",
      "Epoch 439/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9494 - val_loss: 800.8594\n",
      "Epoch 440/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 20.9495 - val_loss: 800.8593\n",
      "Epoch 441/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9496 - val_loss: 800.8589\n",
      "Epoch 442/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9497 - val_loss: 800.8586\n",
      "Epoch 443/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9499 - val_loss: 800.8583\n",
      "Epoch 444/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9500 - val_loss: 800.8582\n",
      "Epoch 445/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9501 - val_loss: 800.8576\n",
      "Epoch 446/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9502 - val_loss: 800.8575\n",
      "Epoch 447/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9503 - val_loss: 800.8573\n",
      "Epoch 448/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9505 - val_loss: 800.8572\n",
      "Epoch 449/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9506 - val_loss: 800.8569\n",
      "Epoch 450/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9507 - val_loss: 800.8569\n",
      "Epoch 451/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9508 - val_loss: 800.8568\n",
      "Epoch 452/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9509 - val_loss: 800.8565\n",
      "Epoch 453/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9510 - val_loss: 800.8564\n",
      "Epoch 454/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9511 - val_loss: 800.8563\n",
      "Epoch 455/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9511 - val_loss: 800.8561\n",
      "Epoch 456/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9513 - val_loss: 800.8559\n",
      "Epoch 457/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 20.9513 - val_loss: 800.8557\n",
      "Epoch 458/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9514 - val_loss: 800.8555\n",
      "Epoch 459/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9516 - val_loss: 800.8553\n",
      "Epoch 460/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 20.9516 - val_loss: 800.8550\n",
      "Epoch 461/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9517 - val_loss: 800.8549\n",
      "Epoch 462/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9518 - val_loss: 800.8547\n",
      "Epoch 463/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9518 - val_loss: 800.8546\n",
      "Epoch 464/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9519 - val_loss: 800.8546\n",
      "Epoch 465/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9520 - val_loss: 800.8542\n",
      "Epoch 466/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9520 - val_loss: 800.8542\n",
      "Epoch 467/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9522 - val_loss: 800.8542\n",
      "Epoch 468/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9522 - val_loss: 800.8537\n",
      "Epoch 469/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9523 - val_loss: 800.8534\n",
      "Epoch 470/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9524 - val_loss: 800.8532\n",
      "Epoch 471/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9525 - val_loss: 800.8530\n",
      "Epoch 472/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9525 - val_loss: 800.8531\n",
      "Epoch 473/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9526 - val_loss: 800.8528\n",
      "Epoch 474/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9527 - val_loss: 800.8527\n",
      "Epoch 475/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9527 - val_loss: 800.8527\n",
      "Epoch 476/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9527 - val_loss: 800.8525\n",
      "Epoch 477/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9528 - val_loss: 800.8521\n",
      "Epoch 478/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9529 - val_loss: 800.8520\n",
      "Epoch 479/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9529 - val_loss: 800.8520\n",
      "Epoch 480/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9531 - val_loss: 800.8520\n",
      "Epoch 481/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 20.9531 - val_loss: 800.8518\n",
      "Epoch 482/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9532 - val_loss: 800.8517\n",
      "Epoch 483/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9532 - val_loss: 800.8516\n",
      "Epoch 484/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9533 - val_loss: 800.8516\n",
      "Epoch 485/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9533 - val_loss: 800.8513\n",
      "Epoch 486/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9533 - val_loss: 800.8510\n",
      "Epoch 487/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9534 - val_loss: 800.8511\n",
      "Epoch 488/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9534 - val_loss: 800.8508\n",
      "Epoch 489/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9535 - val_loss: 800.8508\n",
      "Epoch 490/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9535 - val_loss: 800.8506\n",
      "Epoch 491/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9536 - val_loss: 800.8505\n",
      "Epoch 492/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9537 - val_loss: 800.8504\n",
      "Epoch 493/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9537 - val_loss: 800.8502\n",
      "Epoch 494/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9537 - val_loss: 800.8500\n",
      "Epoch 495/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9538 - val_loss: 800.8501\n",
      "Epoch 496/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9538 - val_loss: 800.8498\n",
      "Epoch 497/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9539 - val_loss: 800.8497\n",
      "Epoch 498/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9539 - val_loss: 800.8496\n",
      "Epoch 499/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.9539 - val_loss: 800.8494\n",
      "Epoch 500/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.9540 - val_loss: 800.8494\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.1552, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0026, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0004, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0102, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.8734, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 463ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.01573529e+01, 7.00985294e+01, 7.00397059e+01, 6.99808824e+01,\n",
       "        6.99220588e+01, 6.98159664e+01, 6.96815126e+01, 4.62659091e-01,\n",
       "        2.43531480e-01, 6.51802570e-02, 0.00000000e+00, 7.60643260e-02,\n",
       "        7.76654000e-04, 7.06427871e+01, 7.06175770e+01, 7.05821895e+01,\n",
       "        7.05233660e+01, 7.04645425e+01, 7.04057189e+01, 7.03468954e+01,\n",
       "        7.02880719e+01, 7.02292484e+01, 7.01704248e+01, 7.01116013e+01,\n",
       "        7.00527778e+01, 6.99939543e+01, 6.99351307e+01, 6.98458450e+01,\n",
       "        6.97113912e+01, 6.95769374e+01, 6.94424837e+01, 6.93080299e+01,\n",
       "        6.91735761e+01, 6.90391223e+01, 6.89046685e+01, 6.87702147e+01,\n",
       "        6.86357610e+01, 6.85013072e+01, 6.83668534e+01, 6.82788749e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 8.29133500e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.93788900e-02, 0.00000000e+00, 7.00070261e+01,\n",
       "        6.99482026e+01, 6.98757236e+01, 6.97412698e+01, 6.96068161e+01,\n",
       "        6.94723623e+01, 6.93379085e+01, 6.92034547e+01, 6.90690009e+01,\n",
       "        6.89345472e+01, 6.88000934e+01, 6.86656396e+01, 6.85311858e+01,\n",
       "        6.83967320e+01, 6.82882120e+01, 6.39678105e+01, 6.37913399e+01,\n",
       "        6.36148693e+01, 6.34383987e+01, 6.32510504e+01, 6.30241597e+01,\n",
       "        6.27972689e+01, 6.25703782e+01, 6.23937208e+01, 0.00000000e+00,\n",
       "        8.05609170e-01, 4.75145149e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.66843850e-01, 1.95178750e-01, 0.00000000e+00, 2.06388060e-01,\n",
       "        3.83822441e+01, 4.11752015e-02, 0.00000000e+00, 2.08030969e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.87644804e-01, 0.00000000e+00, 4.21391070e-01,\n",
       "        0.00000000e+00, 3.79072458e-01, 0.00000000e+00, 5.69434285e-01,\n",
       "        3.44123453e-01, 7.32500792e-01, 3.52534056e-01, 2.73457944e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58.68014706, 58.65353641, 58.62692577, 58.60031513, 58.57370448,\n",
       "       58.54709384, 58.52048319, 58.49387255, 58.4672619 , 58.44065126,\n",
       "       58.41404062, 58.38742997, 58.36081933, 58.33420868, 58.30759804,\n",
       "       58.28098739, 58.25437675, 58.22776611, 58.20115546, 58.17454482,\n",
       "       58.14793417, 58.12132353, 58.09471289, 58.06810224, 58.0414916 ,\n",
       "       58.01488095, 57.98827031, 57.96165966, 57.93504902, 57.90843838,\n",
       "       57.88182773, 57.85521709, 57.82860644, 57.8019958 , 57.78559131,\n",
       "       57.77001435, 57.75443738, 57.73886042, 57.72328346, 57.7077065 ,\n",
       "       57.69212953, 57.67655257, 57.66097561, 57.64539865, 57.62982168,\n",
       "       57.61424472, 57.59866776, 57.5830908 , 57.56751383, 57.55193687,\n",
       "       57.53635991, 57.52078295, 57.50520598, 57.48962902, 57.47405206,\n",
       "       57.4584751 , 57.44289813, 57.42732117, 57.41174421, 57.39616725,\n",
       "       57.38059028, 57.36501332, 57.34943636, 57.3338594 , 57.31828243,\n",
       "       57.30270547, 57.28712851, 57.27155155, 57.25597458, 57.24039762,\n",
       "       57.22482066, 57.2092437 , 57.19366673, 57.17808977, 57.16251281,\n",
       "       57.14693585, 57.13135889, 57.11578192, 57.10020496, 57.084628  ,\n",
       "       57.06905104, 57.05347407, 57.03789711, 57.02232015, 57.00674319,\n",
       "       56.99116622, 56.97558926, 56.9600123 , 56.94443534, 56.92885837,\n",
       "       56.91328141, 56.89770445, 56.88212749, 56.86655052, 56.85097356,\n",
       "       56.8353966 , 56.81981964, 56.80424267, 56.78866571, 56.77308875])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.16677777701043\n",
      "29.392703851907694\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
