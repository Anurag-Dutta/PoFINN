{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2295    53.983972\n",
       "2296    53.975227\n",
       "2297    53.966482\n",
       "2298    53.957737\n",
       "2299    53.948992\n",
       "Name: C1, Length: 2300, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_2200_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2195     0.000000\n",
       "2196     0.000000\n",
       "2197     0.791437\n",
       "2198     0.323886\n",
       "2199     0.000000\n",
       "Name: C1, Length: 2200, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2200)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750, 1, 251) (1750, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/22 [==============================] - 2s 31ms/step - loss: 4408.1377 - val_loss: 2773.6809\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4204.6899 - val_loss: 2626.8608\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4082.8757 - val_loss: 2568.2974\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4010.2639 - val_loss: 2517.6565\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3939.9783 - val_loss: 2472.2681\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3871.6445 - val_loss: 2428.1475\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3804.8281 - val_loss: 2384.9341\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3735.9900 - val_loss: 2339.3530\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3666.8413 - val_loss: 2295.0349\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3599.5789 - val_loss: 2252.3301\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3533.9531 - val_loss: 2210.7456\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3469.6814 - val_loss: 2170.1433\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3406.6028 - val_loss: 2130.4404\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3344.6204 - val_loss: 2091.5830\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3283.6658 - val_loss: 2053.5322\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3223.6929 - val_loss: 2016.2585\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 3164.6633 - val_loss: 1979.7375\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 3106.5476 - val_loss: 1943.9496\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 3049.3215 - val_loss: 1908.8773\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2992.9629 - val_loss: 1874.5059\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2937.4529 - val_loss: 1840.8210\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2882.7769 - val_loss: 1807.8107\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2828.9182 - val_loss: 1775.4636\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2775.8638 - val_loss: 1743.7688\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2723.6008 - val_loss: 1712.7164\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2672.1172 - val_loss: 1682.2970\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2621.4014 - val_loss: 1652.5005\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2571.4438 - val_loss: 1623.3191\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 2522.2334 - val_loss: 1594.7439\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 2473.7610 - val_loss: 1566.7673\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2426.0168 - val_loss: 1539.3807\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2378.9917 - val_loss: 1512.5767\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2332.6780 - val_loss: 1486.3473\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2287.0662 - val_loss: 1460.6859\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2242.1475 - val_loss: 1435.5846\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2197.9150 - val_loss: 1411.0367\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2154.3604 - val_loss: 1387.0349\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2111.4758 - val_loss: 1363.5725\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2069.2537 - val_loss: 1340.6428\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2027.6868 - val_loss: 1318.2394\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1986.7673 - val_loss: 1296.3551\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1946.4885 - val_loss: 1274.9838\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1906.8434 - val_loss: 1254.1193\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1867.8246 - val_loss: 1233.7550\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1829.4254 - val_loss: 1213.8845\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1791.6388 - val_loss: 1194.5022\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1754.4583 - val_loss: 1175.6016\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1717.8772 - val_loss: 1157.1764\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1681.8893 - val_loss: 1139.2209\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1646.4875 - val_loss: 1121.7291\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1611.6660 - val_loss: 1104.6951\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1577.4181 - val_loss: 1088.1134\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1543.7373 - val_loss: 1071.9775\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1510.6180 - val_loss: 1056.2819\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1478.0537 - val_loss: 1041.0211\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1446.0387 - val_loss: 1026.1893\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1414.5660 - val_loss: 1011.7807\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1383.6309 - val_loss: 997.7901\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1353.2261 - val_loss: 984.2117\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1323.3469 - val_loss: 971.0400\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1293.9868 - val_loss: 958.2692\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1265.1403 - val_loss: 945.8943\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1236.8011 - val_loss: 933.9097\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1208.9642 - val_loss: 922.3099\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1181.6238 - val_loss: 911.0899\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1154.7740 - val_loss: 900.2440\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1128.4094 - val_loss: 889.7668\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1102.5244 - val_loss: 879.6536\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1077.1135 - val_loss: 869.8984\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1052.1710 - val_loss: 860.4966\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1027.6920 - val_loss: 851.4427\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1003.6705 - val_loss: 842.7316\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 980.1014 - val_loss: 834.3580\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 956.9794 - val_loss: 826.3170\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 934.2992 - val_loss: 818.6033\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 912.0554 - val_loss: 811.2120\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 890.2432 - val_loss: 804.1379\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 868.8566 - val_loss: 797.3761\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 847.8911 - val_loss: 790.9216\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 827.3412 - val_loss: 784.7689\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 807.2018 - val_loss: 778.9136\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 787.4678 - val_loss: 773.3506\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 768.1342 - val_loss: 768.0749\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 749.1959 - val_loss: 763.0814\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 730.6478 - val_loss: 758.3654\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 712.4849 - val_loss: 753.9221\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 694.7024 - val_loss: 749.7466\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 677.2953 - val_loss: 745.8337\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 660.2585 - val_loss: 742.1788\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 643.5875 - val_loss: 738.7774\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 627.2769 - val_loss: 735.6242\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 611.3218 - val_loss: 732.7147\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 595.7178 - val_loss: 730.0441\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 580.4601 - val_loss: 727.6074\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 565.5438 - val_loss: 725.4003\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 550.9639 - val_loss: 723.4178\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 536.7157 - val_loss: 721.6553\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 522.7947 - val_loss: 720.1080\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 509.1961 - val_loss: 718.7714\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 495.9151 - val_loss: 717.6407\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 482.9471 - val_loss: 716.7115\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 470.2875 - val_loss: 715.9789\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 457.9315 - val_loss: 715.4384\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 445.8748 - val_loss: 715.0856\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 434.1127 - val_loss: 714.9158\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 422.6405 - val_loss: 714.9244\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 411.4537 - val_loss: 715.1071\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 400.5478 - val_loss: 715.4592\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 389.9186 - val_loss: 715.9763\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 379.5612 - val_loss: 716.6540\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 369.4713 - val_loss: 717.4878\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 359.6445 - val_loss: 718.4732\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 350.0764 - val_loss: 719.6060\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 340.7626 - val_loss: 720.8817\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 331.6986 - val_loss: 722.2959\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 322.8803 - val_loss: 723.8445\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 314.3031 - val_loss: 725.5230\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 305.9628 - val_loss: 727.3273\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 297.8554 - val_loss: 729.2529\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 289.9763 - val_loss: 731.2958\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 282.3215 - val_loss: 733.4519\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 274.8867 - val_loss: 735.7169\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 267.6677 - val_loss: 738.0866\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 260.6603 - val_loss: 740.5573\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 253.8605 - val_loss: 743.1246\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 247.2642 - val_loss: 745.7855\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 240.8672 - val_loss: 748.5388\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 234.6575 - val_loss: 751.3510\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 228.6552 - val_loss: 754.2598\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 222.8320 - val_loss: 757.2490\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 217.1926 - val_loss: 760.3113\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 211.7326 - val_loss: 763.4425\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 206.4483 - val_loss: 766.6387\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 201.3355 - val_loss: 769.8964\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 196.3907 - val_loss: 773.2118\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 191.6101 - val_loss: 776.5812\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 186.9898 - val_loss: 780.0012\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 182.5260 - val_loss: 783.4678\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 178.2152 - val_loss: 786.9780\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 174.0536 - val_loss: 790.5278\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 170.0377 - val_loss: 794.1143\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 166.1638 - val_loss: 797.7334\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 162.4285 - val_loss: 801.3823\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 158.8280 - val_loss: 805.0579\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 155.3592 - val_loss: 808.7562\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 152.0184 - val_loss: 812.4748\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 148.8024 - val_loss: 816.2103\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 145.7076 - val_loss: 819.9593\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 142.7308 - val_loss: 823.7197\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 139.8688 - val_loss: 827.4876\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 137.1183 - val_loss: 831.2603\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 134.4764 - val_loss: 835.0352\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 131.9396 - val_loss: 838.8096\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 129.5049 - val_loss: 842.5809\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 127.1694 - val_loss: 846.3459\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 124.9300 - val_loss: 850.1024\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 122.7838 - val_loss: 853.8480\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 120.7279 - val_loss: 857.5801\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 118.7595 - val_loss: 861.2961\n",
      "Epoch 160/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 116.8756 - val_loss: 864.9942\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 115.0737 - val_loss: 868.6721\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.3509 - val_loss: 872.3275\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 111.7046 - val_loss: 875.9581\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 110.1323 - val_loss: 879.5620\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 108.6314 - val_loss: 883.1375\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 107.1995 - val_loss: 886.6824\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 105.8339 - val_loss: 890.1956\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 104.5323 - val_loss: 893.6741\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 103.2926 - val_loss: 897.1174\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 102.1122 - val_loss: 900.5234\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 100.9889 - val_loss: 903.8908\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 99.9207 - val_loss: 907.2182\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 98.9053 - val_loss: 910.5041\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 97.9408 - val_loss: 913.7475\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 97.0250 - val_loss: 916.9468\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 96.1560 - val_loss: 920.1011\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 95.3319 - val_loss: 923.2089\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 94.5508 - val_loss: 926.2697\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 93.8110 - val_loss: 929.2826\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 93.1106 - val_loss: 932.2466\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 92.4479 - val_loss: 935.1611\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 91.8212 - val_loss: 938.0252\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 91.2291 - val_loss: 940.8384\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 90.6697 - val_loss: 943.6003\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 90.1418 - val_loss: 946.3100\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.6438 - val_loss: 948.9680\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.1743 - val_loss: 951.5727\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 88.7320 - val_loss: 954.1246\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 88.3155 - val_loss: 956.6229\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 87.9236 - val_loss: 959.0681\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 87.5550 - val_loss: 961.4593\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 87.2086 - val_loss: 963.7973\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 86.8833 - val_loss: 966.0815\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 86.5779 - val_loss: 968.3123\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 86.2915 - val_loss: 970.4900\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 86.0229 - val_loss: 972.6134\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 85.7713 - val_loss: 974.6846\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 85.5358 - val_loss: 976.7033\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 85.3154 - val_loss: 978.6699\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 85.1092 - val_loss: 980.5839\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 84.9165 - val_loss: 982.4460\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 84.7366 - val_loss: 984.2575\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 84.5686 - val_loss: 986.0179\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 84.4120 - val_loss: 987.7288\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 84.2659 - val_loss: 989.3896\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 84.1299 - val_loss: 991.0017\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 84.0032 - val_loss: 992.5656\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 83.8852 - val_loss: 994.0818\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 83.7756 - val_loss: 995.5515\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 83.6737 - val_loss: 996.9743\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 83.5790 - val_loss: 998.3517\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 83.4911 - val_loss: 999.6841\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 83.4096 - val_loss: 1000.9726\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 83.3340 - val_loss: 1002.2185\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 83.2639 - val_loss: 1003.4221\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 83.1991 - val_loss: 1004.5841\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 83.1389 - val_loss: 1005.7054\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 83.0833 - val_loss: 1006.7872\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 83.0320 - val_loss: 1007.8298\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.9845 - val_loss: 1008.8347\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.9406 - val_loss: 1009.8028\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.9000 - val_loss: 1010.7341\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.8626 - val_loss: 1011.6302\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.8281 - val_loss: 1012.4923\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.7963 - val_loss: 1013.3206\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.7670 - val_loss: 1014.1163\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.7400 - val_loss: 1014.8802\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.7152 - val_loss: 1015.6135\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.6923 - val_loss: 1016.3169\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 82.6712 - val_loss: 1016.9913\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 82.6519 - val_loss: 1017.6373\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 82.6341 - val_loss: 1018.2558\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 82.6178 - val_loss: 1018.8483\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.6028 - val_loss: 1019.4151\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.5890 - val_loss: 1019.9567\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.5763 - val_loss: 1020.4743\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.5648 - val_loss: 1020.9688\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.5541 - val_loss: 1021.4413\n",
      "Epoch 239/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.5444 - val_loss: 1021.8918\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 82.5355 - val_loss: 1022.3216\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 82.5273 - val_loss: 1022.7318\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.5198 - val_loss: 1023.1221\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.5130 - val_loss: 1023.4944\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.5067 - val_loss: 1023.8478\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.5010 - val_loss: 1024.1849\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4958 - val_loss: 1024.5056\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4910 - val_loss: 1024.8103\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4867 - val_loss: 1025.0996\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4827 - val_loss: 1025.3746\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4791 - val_loss: 1025.6348\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4758 - val_loss: 1025.8821\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4728 - val_loss: 1026.1165\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4701 - val_loss: 1026.3386\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4676 - val_loss: 1026.5483\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4654 - val_loss: 1026.7476\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4634 - val_loss: 1026.9360\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4616 - val_loss: 1027.1139\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4600 - val_loss: 1027.2825\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4585 - val_loss: 1027.4413\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4572 - val_loss: 1027.5913\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4561 - val_loss: 1027.7335\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4550 - val_loss: 1027.8669\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4541 - val_loss: 1027.9933\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4532 - val_loss: 1028.1116\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4526 - val_loss: 1028.2238\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4519 - val_loss: 1028.3287\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4515 - val_loss: 1028.4280\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 82.4510 - val_loss: 1028.5208\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 82.4507 - val_loss: 1028.6083\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4504 - val_loss: 1028.6910\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4501 - val_loss: 1028.7684\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4499 - val_loss: 1028.8405\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4498 - val_loss: 1028.9081\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4497 - val_loss: 1028.9713\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4497 - val_loss: 1029.0312\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4497 - val_loss: 1029.0869\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4497 - val_loss: 1029.1394\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4498 - val_loss: 1029.1880\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4499 - val_loss: 1029.2329\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4501 - val_loss: 1029.2755\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4502 - val_loss: 1029.3152\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4504 - val_loss: 1029.3523\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4506 - val_loss: 1029.3870\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4509 - val_loss: 1029.4193\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4511 - val_loss: 1029.4491\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4515 - val_loss: 1029.4769\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4517 - val_loss: 1029.5031\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4521 - val_loss: 1029.5269\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4524 - val_loss: 1029.5493\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4527 - val_loss: 1029.5698\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4530 - val_loss: 1029.5892\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4534 - val_loss: 1029.6072\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 82.4538 - val_loss: 1029.6244\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4542 - val_loss: 1029.6394\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4545 - val_loss: 1029.6532\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4549 - val_loss: 1029.6660\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4552 - val_loss: 1029.6777\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4556 - val_loss: 1029.6884\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4561 - val_loss: 1029.6986\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4565 - val_loss: 1029.7080\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4569 - val_loss: 1029.7164\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4573 - val_loss: 1029.7249\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4576 - val_loss: 1029.7311\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4581 - val_loss: 1029.7384\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4585 - val_loss: 1029.7437\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4589 - val_loss: 1029.7495\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4593 - val_loss: 1029.7542\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4597 - val_loss: 1029.7583\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4601 - val_loss: 1029.7625\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4605 - val_loss: 1029.7655\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4609 - val_loss: 1029.7692\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4613 - val_loss: 1029.7716\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4617 - val_loss: 1029.7738\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4621 - val_loss: 1029.7764\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 82.4625 - val_loss: 1029.7784\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4629 - val_loss: 1029.7802\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4633 - val_loss: 1029.7820\n",
      "Epoch 318/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4636 - val_loss: 1029.7827\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 82.4640 - val_loss: 1029.7834\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4644 - val_loss: 1029.7845\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4648 - val_loss: 1029.7858\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4651 - val_loss: 1029.7864\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4655 - val_loss: 1029.7864\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4658 - val_loss: 1029.7866\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4662 - val_loss: 1029.7871\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4666 - val_loss: 1029.7871\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4669 - val_loss: 1029.7870\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4673 - val_loss: 1029.7874\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4675 - val_loss: 1029.7867\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4679 - val_loss: 1029.7866\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4682 - val_loss: 1029.7858\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4685 - val_loss: 1029.7854\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4688 - val_loss: 1029.7848\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4692 - val_loss: 1029.7843\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4695 - val_loss: 1029.7843\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4698 - val_loss: 1029.7836\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4701 - val_loss: 1029.7832\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4704 - val_loss: 1029.7825\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4707 - val_loss: 1029.7820\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 82.4710 - val_loss: 1029.7817\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 82.4712 - val_loss: 1029.7808\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4715 - val_loss: 1029.7798\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4718 - val_loss: 1029.7791\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4721 - val_loss: 1029.7780\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4724 - val_loss: 1029.7775\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4726 - val_loss: 1029.7765\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 82.4729 - val_loss: 1029.7755\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4731 - val_loss: 1029.7747\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4734 - val_loss: 1029.7734\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4736 - val_loss: 1029.7726\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4739 - val_loss: 1029.7720\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4741 - val_loss: 1029.7712\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4744 - val_loss: 1029.7709\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4745 - val_loss: 1029.7697\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4748 - val_loss: 1029.7688\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4750 - val_loss: 1029.7684\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4752 - val_loss: 1029.7678\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4754 - val_loss: 1029.7667\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 82.4756 - val_loss: 1029.7656\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4759 - val_loss: 1029.7648\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4761 - val_loss: 1029.7644\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4763 - val_loss: 1029.7642\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4764 - val_loss: 1029.7632\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 82.4766 - val_loss: 1029.7623\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4768 - val_loss: 1029.7615\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4770 - val_loss: 1029.7600\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4772 - val_loss: 1029.7596\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4774 - val_loss: 1029.7592\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4776 - val_loss: 1029.7582\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4777 - val_loss: 1029.7577\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 82.4779 - val_loss: 1029.7568\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4781 - val_loss: 1029.7562\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4782 - val_loss: 1029.7551\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4784 - val_loss: 1029.7544\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4785 - val_loss: 1029.7535\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4787 - val_loss: 1029.7532\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4789 - val_loss: 1029.7527\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4790 - val_loss: 1029.7523\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4791 - val_loss: 1029.7515\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4793 - val_loss: 1029.7515\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4794 - val_loss: 1029.7509\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4796 - val_loss: 1029.7507\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4797 - val_loss: 1029.7495\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4798 - val_loss: 1029.7489\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4800 - val_loss: 1029.7485\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 82.4801 - val_loss: 1029.7482\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4802 - val_loss: 1029.7472\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4803 - val_loss: 1029.7466\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4805 - val_loss: 1029.7465\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4805 - val_loss: 1029.7457\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4806 - val_loss: 1029.7454\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4808 - val_loss: 1029.7449\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4809 - val_loss: 1029.7441\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4810 - val_loss: 1029.7440\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4811 - val_loss: 1029.7435\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4812 - val_loss: 1029.7428\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4813 - val_loss: 1029.7424\n",
      "Epoch 398/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4814 - val_loss: 1029.7421\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4815 - val_loss: 1029.7418\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4816 - val_loss: 1029.7413\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4817 - val_loss: 1029.7408\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4817 - val_loss: 1029.7399\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4818 - val_loss: 1029.7394\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4820 - val_loss: 1029.7389\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4820 - val_loss: 1029.7380\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 82.4822 - val_loss: 1029.7379\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4822 - val_loss: 1029.7378\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4823 - val_loss: 1029.7373\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4824 - val_loss: 1029.7372\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4824 - val_loss: 1029.7368\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4826 - val_loss: 1029.7369\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4826 - val_loss: 1029.7366\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4826 - val_loss: 1029.7356\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4828 - val_loss: 1029.7356\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4828 - val_loss: 1029.7352\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4829 - val_loss: 1029.7350\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4829 - val_loss: 1029.7346\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4830 - val_loss: 1029.7341\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4831 - val_loss: 1029.7341\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4832 - val_loss: 1029.7343\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4832 - val_loss: 1029.7338\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4833 - val_loss: 1029.7333\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4833 - val_loss: 1029.7329\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4834 - val_loss: 1029.7325\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4835 - val_loss: 1029.7327\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 82.4835 - val_loss: 1029.7325\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4835 - val_loss: 1029.7325\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4836 - val_loss: 1029.7322\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4837 - val_loss: 1029.7321\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4837 - val_loss: 1029.7322\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4837 - val_loss: 1029.7321\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4838 - val_loss: 1029.7316\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4838 - val_loss: 1029.7312\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4839 - val_loss: 1029.7312\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4839 - val_loss: 1029.7310\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4840 - val_loss: 1029.7307\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4840 - val_loss: 1029.7306\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4840 - val_loss: 1029.7301\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4841 - val_loss: 1029.7300\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 82.4841 - val_loss: 1029.7295\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4842 - val_loss: 1029.7296\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 82.4842 - val_loss: 1029.7289\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4843 - val_loss: 1029.7295\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4843 - val_loss: 1029.7294\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 82.4844 - val_loss: 1029.7296\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4844 - val_loss: 1029.7291\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4844 - val_loss: 1029.7286\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4844 - val_loss: 1029.7281\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4844 - val_loss: 1029.7272\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4845 - val_loss: 1029.7269\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4846 - val_loss: 1029.7268\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4846 - val_loss: 1029.7267\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4847 - val_loss: 1029.7268\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4847 - val_loss: 1029.7266\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4847 - val_loss: 1029.7262\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4847 - val_loss: 1029.7256\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4847 - val_loss: 1029.7251\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4847 - val_loss: 1029.7249\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4848 - val_loss: 1029.7246\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4848 - val_loss: 1029.7242\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4848 - val_loss: 1029.7239\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4848 - val_loss: 1029.7234\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4848 - val_loss: 1029.7233\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4849 - val_loss: 1029.7233\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 82.4849 - val_loss: 1029.7223\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4850 - val_loss: 1029.7222\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4850 - val_loss: 1029.7217\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4850 - val_loss: 1029.7213\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4851 - val_loss: 1029.7211\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4851 - val_loss: 1029.7209\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4851 - val_loss: 1029.7209\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4851 - val_loss: 1029.7209\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4851 - val_loss: 1029.7207\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4851 - val_loss: 1029.7202\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4852 - val_loss: 1029.7200\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4852 - val_loss: 1029.7198\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4851 - val_loss: 1029.7191\n",
      "Epoch 478/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4852 - val_loss: 1029.7188\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4853 - val_loss: 1029.7185\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4853 - val_loss: 1029.7183\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4853 - val_loss: 1029.7188\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4853 - val_loss: 1029.7189\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4853 - val_loss: 1029.7185\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 82.4853 - val_loss: 1029.7179\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4853 - val_loss: 1029.7177\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4854 - val_loss: 1029.7172\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4853 - val_loss: 1029.7163\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4853 - val_loss: 1029.7152\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4853 - val_loss: 1029.7140\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4854 - val_loss: 1029.7131\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4854 - val_loss: 1029.7123\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4854 - val_loss: 1029.7113\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.4854 - val_loss: 1029.7106\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4854 - val_loss: 1029.7096\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4854 - val_loss: 1029.7081\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4854 - val_loss: 1029.7068\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4855 - val_loss: 1029.7057\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4855 - val_loss: 1029.7043\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4855 - val_loss: 1029.7026\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4855 - val_loss: 1029.7003\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 414ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61.90375817, 61.84493464, 61.78611111, 61.72728758, 61.66846405,\n",
       "        61.60964052, 61.57611111,  0.30991882,  0.35429442,  0.32987547,\n",
       "         0.3086533 ,  0.08268929,  0.        , 62.3208917 , 62.3124883 ,\n",
       "        62.304085  , 62.2697712 , 62.2109477 , 62.1521242 , 62.0933007 ,\n",
       "        62.0344771 , 61.9756536 , 61.9168301 , 61.8580065 , 61.799183  ,\n",
       "        61.7403595 , 61.6815359 , 61.6227124 , 61.5824603 , 63.9089869 ,\n",
       "        63.7325163 , 63.5560458 , 63.3795752 , 63.1754202 , 62.9485294 ,\n",
       "        62.7216387 , 62.4947479 , 62.3853175 ,  0.45828229,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.97055447,  0.        ,\n",
       "         0.        ,  0.        , 61.75343137, 61.69460784, 61.63578431,\n",
       "        61.58880952, 63.94820261, 63.77173203, 63.59526144, 63.41879085,\n",
       "        63.22584034, 62.99894958, 62.77205882, 62.54516807, 62.3909197 ,\n",
       "         0.20421855,  0.27068555, 63.3142157 , 63.0913866 , 62.8644958 ,\n",
       "        62.637605  , 62.4107143 , 62.3759804 , 62.3507703 , 62.3255602 ,\n",
       "        62.3003501 ,  0.        ,  0.        , 61.75678635,  0.        ,\n",
       "         0.11085498,  0.4965252 ,  0.        ,  0.44235113,  0.2936219 ,\n",
       "        60.18032074,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.42615733,  0.        ,  0.        ,\n",
       "         0.        ,  0.08253884,  0.        ,  0.45907435,  0.        ,\n",
       "         0.        ,  0.        ,  0.31261057,  1.02814138,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54.81474346, 54.8059985 , 54.79725354, 54.78850857, 54.77976361,\n",
       "       54.77101865, 54.76227369, 54.75352873, 54.74478377, 54.73603881,\n",
       "       54.72729384, 54.71854888, 54.70980392, 54.70105896, 54.692314  ,\n",
       "       54.68356904, 54.67482408, 54.66607911, 54.65733415, 54.64858919,\n",
       "       54.63984423, 54.63109927, 54.62235431, 54.61360935, 54.60486438,\n",
       "       54.59611942, 54.58737446, 54.5786295 , 54.56988454, 54.56113958,\n",
       "       54.55239462, 54.54364965, 54.53490469, 54.52615973, 54.51741477,\n",
       "       54.50866981, 54.49992485, 54.49117989, 54.48243493, 54.47368996,\n",
       "       54.464945  , 54.45620004, 54.44745508, 54.43871012, 54.42996516,\n",
       "       54.4212202 , 54.41247523, 54.40373027, 54.39498531, 54.38624035,\n",
       "       54.37749539, 54.36875043, 54.36000547, 54.3512605 , 54.34251554,\n",
       "       54.33377058, 54.32502562, 54.31628066, 54.3075357 , 54.29879074,\n",
       "       54.29004577, 54.28130081, 54.27255585, 54.26381089, 54.25506593,\n",
       "       54.24632097, 54.23757601, 54.22883104, 54.22008608, 54.21134112,\n",
       "       54.20259616, 54.1938512 , 54.18510624, 54.17636128, 54.16761631,\n",
       "       54.15887135, 54.15012639, 54.14138143, 54.13263647, 54.12389151,\n",
       "       54.11514655, 54.10640159, 54.09765662, 54.08891166, 54.0801667 ,\n",
       "       54.07142174, 54.06267678, 54.05393182, 54.04518686, 54.03644189,\n",
       "       54.02769693, 54.01895197, 54.01020701, 54.00146205, 53.99271709,\n",
       "       53.98397213, 53.97522716, 53.9664822 , 53.95773724, 53.94899228])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.365608934862465\n",
      "28.21650145245901\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
