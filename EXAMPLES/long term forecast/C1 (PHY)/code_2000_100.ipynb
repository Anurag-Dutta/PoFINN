{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2095    56.004365\n",
       "2096    55.988492\n",
       "2097    55.972619\n",
       "2098    55.956746\n",
       "2099    55.940873\n",
       "Name: C1, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_2000_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1995     0.442351\n",
       "1996     0.262234\n",
       "1997     0.148249\n",
       "1998     0.293622\n",
       "1999     0.706635\n",
       "Name: C1, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2000)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1550, 1, 251) (1550, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 3s 28ms/step - loss: 4476.5322 - val_loss: 3101.8479\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4406.0205 - val_loss: 3062.0369\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4343.8076 - val_loss: 3004.0928\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4266.2607 - val_loss: 2960.7952\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4204.6646 - val_loss: 2918.4233\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4144.3657 - val_loss: 2877.0100\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4085.1826 - val_loss: 2836.3682\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4026.9165 - val_loss: 2796.3887\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3969.4568 - val_loss: 2757.0110\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3912.7388 - val_loss: 2718.1951\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3856.7190 - val_loss: 2679.9160\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3801.3701 - val_loss: 2642.1558\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3746.6702 - val_loss: 2604.8987\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3692.6035 - val_loss: 2568.1338\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3639.1558 - val_loss: 2531.8521\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3586.3149 - val_loss: 2496.0439\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3534.0725 - val_loss: 2460.7031\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 3482.4189 - val_loss: 2425.8230\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 3431.3472 - val_loss: 2391.3967\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3380.8491 - val_loss: 2357.4192\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 3330.9192 - val_loss: 2323.8853\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3281.5496 - val_loss: 2290.7900\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 3232.7351 - val_loss: 2258.1279\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3184.4705 - val_loss: 2225.8955\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3136.7495 - val_loss: 2194.0879\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3089.5669 - val_loss: 2162.7009\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3042.9185 - val_loss: 2131.7307\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2996.7986 - val_loss: 2101.1726\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2951.2026 - val_loss: 2071.0229\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2906.1257 - val_loss: 2041.2781\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2861.5630 - val_loss: 2011.9337\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2817.5110 - val_loss: 1982.9863\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2773.9639 - val_loss: 1954.4319\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2730.9185 - val_loss: 1926.2659\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2688.3696 - val_loss: 1898.4827\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2646.3137 - val_loss: 1871.0680\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2603.8445 - val_loss: 1833.9111\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2546.1580 - val_loss: 1802.6525\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2499.2468 - val_loss: 1772.5037\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2454.1162 - val_loss: 1743.5807\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2410.4509 - val_loss: 1715.5756\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2367.9028 - val_loss: 1688.3123\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 2326.2781 - val_loss: 1661.6884\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2285.4597 - val_loss: 1635.6409\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2245.3730 - val_loss: 1610.1250\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2205.9646 - val_loss: 1585.1093\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2167.1963 - val_loss: 1560.5693\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2129.0374 - val_loss: 1536.4858\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2091.4646 - val_loss: 1512.8427\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2054.4565 - val_loss: 1489.6260\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2017.9978 - val_loss: 1466.8252\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1982.0734 - val_loss: 1444.4296\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1946.6705 - val_loss: 1422.4304\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1911.7787 - val_loss: 1400.8193\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1877.3865 - val_loss: 1379.5894\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1843.4857 - val_loss: 1358.7333\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1810.0675 - val_loss: 1338.2449\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1777.1246 - val_loss: 1318.1189\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1744.6492 - val_loss: 1298.3492\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1712.6343 - val_loss: 1278.9309\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1681.0741 - val_loss: 1259.8585\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1649.9615 - val_loss: 1241.1276\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1619.2917 - val_loss: 1222.7330\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1589.0579 - val_loss: 1204.6714\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1559.2555 - val_loss: 1186.9379\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1529.8794 - val_loss: 1169.5282\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1500.9244 - val_loss: 1152.4384\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1472.3857 - val_loss: 1135.6652\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1444.2584 - val_loss: 1119.2039\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1416.5377 - val_loss: 1103.0508\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1389.2196 - val_loss: 1087.2034\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1362.2994 - val_loss: 1071.6569\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1335.7732 - val_loss: 1056.4083\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1309.6367 - val_loss: 1041.4540\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1283.8855 - val_loss: 1026.7909\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1258.5155 - val_loss: 1012.4154\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1233.5231 - val_loss: 998.3241\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1208.9041 - val_loss: 984.5141\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1184.6543 - val_loss: 970.9819\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1160.7710 - val_loss: 957.7247\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1137.2495 - val_loss: 944.7389\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1114.0865 - val_loss: 932.0217\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1091.2783 - val_loss: 919.5699\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1068.8214 - val_loss: 907.3809\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1046.7120 - val_loss: 895.4509\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1024.9471 - val_loss: 883.7778\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1003.5227 - val_loss: 872.3582\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 982.4355 - val_loss: 861.1889\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 961.6818 - val_loss: 850.2673\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 941.2585 - val_loss: 839.5908\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 921.1624 - val_loss: 829.1561\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 901.3901 - val_loss: 818.9606\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 881.9382 - val_loss: 809.0015\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 862.8034 - val_loss: 799.2758\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 843.9826 - val_loss: 789.7806\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 825.4722 - val_loss: 780.5135\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 807.2690 - val_loss: 771.4715\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 789.3702 - val_loss: 762.6520\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 771.7730 - val_loss: 754.0522\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 754.4733 - val_loss: 745.6693\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 737.4683 - val_loss: 737.5007\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 720.7550 - val_loss: 729.5438\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 704.3303 - val_loss: 721.7956\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 688.1913 - val_loss: 714.2536\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 672.3344 - val_loss: 706.9155\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 656.7574 - val_loss: 699.7781\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 641.4568 - val_loss: 692.8392\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 626.4294 - val_loss: 686.0961\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 611.6724 - val_loss: 679.5458\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 597.1832 - val_loss: 673.1860\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 582.9581 - val_loss: 667.0144\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 568.9948 - val_loss: 661.0279\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 555.2899 - val_loss: 655.2243\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 541.8406 - val_loss: 649.6004\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 528.6437 - val_loss: 644.1545\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 515.6969 - val_loss: 638.8835\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 502.9970 - val_loss: 633.7850\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 490.5410 - val_loss: 628.8566\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 478.3264 - val_loss: 624.0956\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 466.3499 - val_loss: 619.4995\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 454.6089 - val_loss: 615.0658\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 443.1002 - val_loss: 610.7921\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 431.8215 - val_loss: 606.6755\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 420.7697 - val_loss: 602.7141\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 409.9422 - val_loss: 598.9052\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 399.3359 - val_loss: 595.2462\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 388.9482 - val_loss: 591.7347\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 378.7762 - val_loss: 588.3682\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 368.8173 - val_loss: 585.1443\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 359.0686 - val_loss: 582.0606\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 349.5275 - val_loss: 579.1147\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 340.1914 - val_loss: 576.3040\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 331.0570 - val_loss: 573.6262\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 322.1221 - val_loss: 571.0788\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 313.3837 - val_loss: 568.6595\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 304.8393 - val_loss: 566.3657\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 296.4858 - val_loss: 564.1952\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 288.3210 - val_loss: 562.1456\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 280.3421 - val_loss: 560.2145\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 272.5464 - val_loss: 558.3996\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 264.9311 - val_loss: 556.6984\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 257.4937 - val_loss: 555.1086\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 250.2316 - val_loss: 553.6279\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 243.1422 - val_loss: 552.2538\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 236.2227 - val_loss: 550.9843\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 229.4707 - val_loss: 549.8170\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 222.8834 - val_loss: 548.7493\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 216.4585 - val_loss: 547.7791\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 210.1930 - val_loss: 546.9042\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 204.0847 - val_loss: 546.1223\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 198.1310 - val_loss: 545.4312\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 192.3292 - val_loss: 544.8284\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 186.6772 - val_loss: 544.3118\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.1722 - val_loss: 543.8793\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 175.8116 - val_loss: 543.5285\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.5931 - val_loss: 543.2573\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 165.5139 - val_loss: 543.0635\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 160.5719 - val_loss: 542.9449\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 155.7643 - val_loss: 542.8992\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 151.0891 - val_loss: 542.9243\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 146.5436 - val_loss: 543.0181\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 142.1255 - val_loss: 543.1783\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 137.8321 - val_loss: 543.4019\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 133.6615 - val_loss: 543.6063\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 128.7471 - val_loss: 544.3409\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 123.3112 - val_loss: 545.0140\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 118.3244 - val_loss: 545.7435\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 113.7403 - val_loss: 546.5282\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 109.4640 - val_loss: 547.3668\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 105.4378 - val_loss: 548.2576\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 101.6261 - val_loss: 549.1979\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 98.0048 - val_loss: 550.1851\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 94.5561 - val_loss: 551.2165\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 91.2664 - val_loss: 552.2894\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 88.1244 - val_loss: 553.4013\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 85.1211 - val_loss: 554.5496\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 82.2485 - val_loss: 555.7319\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 79.4997 - val_loss: 556.9458\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 76.8685 - val_loss: 558.1889\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 74.3495 - val_loss: 559.4590\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 71.9374 - val_loss: 560.7541\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 69.6276 - val_loss: 562.0718\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 67.4159 - val_loss: 563.4101\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 65.2982 - val_loss: 564.7671\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 63.2706 - val_loss: 566.1408\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 61.3296 - val_loss: 567.5295\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 59.4718 - val_loss: 568.9311\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 57.6940 - val_loss: 570.3442\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 55.9930 - val_loss: 571.7667\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 54.3660 - val_loss: 573.1973\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 52.8101 - val_loss: 574.6341\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 51.3225 - val_loss: 576.0760\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 49.9007 - val_loss: 577.5211\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 48.5423 - val_loss: 578.9679\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 47.2447 - val_loss: 580.4153\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 46.0056 - val_loss: 581.8620\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 44.8228 - val_loss: 583.3065\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 43.6941 - val_loss: 584.7474\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 42.6175 - val_loss: 586.1839\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 41.5909 - val_loss: 587.6146\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 40.6123 - val_loss: 589.0384\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 39.6799 - val_loss: 590.4543\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 38.7917 - val_loss: 591.8613\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 37.9461 - val_loss: 593.2585\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 37.1413 - val_loss: 594.6447\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 36.3757 - val_loss: 596.0193\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 35.6476 - val_loss: 597.3814\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 34.9554 - val_loss: 598.7300\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 34.2978 - val_loss: 600.0647\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 33.6733 - val_loss: 601.3845\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 33.0803 - val_loss: 602.6888\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 32.5176 - val_loss: 603.9771\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 31.9839 - val_loss: 605.2485\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 31.4778 - val_loss: 606.5027\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 30.9983 - val_loss: 607.7391\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 30.5440 - val_loss: 608.9573\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 30.1138 - val_loss: 610.1569\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 29.7067 - val_loss: 611.3373\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 29.3216 - val_loss: 612.4983\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 28.9574 - val_loss: 613.6391\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 28.6133 - val_loss: 614.7603\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 28.2881 - val_loss: 615.8611\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 27.9810 - val_loss: 616.9413\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 27.6912 - val_loss: 618.0009\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 27.4177 - val_loss: 619.0393\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 27.1598 - val_loss: 620.0566\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 26.9167 - val_loss: 621.0531\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 26.6876 - val_loss: 622.0281\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 26.4719 - val_loss: 622.9819\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 26.2688 - val_loss: 623.9142\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 26.0777 - val_loss: 624.8251\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 25.8980 - val_loss: 625.7150\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 25.7291 - val_loss: 626.5833\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 25.5703 - val_loss: 627.4307\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 25.4212 - val_loss: 628.2570\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 25.2811 - val_loss: 629.0621\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 25.1497 - val_loss: 629.8465\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 25.0264 - val_loss: 630.6100\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 24.9108 - val_loss: 631.3528\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 24.8024 - val_loss: 632.0757\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 24.7008 - val_loss: 632.7782\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 24.6057 - val_loss: 633.4609\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 24.5166 - val_loss: 634.1237\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 24.4333 - val_loss: 634.7675\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 24.3553 - val_loss: 635.3917\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 24.2823 - val_loss: 635.9972\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 24.2141 - val_loss: 636.5837\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 24.1503 - val_loss: 637.1522\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 24.0908 - val_loss: 637.7025\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 24.0351 - val_loss: 638.2352\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.9832 - val_loss: 638.7502\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.9347 - val_loss: 639.2482\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.8894 - val_loss: 639.7295\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.8472 - val_loss: 640.1943\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.8078 - val_loss: 640.6429\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.7711 - val_loss: 641.0758\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.7369 - val_loss: 641.4937\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.7050 - val_loss: 641.8965\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.6752 - val_loss: 642.2843\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.6475 - val_loss: 642.6578\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.6218 - val_loss: 643.0175\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.5977 - val_loss: 643.3633\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.5754 - val_loss: 643.6960\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 23.5545 - val_loss: 644.0157\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.5351 - val_loss: 644.3230\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.5170 - val_loss: 644.6180\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.5002 - val_loss: 644.9010\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.4846 - val_loss: 645.1726\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.4701 - val_loss: 645.4329\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.4566 - val_loss: 645.6826\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.4440 - val_loss: 645.9214\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.4323 - val_loss: 646.1503\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.4215 - val_loss: 646.3696\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.4113 - val_loss: 646.5790\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.4019 - val_loss: 646.7791\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3932 - val_loss: 646.9702\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3851 - val_loss: 647.1529\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3776 - val_loss: 647.3270\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3706 - val_loss: 647.4937\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3641 - val_loss: 647.6523\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3581 - val_loss: 647.8034\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3525 - val_loss: 647.9474\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 23.3473 - val_loss: 648.0847\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3425 - val_loss: 648.2148\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3381 - val_loss: 648.3391\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3340 - val_loss: 648.4574\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3301 - val_loss: 648.5694\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3266 - val_loss: 648.6757\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3234 - val_loss: 648.7770\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3203 - val_loss: 648.8730\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3175 - val_loss: 648.9637\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3149 - val_loss: 649.0499\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3126 - val_loss: 649.1315\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3104 - val_loss: 649.2088\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3084 - val_loss: 649.2820\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3065 - val_loss: 649.3509\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3049 - val_loss: 649.4158\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3033 - val_loss: 649.4776\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3019 - val_loss: 649.5356\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3007 - val_loss: 649.5905\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2995 - val_loss: 649.6425\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2985 - val_loss: 649.6912\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2975 - val_loss: 649.7370\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2967 - val_loss: 649.7802\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2959 - val_loss: 649.8209\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2953 - val_loss: 649.8591\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2947 - val_loss: 649.8951\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2942 - val_loss: 649.9290\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 23.2937 - val_loss: 649.9605\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.2934 - val_loss: 649.9901\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.2930 - val_loss: 650.0178\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2928 - val_loss: 650.0439\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2926 - val_loss: 650.0684\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2924 - val_loss: 650.0911\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2923 - val_loss: 650.1123\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2922 - val_loss: 650.1320\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2922 - val_loss: 650.1506\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2922 - val_loss: 650.1676\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2923 - val_loss: 650.1837\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2924 - val_loss: 650.1985\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2925 - val_loss: 650.2123\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2926 - val_loss: 650.2249\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2928 - val_loss: 650.2368\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2930 - val_loss: 650.2479\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2932 - val_loss: 650.2581\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2934 - val_loss: 650.2675\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2937 - val_loss: 650.2762\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2940 - val_loss: 650.2840\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2943 - val_loss: 650.2917\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2946 - val_loss: 650.2982\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 23.2949 - val_loss: 650.3043\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.2953 - val_loss: 650.3099\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.2956 - val_loss: 650.3147\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2960 - val_loss: 650.3193\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2964 - val_loss: 650.3236\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2967 - val_loss: 650.3273\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2972 - val_loss: 650.3307\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2976 - val_loss: 650.3337\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2979 - val_loss: 650.3363\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2984 - val_loss: 650.3386\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2988 - val_loss: 650.3409\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2992 - val_loss: 650.3431\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2997 - val_loss: 650.3448\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3001 - val_loss: 650.3463\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3005 - val_loss: 650.3474\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3009 - val_loss: 650.3483\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3014 - val_loss: 650.3491\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3018 - val_loss: 650.3495\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3023 - val_loss: 650.3499\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3028 - val_loss: 650.3503\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 23.3032 - val_loss: 650.3509\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 23.3036 - val_loss: 650.3511\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3041 - val_loss: 650.3510\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3045 - val_loss: 650.3510\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3049 - val_loss: 650.3507\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3054 - val_loss: 650.3505\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3058 - val_loss: 650.3499\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3063 - val_loss: 650.3495\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3067 - val_loss: 650.3490\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3071 - val_loss: 650.3486\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3076 - val_loss: 650.3480\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 23.3080 - val_loss: 650.3471\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3084 - val_loss: 650.3464\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3089 - val_loss: 650.3459\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3093 - val_loss: 650.3450\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3097 - val_loss: 650.3442\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3101 - val_loss: 650.3433\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3106 - val_loss: 650.3420\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3109 - val_loss: 650.3411\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 23.3114 - val_loss: 650.3404\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3118 - val_loss: 650.3393\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3122 - val_loss: 650.3384\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3126 - val_loss: 650.3374\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3129 - val_loss: 650.3362\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3134 - val_loss: 650.3353\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3137 - val_loss: 650.3341\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3141 - val_loss: 650.3328\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3145 - val_loss: 650.3317\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3149 - val_loss: 650.3307\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3153 - val_loss: 650.3299\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3156 - val_loss: 650.3290\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3159 - val_loss: 650.3279\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3163 - val_loss: 650.3267\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3167 - val_loss: 650.3257\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3171 - val_loss: 650.3246\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3174 - val_loss: 650.3235\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3178 - val_loss: 650.3228\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3181 - val_loss: 650.3217\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3184 - val_loss: 650.3205\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3187 - val_loss: 650.3196\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 23.3191 - val_loss: 650.3185\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 23.3194 - val_loss: 650.3176\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3197 - val_loss: 650.3169\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3200 - val_loss: 650.3159\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3203 - val_loss: 650.3151\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3206 - val_loss: 650.3141\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3209 - val_loss: 650.3129\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3212 - val_loss: 650.3121\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3215 - val_loss: 650.3111\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3218 - val_loss: 650.3100\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3221 - val_loss: 650.3092\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3224 - val_loss: 650.3085\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3226 - val_loss: 650.3076\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3229 - val_loss: 650.3068\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3232 - val_loss: 650.3058\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3234 - val_loss: 650.3049\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3237 - val_loss: 650.3041\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3240 - val_loss: 650.3032\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3242 - val_loss: 650.3022\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 23.3245 - val_loss: 650.3018\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3247 - val_loss: 650.3009\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3249 - val_loss: 650.2999\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3252 - val_loss: 650.2991\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3255 - val_loss: 650.2985\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3257 - val_loss: 650.2977\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3259 - val_loss: 650.2969\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3261 - val_loss: 650.2961\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3263 - val_loss: 650.2954\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3265 - val_loss: 650.2947\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3267 - val_loss: 650.2939\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3270 - val_loss: 650.2933\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3271 - val_loss: 650.2924\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3274 - val_loss: 650.2917\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3276 - val_loss: 650.2910\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3278 - val_loss: 650.2903\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3280 - val_loss: 650.2896\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3282 - val_loss: 650.2890\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3284 - val_loss: 650.2882\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3285 - val_loss: 650.2874\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 23.3287 - val_loss: 650.2868\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3289 - val_loss: 650.2858\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3291 - val_loss: 650.2856\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3293 - val_loss: 650.2851\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3295 - val_loss: 650.2845\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3296 - val_loss: 650.2840\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3298 - val_loss: 650.2834\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3299 - val_loss: 650.2827\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3301 - val_loss: 650.2821\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3302 - val_loss: 650.2813\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3304 - val_loss: 650.2807\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3305 - val_loss: 650.2800\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3307 - val_loss: 650.2795\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3309 - val_loss: 650.2791\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3310 - val_loss: 650.2785\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3311 - val_loss: 650.2778\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3313 - val_loss: 650.2772\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3314 - val_loss: 650.2767\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3316 - val_loss: 650.2762\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3317 - val_loss: 650.2756\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 23.3318 - val_loss: 650.2750\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3320 - val_loss: 650.2745\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3321 - val_loss: 650.2740\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3322 - val_loss: 650.2736\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3323 - val_loss: 650.2733\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3324 - val_loss: 650.2727\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3326 - val_loss: 650.2723\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3327 - val_loss: 650.2718\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3328 - val_loss: 650.2715\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3330 - val_loss: 650.2712\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3330 - val_loss: 650.2708\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3331 - val_loss: 650.2701\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3332 - val_loss: 650.2700\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3333 - val_loss: 650.2695\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3334 - val_loss: 650.2689\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3335 - val_loss: 650.2684\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3337 - val_loss: 650.2681\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3337 - val_loss: 650.2678\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3338 - val_loss: 650.2675\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3339 - val_loss: 650.2670\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3340 - val_loss: 650.2667\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 23.3341 - val_loss: 650.2664\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3342 - val_loss: 650.2659\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3343 - val_loss: 650.2655\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3344 - val_loss: 650.2653\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3345 - val_loss: 650.2651\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3345 - val_loss: 650.2648\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3346 - val_loss: 650.2643\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3347 - val_loss: 650.2640\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3347 - val_loss: 650.2634\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3348 - val_loss: 650.2632\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3349 - val_loss: 650.2626\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3350 - val_loss: 650.2623\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3351 - val_loss: 650.2619\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3352 - val_loss: 650.2617\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3352 - val_loss: 650.2612\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3353 - val_loss: 650.2609\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3353 - val_loss: 650.2607\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3353 - val_loss: 650.2601\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3355 - val_loss: 650.2600\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 23.3355 - val_loss: 650.2597\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3356 - val_loss: 650.2596\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3356 - val_loss: 650.2593\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3357 - val_loss: 650.2590\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3358 - val_loss: 650.2587\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3358 - val_loss: 650.2583\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3359 - val_loss: 650.2582\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3359 - val_loss: 650.2581\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3360 - val_loss: 650.2579\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 23.3360 - val_loss: 650.2573\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3360 - val_loss: 650.2570\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 445ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62.67121849, 62.59558824, 62.51995798, 62.44432773, 62.39652194,\n",
       "        62.38811858, 62.37971522,  0.59277862,  0.13026485,  0.        ,\n",
       "         0.07421523,  0.        ,  0.93613142, 63.3534314 , 63.2930672 ,\n",
       "        63.217437  , 63.1418067 , 63.0661765 , 62.9905462 , 62.914916  ,\n",
       "        62.8392857 , 62.7636555 , 62.6880252 , 62.612395  , 62.5367647 ,\n",
       "        62.4611345 , 62.3983894 , 62.389986  , 62.3815826 , 62.3731793 ,\n",
       "        62.3647759 , 62.3563726 , 62.3479692 , 62.3395658 , 62.3311625 ,\n",
       "        62.3227591 , 62.3143557 , 62.3059524 , 62.2828431 , 62.2240196 ,\n",
       "         0.9198972 ,  0.        ,  0.59846479,  1.17285824,  0.        ,\n",
       "         1.02453041,  0.        , 62.47794118, 62.40231092, 62.39185341,\n",
       "        62.38345005, 62.37504669, 62.36664332, 62.35823996, 62.3498366 ,\n",
       "        62.34143324, 62.33302988, 62.32462652, 62.31622316, 62.30781979,\n",
       "        62.29591503, 62.2370915 , 62.17826797, 62.11944444, 62.06062092,\n",
       "        62.00179739, 61.94297386, 61.88415033, 61.8253268 , 61.76650327,\n",
       "        61.70767974, 61.64885621, 61.59515873, 68.71121979,  0.6269477 ,\n",
       "         0.21235818,  0.09256098,  0.43633798,  0.        ,  0.        ,\n",
       "        41.76460648,  0.40098166,  0.3253856 ,  0.        ,  0.        ,\n",
       "         0.28696507,  0.        ,  0.        ,  0.        ,  0.26552701,\n",
       "         0.4546504 ,  0.66112316,  0.28979445,  0.        ,  0.64273834,\n",
       "         0.        ,  0.07518099,  0.        ,  0.14663041,  0.28230149]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([57.51230159, 57.49642857, 57.48055556, 57.46468254, 57.44880952,\n",
       "       57.43293651, 57.41706349, 57.40119048, 57.38531746, 57.36944444,\n",
       "       57.35357143, 57.33769841, 57.3218254 , 57.30595238, 57.29007937,\n",
       "       57.27420635, 57.25833333, 57.24246032, 57.2265873 , 57.21071429,\n",
       "       57.19484127, 57.17896825, 57.16309524, 57.14722222, 57.13134921,\n",
       "       57.11547619, 57.09960317, 57.08373016, 57.06785714, 57.05198413,\n",
       "       57.03611111, 57.0202381 , 57.00436508, 56.98849206, 56.97261905,\n",
       "       56.95674603, 56.94087302, 56.925     , 56.90912698, 56.89325397,\n",
       "       56.87738095, 56.86150794, 56.84563492, 56.8297619 , 56.81388889,\n",
       "       56.79801587, 56.78214286, 56.76626984, 56.75039683, 56.73452381,\n",
       "       56.71865079, 56.70277778, 56.68690476, 56.67103175, 56.65515873,\n",
       "       56.63928571, 56.6234127 , 56.60753968, 56.59166667, 56.57579365,\n",
       "       56.55992063, 56.54404762, 56.5281746 , 56.51230159, 56.49642857,\n",
       "       56.48055556, 56.46468254, 56.44880952, 56.43293651, 56.41706349,\n",
       "       56.40119048, 56.38531746, 56.36944444, 56.35357143, 56.33769841,\n",
       "       56.3218254 , 56.30595238, 56.29007937, 56.27420635, 56.25833333,\n",
       "       56.24246032, 56.2265873 , 56.21071429, 56.19484127, 56.17896825,\n",
       "       56.16309524, 56.14722222, 56.13134921, 56.11547619, 56.09960317,\n",
       "       56.08373016, 56.06785714, 56.05198413, 56.03611111, 56.0202381 ,\n",
       "       56.00436508, 55.98849206, 55.97261905, 55.95674603, 55.94087302])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.94343412716264\n",
      "24.908361219281737\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
