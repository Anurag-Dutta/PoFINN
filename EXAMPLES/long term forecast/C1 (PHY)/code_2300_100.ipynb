{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2395    53.109476\n",
       "2396    53.100731\n",
       "2397    53.091986\n",
       "2398    53.083241\n",
       "2399    53.074496\n",
       "Name: C1, Length: 2400, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_2300_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2295     0.000000\n",
       "2296     0.000000\n",
       "2297     0.312611\n",
       "2298     1.028141\n",
       "2299     0.000000\n",
       "Name: C1, Length: 2300, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2300)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1850, 1, 251) (1850, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 2s 27ms/step - loss: 4169.3984 - val_loss: 2525.1252\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3998.6550 - val_loss: 2397.4834\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3858.3228 - val_loss: 2320.7573\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3756.9294 - val_loss: 2258.4141\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3655.7834 - val_loss: 2200.3037\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3561.1011 - val_loss: 2139.5757\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3470.0349 - val_loss: 2084.6648\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3381.7632 - val_loss: 2031.7142\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3295.8628 - val_loss: 1980.5221\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3212.0925 - val_loss: 1930.9623\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3130.2969 - val_loss: 1882.9462\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3050.3665 - val_loss: 1836.3656\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2972.2183 - val_loss: 1787.6144\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2885.8635 - val_loss: 1739.2208\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2799.9136 - val_loss: 1689.6307\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2716.8872 - val_loss: 1643.8553\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2637.6526 - val_loss: 1600.4806\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2561.4534 - val_loss: 1559.0802\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2487.7507 - val_loss: 1519.4199\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2416.2449 - val_loss: 1481.3557\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2346.7493 - val_loss: 1444.7888\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2279.1333 - val_loss: 1409.6439\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2213.2991 - val_loss: 1375.8613\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2149.1702 - val_loss: 1343.3910\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2086.6829 - val_loss: 1312.1887\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2025.7825 - val_loss: 1282.2162\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1966.4215 - val_loss: 1253.4382\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1908.5574 - val_loss: 1225.8223\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1852.1523 - val_loss: 1199.3380\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1797.1698 - val_loss: 1173.9572\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1743.5780 - val_loss: 1149.6520\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1691.3445 - val_loss: 1126.3967\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1640.4412 - val_loss: 1104.1665\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1590.8392 - val_loss: 1082.9368\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1542.5122 - val_loss: 1062.6847\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1495.4341 - val_loss: 1043.3866\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1449.5797 - val_loss: 1025.0206\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1404.9260 - val_loss: 1007.5649\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1361.4478 - val_loss: 990.9983\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1319.1238 - val_loss: 975.2995\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1277.9307 - val_loss: 960.4478\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1237.8467 - val_loss: 946.4236\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1198.8507 - val_loss: 933.2064\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1160.9219 - val_loss: 920.7766\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1124.0392 - val_loss: 909.1147\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1088.1825 - val_loss: 898.2020\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1053.3319 - val_loss: 888.0191\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1019.4677 - val_loss: 878.5476\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 986.5709 - val_loss: 869.7689\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 954.6219 - val_loss: 861.6651\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 923.6021 - val_loss: 854.2177\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 893.4932 - val_loss: 847.4091\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 864.2762 - val_loss: 841.2216\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 835.9335 - val_loss: 835.6378\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 808.4477 - val_loss: 830.6402\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 781.8002 - val_loss: 826.2119\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 755.9736 - val_loss: 822.3356\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 730.9509 - val_loss: 818.9950\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 706.7150 - val_loss: 816.1733\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 683.2491 - val_loss: 813.8539\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 660.5364 - val_loss: 812.0208\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 638.5601 - val_loss: 810.6577\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 617.3042 - val_loss: 809.7488\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 596.7524 - val_loss: 809.2782\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 576.8886 - val_loss: 809.2305\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 557.6970 - val_loss: 809.5900\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 539.1621 - val_loss: 810.3417\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 521.2681 - val_loss: 811.4705\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 504.0001 - val_loss: 812.9611\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 487.3424 - val_loss: 814.7993\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 471.2803 - val_loss: 816.9703\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 455.7992 - val_loss: 819.4597\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 440.8840 - val_loss: 822.2532\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 426.5207 - val_loss: 825.3371\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 412.6947 - val_loss: 828.6972\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 399.3921 - val_loss: 832.3203\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 386.5988 - val_loss: 836.1925\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 374.3008 - val_loss: 840.3008\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 362.4847 - val_loss: 844.6318\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.1372 - val_loss: 849.1734\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 340.2448 - val_loss: 853.9124\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 329.7946 - val_loss: 858.8364\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 319.7737 - val_loss: 863.9333\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 310.1693 - val_loss: 869.1910\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 300.9691 - val_loss: 874.5980\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 292.1605 - val_loss: 880.1425\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 283.7315 - val_loss: 885.8132\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 275.6701 - val_loss: 891.5992\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 267.9645 - val_loss: 897.4895\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 260.6031 - val_loss: 903.4734\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 253.5747 - val_loss: 909.5409\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 246.8680 - val_loss: 915.6814\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 240.4721 - val_loss: 921.8856\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 234.3761 - val_loss: 928.1436\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 228.5696 - val_loss: 934.4459\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 223.0424 - val_loss: 940.7836\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 217.7838 - val_loss: 947.1478\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 212.7844 - val_loss: 953.5304\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 208.0343 - val_loss: 959.9221\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 203.5239 - val_loss: 966.3160\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 199.2440 - val_loss: 972.7036\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 195.1854 - val_loss: 979.0781\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 191.3393 - val_loss: 985.4319\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 187.6971 - val_loss: 991.7579\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 184.2503 - val_loss: 998.0497\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 180.9908 - val_loss: 1004.3015\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 177.9104 - val_loss: 1010.5062\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 175.0014 - val_loss: 1016.6589\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 172.2562 - val_loss: 1022.7540\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 169.6675 - val_loss: 1028.7858\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 167.2281 - val_loss: 1034.7500\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 164.9312 - val_loss: 1040.6412\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.7700 - val_loss: 1046.4559\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 160.7381 - val_loss: 1052.1891\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 158.8289 - val_loss: 1057.8376\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 157.0369 - val_loss: 1063.3979\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 155.3558 - val_loss: 1068.8667\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 153.7800 - val_loss: 1074.2402\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 152.3040 - val_loss: 1079.5165\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.9229 - val_loss: 1084.6927\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 149.6313 - val_loss: 1089.7671\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 148.4244 - val_loss: 1094.7368\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 147.2977 - val_loss: 1099.6011\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 146.2464 - val_loss: 1104.3575\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 145.2667 - val_loss: 1109.0050\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 144.3541 - val_loss: 1113.5433\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 143.5047 - val_loss: 1117.9706\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 142.7149 - val_loss: 1122.2864\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 141.9812 - val_loss: 1126.4908\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 141.2999 - val_loss: 1130.5829\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 140.6680 - val_loss: 1134.5632\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 140.0822 - val_loss: 1138.4313\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 139.5398 - val_loss: 1142.1890\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 139.0377 - val_loss: 1145.8346\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 138.5735 - val_loss: 1149.3700\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 138.1446 - val_loss: 1152.7958\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 137.7487 - val_loss: 1156.1129\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 137.3835 - val_loss: 1159.3234\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 137.0469 - val_loss: 1162.4269\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 136.7368 - val_loss: 1165.4249\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 136.4515 - val_loss: 1168.3195\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 136.1892 - val_loss: 1171.1125\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 135.9480 - val_loss: 1173.8049\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 135.7266 - val_loss: 1176.3986\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 135.5235 - val_loss: 1178.8953\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 135.3372 - val_loss: 1181.2970\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 135.1666 - val_loss: 1183.6062\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 135.0104 - val_loss: 1185.8241\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 134.8674 - val_loss: 1187.9532\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 134.7367 - val_loss: 1189.9965\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 134.6172 - val_loss: 1191.9537\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 134.5081 - val_loss: 1193.8293\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 134.4085 - val_loss: 1195.6246\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 134.3177 - val_loss: 1197.3417\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 134.2349 - val_loss: 1198.9829\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 134.1595 - val_loss: 1200.5505\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 134.0908 - val_loss: 1202.0471\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 134.0283 - val_loss: 1203.4750\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.9714 - val_loss: 1204.8357\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.9197 - val_loss: 1206.1320\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.8727 - val_loss: 1207.3658\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.8300 - val_loss: 1208.5389\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.7913 - val_loss: 1209.6545\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.7561 - val_loss: 1210.7141\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.7243 - val_loss: 1211.7200\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.6954 - val_loss: 1212.6738\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.6691 - val_loss: 1213.5789\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 133.6454 - val_loss: 1214.4360\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.6238 - val_loss: 1215.2463\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 133.6044 - val_loss: 1216.0133\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.5868 - val_loss: 1216.7386\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.5708 - val_loss: 1217.4241\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5565 - val_loss: 1218.0708\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5435 - val_loss: 1218.6808\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.5317 - val_loss: 1219.2562\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.5211 - val_loss: 1219.7976\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5116 - val_loss: 1220.3080\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5030 - val_loss: 1220.7875\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4953 - val_loss: 1221.2389\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4883 - val_loss: 1221.6627\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4821 - val_loss: 1222.0604\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4765 - val_loss: 1222.4332\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4715 - val_loss: 1222.7842\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4670 - val_loss: 1223.1116\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 133.4631 - val_loss: 1223.4187\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.4595 - val_loss: 1223.7057\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4564 - val_loss: 1223.9735\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4537 - val_loss: 1224.2244\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4513 - val_loss: 1224.4590\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.4492 - val_loss: 1224.6777\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.4474 - val_loss: 1224.8812\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4459 - val_loss: 1225.0708\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4445 - val_loss: 1225.2471\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.4434 - val_loss: 1225.4121\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4425 - val_loss: 1225.5635\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4418 - val_loss: 1225.7063\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4412 - val_loss: 1225.8380\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4408 - val_loss: 1225.9598\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4404 - val_loss: 1226.0728\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4403 - val_loss: 1226.1772\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4402 - val_loss: 1226.2745\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4403 - val_loss: 1226.3639\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4405 - val_loss: 1226.4463\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4407 - val_loss: 1226.5220\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4410 - val_loss: 1226.5924\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4414 - val_loss: 1226.6571\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4418 - val_loss: 1226.7170\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4423 - val_loss: 1226.7716\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4429 - val_loss: 1226.8217\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4435 - val_loss: 1226.8677\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4442 - val_loss: 1226.9097\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4449 - val_loss: 1226.9489\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 133.4456 - val_loss: 1226.9841\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4464 - val_loss: 1227.0168\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4472 - val_loss: 1227.0459\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4480 - val_loss: 1227.0728\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 133.4488 - val_loss: 1227.0978\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4497 - val_loss: 1227.1202\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4505 - val_loss: 1227.1407\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4514 - val_loss: 1227.1595\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4523 - val_loss: 1227.1775\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4532 - val_loss: 1225.0615\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.6956 - val_loss: 1226.6301\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5092 - val_loss: 1226.7860\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4929 - val_loss: 1226.8458\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4879 - val_loss: 1226.8903\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4852 - val_loss: 1226.9270\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4835 - val_loss: 1226.9586\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4825 - val_loss: 1226.9858\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4819 - val_loss: 1227.0106\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4816 - val_loss: 1227.0323\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4814 - val_loss: 1227.0511\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4814 - val_loss: 1227.0677\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4816 - val_loss: 1227.0829\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4817 - val_loss: 1227.0962\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4820 - val_loss: 1227.1072\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4824 - val_loss: 1227.1174\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4827 - val_loss: 1227.1259\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4832 - val_loss: 1227.1334\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4837 - val_loss: 1227.1404\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4842 - val_loss: 1227.1470\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 133.4847 - val_loss: 1227.1515\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.4852 - val_loss: 1227.1556\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4858 - val_loss: 1227.1598\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4864 - val_loss: 1227.1625\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4870 - val_loss: 1227.1646\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4876 - val_loss: 1227.1667\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4881 - val_loss: 1227.1682\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4888 - val_loss: 1227.1696\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4894 - val_loss: 1227.1707\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4899 - val_loss: 1227.1709\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4906 - val_loss: 1227.1710\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4912 - val_loss: 1227.1707\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4918 - val_loss: 1227.1702\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4924 - val_loss: 1227.1700\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4930 - val_loss: 1227.1696\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4935 - val_loss: 1227.1680\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4942 - val_loss: 1227.1672\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4948 - val_loss: 1227.1661\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4953 - val_loss: 1227.1650\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4959 - val_loss: 1227.1641\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4965 - val_loss: 1227.1625\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4969 - val_loss: 1227.1610\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4976 - val_loss: 1227.1587\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.4981 - val_loss: 1227.1577\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.4986 - val_loss: 1227.1560\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 133.4991 - val_loss: 1227.1542\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.4997 - val_loss: 1227.1516\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5003 - val_loss: 1227.1500\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5008 - val_loss: 1227.1487\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5012 - val_loss: 1227.1466\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5017 - val_loss: 1227.1442\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5022 - val_loss: 1227.1425\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5027 - val_loss: 1227.1410\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5032 - val_loss: 1227.1390\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5036 - val_loss: 1227.1365\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5041 - val_loss: 1227.1343\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5046 - val_loss: 1227.1328\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5049 - val_loss: 1227.1307\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5054 - val_loss: 1227.1290\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5058 - val_loss: 1227.1268\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5063 - val_loss: 1227.1251\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5066 - val_loss: 1227.1233\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5070 - val_loss: 1227.1216\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5074 - val_loss: 1227.1193\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5078 - val_loss: 1227.1172\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5082 - val_loss: 1227.1154\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5086 - val_loss: 1227.1136\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5089 - val_loss: 1227.1117\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5093 - val_loss: 1227.1097\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5096 - val_loss: 1227.1071\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5100 - val_loss: 1227.1060\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 133.5103 - val_loss: 1227.1039\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.5106 - val_loss: 1227.1021\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5109 - val_loss: 1227.1002\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5112 - val_loss: 1227.0981\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5116 - val_loss: 1227.0958\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5119 - val_loss: 1227.0940\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5122 - val_loss: 1227.0922\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5125 - val_loss: 1227.0900\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5128 - val_loss: 1227.0879\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5130 - val_loss: 1227.0857\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5133 - val_loss: 1227.0839\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5136 - val_loss: 1227.0811\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5139 - val_loss: 1227.0787\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5141 - val_loss: 1227.0769\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5144 - val_loss: 1227.0742\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5146 - val_loss: 1227.0718\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5149 - val_loss: 1227.0693\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5151 - val_loss: 1227.0663\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5154 - val_loss: 1227.0634\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5155 - val_loss: 1227.0604\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5157 - val_loss: 1227.0576\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5159 - val_loss: 1227.0546\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5161 - val_loss: 1227.0504\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5164 - val_loss: 1227.0458\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5166 - val_loss: 1227.0410\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5168 - val_loss: 1227.0358\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5170 - val_loss: 1227.0294\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 133.5172 - val_loss: 1227.0222\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5173 - val_loss: 1227.0135\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.5176 - val_loss: 1227.0022\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5178 - val_loss: 1226.9862\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5179 - val_loss: 1226.9613\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5181 - val_loss: 1226.9147\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5162 - val_loss: 1223.0087\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.7943 - val_loss: 1224.5006\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.6113 - val_loss: 1224.9026\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5889 - val_loss: 1225.1769\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5786 - val_loss: 1225.4080\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5714 - val_loss: 1225.6082\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5658 - val_loss: 1225.7833\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5613 - val_loss: 1225.9374\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5574 - val_loss: 1226.0731\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5543 - val_loss: 1226.1923\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5516 - val_loss: 1226.2983\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5492 - val_loss: 1226.3914\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5472 - val_loss: 1226.4744\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5454 - val_loss: 1226.5466\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5438 - val_loss: 1226.6118\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5425 - val_loss: 1226.6697\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5412 - val_loss: 1226.7206\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 133.5402 - val_loss: 1226.7660\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5393 - val_loss: 1226.8052\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5385 - val_loss: 1226.8411\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5378 - val_loss: 1226.8727\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5371 - val_loss: 1226.9006\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5366 - val_loss: 1226.9261\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5361 - val_loss: 1226.9478\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5356 - val_loss: 1226.9674\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5353 - val_loss: 1226.9856\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5349 - val_loss: 1227.0015\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5346 - val_loss: 1227.0146\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5344 - val_loss: 1227.0265\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5341 - val_loss: 1227.0378\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5339 - val_loss: 1227.0475\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5337 - val_loss: 1227.0555\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5335 - val_loss: 1227.0629\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5334 - val_loss: 1227.0698\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5332 - val_loss: 1227.0756\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5331 - val_loss: 1227.0807\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5331 - val_loss: 1227.0852\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.0894\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.0930\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.0967\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5327 - val_loss: 1227.0997\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 133.5327 - val_loss: 1227.1022\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5327 - val_loss: 1227.1046\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5326 - val_loss: 1227.1069\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5326 - val_loss: 1227.1086\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5325 - val_loss: 1227.1096\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5325 - val_loss: 1227.1106\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5325 - val_loss: 1227.1123\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5325 - val_loss: 1227.1130\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5325 - val_loss: 1227.1140\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5324 - val_loss: 1227.1152\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5324 - val_loss: 1227.1156\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5325 - val_loss: 1227.1162\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5325 - val_loss: 1227.1168\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5325 - val_loss: 1227.1174\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5324 - val_loss: 1227.1177\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5325 - val_loss: 1227.1180\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5325 - val_loss: 1227.1185\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5324 - val_loss: 1227.1188\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5325 - val_loss: 1227.1191\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5324 - val_loss: 1227.1194\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5324 - val_loss: 1227.1198\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5324 - val_loss: 1227.1194\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 133.5325 - val_loss: 1227.1199\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5324 - val_loss: 1227.1198\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5324 - val_loss: 1227.1199\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5325 - val_loss: 1227.1201\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5325 - val_loss: 1227.1202\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5325 - val_loss: 1227.1202\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5325 - val_loss: 1227.1202\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5325 - val_loss: 1227.1202\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5325 - val_loss: 1227.1205\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5325 - val_loss: 1227.1205\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5325 - val_loss: 1227.1206\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5325 - val_loss: 1227.1201\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5325 - val_loss: 1227.1201\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5325 - val_loss: 1227.1199\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5326 - val_loss: 1227.1201\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5326 - val_loss: 1227.1202\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5325 - val_loss: 1227.1202\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5326 - val_loss: 1227.1201\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5326 - val_loss: 1227.1204\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5326 - val_loss: 1227.1202\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5326 - val_loss: 1227.1201\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5326 - val_loss: 1227.1202\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 133.5326 - val_loss: 1227.1199\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5326 - val_loss: 1227.1198\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5326 - val_loss: 1227.1199\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5326 - val_loss: 1227.1195\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5326 - val_loss: 1227.1196\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5326 - val_loss: 1227.1196\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5327 - val_loss: 1227.1196\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5327 - val_loss: 1227.1196\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5327 - val_loss: 1227.1196\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5327 - val_loss: 1227.1194\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5327 - val_loss: 1227.1189\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5327 - val_loss: 1227.1188\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5327 - val_loss: 1227.1188\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5327 - val_loss: 1227.1191\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5327 - val_loss: 1227.1191\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5327 - val_loss: 1227.1191\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5327 - val_loss: 1227.1188\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5328 - val_loss: 1227.1188\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1191\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1193\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1193\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 133.5328 - val_loss: 1227.1193\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1189\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1189\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5328 - val_loss: 1227.1189\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1193\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1193\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5328 - val_loss: 1227.1193\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1193\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1194\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1196\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1194\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1194\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5328 - val_loss: 1227.1194\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5329 - val_loss: 1227.1196\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1196\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1199\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1199\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5328 - val_loss: 1227.1199\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5328 - val_loss: 1227.1196\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1194\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1191\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1191\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 133.5329 - val_loss: 1227.1193\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1193\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1194\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1194\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1194\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5329 - val_loss: 1227.1194\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5329 - val_loss: 1227.1193\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1196\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1196\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1194\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5329 - val_loss: 1227.1195\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1195\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5328 - val_loss: 1227.1193\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1193\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1191\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5329 - val_loss: 1227.1193\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5329 - val_loss: 1227.1190\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5329 - val_loss: 1227.1189\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5329 - val_loss: 1227.1188\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1190\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 133.5329 - val_loss: 1227.1190\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.5329 - val_loss: 1227.1190\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1191\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1193\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1194\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 133.5329 - val_loss: 1227.1194\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1193\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1193\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5329 - val_loss: 1227.1193\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1194\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1196\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5330 - val_loss: 1227.1196\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5330 - val_loss: 1227.1196\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5330 - val_loss: 1227.1196\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5330 - val_loss: 1227.1198\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5329 - val_loss: 1227.1198\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1199\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1196\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 133.5329 - val_loss: 1227.1196\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 133.5329 - val_loss: 1227.1196\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1196\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.5329 - val_loss: 1227.1194\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1194\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5329 - val_loss: 1227.1193\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5330 - val_loss: 1227.1193\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5330 - val_loss: 1227.1191\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.5330 - val_loss: 1227.1191\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 401ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.30997899e+01, 6.28728992e+01, 6.26460084e+01, 6.24191176e+01,\n",
       "        6.95426636e+01, 1.80712970e-01, 0.00000000e+00, 4.00745988e-01,\n",
       "        8.21726920e-02, 0.00000000e+00, 6.11513257e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.17926471e+01, 6.17338235e+01, 6.16750000e+01,\n",
       "        6.16161765e+01, 6.15792857e+01, 6.38893791e+01, 6.37129085e+01,\n",
       "        6.35364379e+01, 6.33599673e+01, 6.31502101e+01, 6.29233193e+01,\n",
       "        6.26964286e+01, 6.24695378e+01, 6.23825163e+01, 6.10286120e-01,\n",
       "        0.00000000e+00, 6.32426471e+01, 6.30157563e+01, 6.27888655e+01,\n",
       "        6.25619748e+01, 6.23927871e+01, 6.23675770e+01, 6.23423669e+01,\n",
       "        6.23171569e+01, 6.22436274e+01, 4.91281510e-01, 0.00000000e+00,\n",
       "        7.44389700e-02, 0.00000000e+00, 5.01668390e-01, 0.00000000e+00,\n",
       "        5.32359540e-01, 2.62233850e-01, 7.06635000e-01, 6.25199580e+01,\n",
       "        6.23881186e+01, 1.30264850e-01, 0.00000000e+00, 6.32930672e+01,\n",
       "        6.30661765e+01, 6.28392857e+01, 6.26123950e+01, 6.23983894e+01,\n",
       "        6.23731793e+01, 6.23479692e+01, 6.23227591e+01, 6.22828431e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.24779412e+01, 6.23834501e+01,\n",
       "        6.23582400e+01, 6.23330299e+01, 6.23078198e+01, 6.21782680e+01,\n",
       "        6.20017974e+01, 6.18253268e+01, 6.16488562e+01, 6.26947700e-01,\n",
       "        4.36337980e-01, 4.17646065e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.65527010e-01, 2.89794450e-01, 0.00000000e+00, 1.46630410e-01,\n",
       "        6.07083626e+01, 0.00000000e+00, 2.27964431e-01, 0.00000000e+00,\n",
       "        3.15263271e-02, 1.38952565e+00, 6.51840091e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.80357531e-01, 0.00000000e+00, 4.49932277e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.09291923e-01, 4.09487516e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53.94024732, 53.93150236, 53.9227574 , 53.91401243, 53.90526747,\n",
       "       53.89652251, 53.88777755, 53.87903259, 53.87028763, 53.86154267,\n",
       "       53.8527977 , 53.84405274, 53.83530778, 53.82656282, 53.81781786,\n",
       "       53.8090729 , 53.80032794, 53.79158297, 53.78283801, 53.77409305,\n",
       "       53.76534809, 53.75660313, 53.74785817, 53.73911321, 53.73036824,\n",
       "       53.72162328, 53.71287832, 53.70413336, 53.6953884 , 53.68664344,\n",
       "       53.67789848, 53.66915352, 53.66040855, 53.65166359, 53.64291863,\n",
       "       53.63417367, 53.62542871, 53.61668375, 53.60793879, 53.59919382,\n",
       "       53.59044886, 53.5817039 , 53.57295894, 53.56421398, 53.55546902,\n",
       "       53.54672406, 53.53797909, 53.52923413, 53.52048917, 53.51174421,\n",
       "       53.50299925, 53.49425429, 53.48550933, 53.47676436, 53.4680194 ,\n",
       "       53.45927444, 53.45052948, 53.44178452, 53.43303956, 53.4242946 ,\n",
       "       53.41554963, 53.40680467, 53.39805971, 53.38931475, 53.38056979,\n",
       "       53.37182483, 53.36307987, 53.3543349 , 53.34558994, 53.33684498,\n",
       "       53.32810002, 53.31935506, 53.3106101 , 53.30186514, 53.29312017,\n",
       "       53.28437521, 53.27563025, 53.26688529, 53.25814033, 53.24939537,\n",
       "       53.24065041, 53.23190545, 53.22316048, 53.21441552, 53.20567056,\n",
       "       53.1969256 , 53.18818064, 53.17943568, 53.17069072, 53.16194575,\n",
       "       53.15320079, 53.14445583, 53.13571087, 53.12696591, 53.11822095,\n",
       "       53.10947599, 53.10073102, 53.09198606, 53.0832411 , 53.07449614])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.17619690030628\n",
      "31.14018378714832\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
