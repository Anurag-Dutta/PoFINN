{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1895    59.045215\n",
       "1896    59.034944\n",
       "1897    59.024673\n",
       "1898    59.014402\n",
       "1899    59.004132\n",
       "Name: C1, Length: 1900, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_1800_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1795     0.000000\n",
       "1796     0.116387\n",
       "1797     0.000000\n",
       "1798     0.000000\n",
       "1799     0.000000\n",
       "Name: C1, Length: 1800, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1800)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1350, 1, 251) (1350, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 3s 45ms/step - loss: 4430.9937 - val_loss: 3353.4124\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4350.1826 - val_loss: 3303.0369\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4290.6167 - val_loss: 3253.0989\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4231.5801 - val_loss: 3203.7268\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4173.1533 - val_loss: 3154.9370\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4115.3398 - val_loss: 3106.7256\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4058.1365 - val_loss: 3059.0864\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4001.5356 - val_loss: 3012.0134\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3945.5334 - val_loss: 2965.5022\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3890.1218 - val_loss: 2919.5479\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3835.2976 - val_loss: 2874.1448\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3781.0559 - val_loss: 2829.2891\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3727.3918 - val_loss: 2784.9758\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3674.3013 - val_loss: 2741.2009\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3621.7783 - val_loss: 2697.9595\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3569.8198 - val_loss: 2655.2476\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3518.4209 - val_loss: 2613.0608\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3467.5769 - val_loss: 2571.3953\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3417.2837 - val_loss: 2530.2456\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3367.5376 - val_loss: 2489.6089\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3318.3335 - val_loss: 2449.4807\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3269.6682 - val_loss: 2409.8560\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3221.5369 - val_loss: 2370.7319\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3173.9353 - val_loss: 2332.1040\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3126.8594 - val_loss: 2293.9678\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3080.3054 - val_loss: 2256.3193\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3034.2698 - val_loss: 2219.1550\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2988.7473 - val_loss: 2182.4712\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2943.7349 - val_loss: 2146.2632\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2899.2285 - val_loss: 2110.5283\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2855.2236 - val_loss: 2075.2610\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2811.7170 - val_loss: 2040.4586\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2768.7053 - val_loss: 2006.1169\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2726.1833 - val_loss: 1972.2324\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2684.1477 - val_loss: 1938.8008\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2642.5957 - val_loss: 1905.8191\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2601.5222 - val_loss: 1873.2830\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2560.9241 - val_loss: 1841.1890\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2520.7971 - val_loss: 1809.5333\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2481.1387 - val_loss: 1778.3127\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2441.9441 - val_loss: 1747.5229\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2403.2107 - val_loss: 1717.1610\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 2364.9341 - val_loss: 1687.2230\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2327.1104 - val_loss: 1657.7056\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2289.7373 - val_loss: 1628.6046\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2252.8098 - val_loss: 1599.9169\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2216.3252 - val_loss: 1571.6392\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2180.2798 - val_loss: 1543.7678\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2144.6707 - val_loss: 1516.2993\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2109.4934 - val_loss: 1489.2305\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2074.7451 - val_loss: 1462.5575\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2040.4218 - val_loss: 1436.2770\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2006.5212 - val_loss: 1410.3859\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1973.0391 - val_loss: 1384.8806\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1939.9722 - val_loss: 1359.7579\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1907.3174 - val_loss: 1335.0139\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1875.0709 - val_loss: 1310.6462\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1843.2302 - val_loss: 1286.6511\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1811.7914 - val_loss: 1263.0254\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1780.7513 - val_loss: 1239.7649\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1750.1067 - val_loss: 1216.8687\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1719.8545 - val_loss: 1194.3308\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1689.9912 - val_loss: 1172.1494\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1660.5137 - val_loss: 1150.3213\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1631.4189 - val_loss: 1128.8427\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1602.7037 - val_loss: 1107.7115\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1574.3649 - val_loss: 1086.9236\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1546.3993 - val_loss: 1066.4758\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1518.8037 - val_loss: 1046.3656\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1491.5754 - val_loss: 1026.5898\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1464.7109 - val_loss: 1007.1453\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1438.2073 - val_loss: 988.0281\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1412.0614 - val_loss: 969.2361\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1386.2695 - val_loss: 950.7662\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1360.8303 - val_loss: 932.6148\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1335.7395 - val_loss: 914.7794\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1310.9945 - val_loss: 897.2566\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1286.5923 - val_loss: 880.0438\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1262.5299 - val_loss: 863.1375\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1238.8041 - val_loss: 846.5355\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1215.4121 - val_loss: 830.2338\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1192.3513 - val_loss: 814.2299\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1169.6184 - val_loss: 798.5215\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1147.2109 - val_loss: 783.1045\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1125.1251 - val_loss: 767.9767\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1103.3588 - val_loss: 753.1351\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1081.9092 - val_loss: 738.5763\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1060.7728 - val_loss: 724.2979\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1039.9475 - val_loss: 710.2974\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1019.4300 - val_loss: 696.5710\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 999.2176 - val_loss: 683.1169\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 979.3076 - val_loss: 669.9310\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 959.6970 - val_loss: 657.0112\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 940.3832 - val_loss: 644.3545\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 921.3630 - val_loss: 631.9585\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 902.6346 - val_loss: 619.8198\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 884.1945 - val_loss: 607.9360\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 866.0398 - val_loss: 596.3041\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 848.1684 - val_loss: 584.9212\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 830.5772 - val_loss: 573.7845\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 813.2635 - val_loss: 562.8919\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 796.2249 - val_loss: 552.2404\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 779.4581 - val_loss: 541.8260\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 762.9608 - val_loss: 531.6475\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 746.7305 - val_loss: 521.7015\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 730.7640 - val_loss: 511.9851\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 715.0587 - val_loss: 502.4961\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 699.6123 - val_loss: 493.2314\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 684.4222 - val_loss: 484.1886\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 669.4859 - val_loss: 475.3647\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 654.8004 - val_loss: 466.7573\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 640.3633 - val_loss: 458.3634\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 626.1718 - val_loss: 450.1811\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 612.2237 - val_loss: 442.2064\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 598.5157 - val_loss: 434.4379\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 585.0460 - val_loss: 426.8725\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 571.8118 - val_loss: 419.5074\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 558.8107 - val_loss: 412.3400\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 546.0395 - val_loss: 405.3680\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 533.4961 - val_loss: 398.5882\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 521.1779 - val_loss: 391.9986\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 509.0825 - val_loss: 385.5963\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 497.2075 - val_loss: 379.3790\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 485.5503 - val_loss: 373.3438\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 474.1081 - val_loss: 367.4883\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 462.8788 - val_loss: 361.8100\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 451.8597 - val_loss: 356.3060\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 441.0486 - val_loss: 350.9739\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 430.4425 - val_loss: 345.8112\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 420.0393 - val_loss: 340.8156\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 409.8370 - val_loss: 335.9844\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 399.8325 - val_loss: 331.3150\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 390.0237 - val_loss: 326.8048\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 380.4078 - val_loss: 322.4515\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 370.9826 - val_loss: 318.2528\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 361.7460 - val_loss: 314.2056\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 352.6952 - val_loss: 310.3081\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 343.8282 - val_loss: 306.5577\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 335.1426 - val_loss: 302.9516\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 326.6355 - val_loss: 299.4876\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 318.3051 - val_loss: 296.1630\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 310.1487 - val_loss: 292.9758\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 302.1642 - val_loss: 289.9236\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 294.3494 - val_loss: 287.0036\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 286.7017 - val_loss: 284.2135\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 279.2186 - val_loss: 281.5511\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 271.8982 - val_loss: 279.0138\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 264.7381 - val_loss: 276.5995\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 257.7362 - val_loss: 274.3057\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 250.8900 - val_loss: 272.1302\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 244.1973 - val_loss: 270.0703\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 237.6557 - val_loss: 268.1240\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 231.2631 - val_loss: 266.2889\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 225.0172 - val_loss: 264.5628\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 218.9158 - val_loss: 262.9432\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 212.9568 - val_loss: 261.4280\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 207.1379 - val_loss: 260.0149\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 201.4570 - val_loss: 258.7016\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 195.9119 - val_loss: 257.4860\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 190.5003 - val_loss: 256.3657\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 185.2202 - val_loss: 255.3387\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 180.0696 - val_loss: 254.4026\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 175.0461 - val_loss: 253.5554\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 170.1476 - val_loss: 252.7948\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 165.3722 - val_loss: 252.1188\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 160.7178 - val_loss: 251.5251\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 156.1821 - val_loss: 251.0116\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 151.7632 - val_loss: 250.5763\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 147.4590 - val_loss: 250.2171\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 143.2675 - val_loss: 249.9319\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 139.1868 - val_loss: 249.7186\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 135.2146 - val_loss: 249.5752\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 131.3491 - val_loss: 249.4997\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 127.5882 - val_loss: 249.4901\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 123.9302 - val_loss: 249.5444\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 120.3727 - val_loss: 249.6606\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 116.9142 - val_loss: 249.8368\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 113.5527 - val_loss: 250.0710\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 110.2861 - val_loss: 250.3615\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 107.1126 - val_loss: 250.7061\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 104.0305 - val_loss: 251.1031\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 101.0379 - val_loss: 251.5507\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 98.1327 - val_loss: 252.0470\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 95.3133 - val_loss: 252.5902\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 92.5779 - val_loss: 253.1785\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 89.9246 - val_loss: 253.8101\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 87.3516 - val_loss: 254.4834\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 84.8574 - val_loss: 255.1966\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 82.4400 - val_loss: 255.9479\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 80.0980 - val_loss: 256.7357\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 77.8294 - val_loss: 257.5584\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 75.6326 - val_loss: 258.4144\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 73.5059 - val_loss: 259.3020\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 71.4477 - val_loss: 260.2196\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 69.4566 - val_loss: 261.1657\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 67.5308 - val_loss: 262.1388\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 65.6686 - val_loss: 263.1373\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 63.8685 - val_loss: 264.1598\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 62.1292 - val_loss: 265.2048\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 60.4489 - val_loss: 266.2709\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 58.8263 - val_loss: 267.3567\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 57.2599 - val_loss: 268.4609\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 55.7478 - val_loss: 269.5819\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 54.2892 - val_loss: 270.7188\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 52.8824 - val_loss: 271.8696\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 51.5261 - val_loss: 273.0338\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 50.2187 - val_loss: 274.2098\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 48.9590 - val_loss: 275.3962\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 47.7459 - val_loss: 276.5923\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 46.5777 - val_loss: 277.7962\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 45.4533 - val_loss: 279.0076\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 44.3715 - val_loss: 280.2250\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 43.3308 - val_loss: 281.4474\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 42.3302 - val_loss: 282.6736\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 41.3684 - val_loss: 283.9025\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 40.4445 - val_loss: 285.1332\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 39.5571 - val_loss: 286.3651\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 38.7050 - val_loss: 287.5966\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 37.8873 - val_loss: 288.8274\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 37.1027 - val_loss: 290.0562\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 36.3503 - val_loss: 291.2826\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 35.6289 - val_loss: 292.5052\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 34.9376 - val_loss: 293.7236\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 34.2754 - val_loss: 294.9369\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.6413 - val_loss: 296.1444\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 33.0343 - val_loss: 297.3457\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 32.4534 - val_loss: 298.5397\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 31.8979 - val_loss: 299.7257\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.3668 - val_loss: 300.9032\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.8592 - val_loss: 302.0715\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 30.3743 - val_loss: 303.2303\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.9114 - val_loss: 304.3789\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.4693 - val_loss: 305.5164\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 29.0477 - val_loss: 306.6429\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 28.6455 - val_loss: 307.7577\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 28.2621 - val_loss: 308.8602\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.8967 - val_loss: 309.9502\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.5487 - val_loss: 311.0272\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.2173 - val_loss: 312.0910\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.9019 - val_loss: 313.1408\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.6019 - val_loss: 314.1764\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.3166 - val_loss: 315.1980\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.0455 - val_loss: 316.2046\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.7879 - val_loss: 317.1967\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5432 - val_loss: 318.1736\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3109 - val_loss: 319.1350\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 25.0905 - val_loss: 320.0809\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.8815 - val_loss: 321.0113\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.6834 - val_loss: 321.9256\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 24.4956 - val_loss: 322.8243\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 24.3177 - val_loss: 323.7069\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 24.1493 - val_loss: 324.5732\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.9900 - val_loss: 325.4230\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.8392 - val_loss: 326.2569\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.6967 - val_loss: 327.0736\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.5621 - val_loss: 327.8747\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.4348 - val_loss: 328.6589\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.3148 - val_loss: 329.4272\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.2014 - val_loss: 330.1788\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.0945 - val_loss: 330.9145\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.9936 - val_loss: 331.6337\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.8985 - val_loss: 332.3368\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.8090 - val_loss: 333.0238\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.7246 - val_loss: 333.6945\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.6453 - val_loss: 334.3493\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.5706 - val_loss: 334.9886\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.5004 - val_loss: 335.6121\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.4344 - val_loss: 336.2199\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.3723 - val_loss: 336.8125\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.3141 - val_loss: 337.3899\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 22.2594 - val_loss: 337.9519\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.2081 - val_loss: 338.4991\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.1600 - val_loss: 339.0315\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.1149 - val_loss: 339.5497\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.0726 - val_loss: 340.0535\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.0329 - val_loss: 340.5431\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.9958 - val_loss: 341.0188\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.9611 - val_loss: 341.4802\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.9286 - val_loss: 341.9287\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.8982 - val_loss: 342.3633\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.8699 - val_loss: 342.7852\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.8434 - val_loss: 343.1942\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.8185 - val_loss: 343.5907\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.7955 - val_loss: 343.9749\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.7738 - val_loss: 344.3468\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.7537 - val_loss: 344.7070\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.7348 - val_loss: 345.0553\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.7174 - val_loss: 345.3923\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.7010 - val_loss: 345.7181\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.6858 - val_loss: 346.0332\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.6717 - val_loss: 346.3374\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.6585 - val_loss: 346.6314\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.6462 - val_loss: 346.9153\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 21.6348 - val_loss: 347.1891\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.6242 - val_loss: 347.4533\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.6143 - val_loss: 347.7080\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.6051 - val_loss: 347.9535\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5965 - val_loss: 348.1899\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5887 - val_loss: 348.4179\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5813 - val_loss: 348.6369\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5745 - val_loss: 348.8480\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5682 - val_loss: 349.0510\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5623 - val_loss: 349.2462\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5569 - val_loss: 349.4339\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5518 - val_loss: 349.6138\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5472 - val_loss: 349.7870\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5428 - val_loss: 349.9529\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5388 - val_loss: 350.1120\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5352 - val_loss: 350.2648\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5317 - val_loss: 350.4112\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5285 - val_loss: 350.5516\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5257 - val_loss: 350.6861\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5230 - val_loss: 350.8151\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 21.5205 - val_loss: 350.9382\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5182 - val_loss: 351.0563\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5161 - val_loss: 351.1695\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5141 - val_loss: 351.2771\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5124 - val_loss: 351.3803\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5107 - val_loss: 351.4788\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5092 - val_loss: 351.5727\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5078 - val_loss: 351.6626\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5066 - val_loss: 351.7484\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5054 - val_loss: 351.8302\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5043 - val_loss: 351.9077\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5034 - val_loss: 351.9818\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5025 - val_loss: 352.0526\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5017 - val_loss: 352.1199\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5010 - val_loss: 352.1841\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5003 - val_loss: 352.2448\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4998 - val_loss: 352.3026\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4993 - val_loss: 352.3576\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.4988 - val_loss: 352.4097\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4984 - val_loss: 352.4595\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.4980 - val_loss: 352.5065\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4977 - val_loss: 352.5509\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4975 - val_loss: 352.5934\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4973 - val_loss: 352.6333\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 21.4971 - val_loss: 352.6714\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.4969 - val_loss: 352.7073\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.4968 - val_loss: 352.7414\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.4967 - val_loss: 352.7735\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4966 - val_loss: 352.8036\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.4966 - val_loss: 352.8323\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4966 - val_loss: 352.8598\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4966 - val_loss: 352.8852\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.4966 - val_loss: 352.9092\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4967 - val_loss: 352.9317\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4968 - val_loss: 352.9531\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4969 - val_loss: 352.9734\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4970 - val_loss: 352.9923\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.4972 - val_loss: 353.0101\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4973 - val_loss: 353.0269\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.4975 - val_loss: 353.0430\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4977 - val_loss: 353.0576\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 21.4979 - val_loss: 353.0717\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.4981 - val_loss: 353.0849\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4983 - val_loss: 353.0969\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4985 - val_loss: 353.1085\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4987 - val_loss: 353.1191\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.4989 - val_loss: 353.1288\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.4992 - val_loss: 353.1384\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.4994 - val_loss: 353.1470\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.4997 - val_loss: 353.1547\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5000 - val_loss: 353.1622\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5003 - val_loss: 353.1692\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5005 - val_loss: 353.1755\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.5008 - val_loss: 353.1816\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5011 - val_loss: 353.1870\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5014 - val_loss: 353.1925\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.5016 - val_loss: 353.1967\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5020 - val_loss: 353.2013\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 21.5023 - val_loss: 353.2056\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5026 - val_loss: 353.2093\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5029 - val_loss: 353.2127\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5032 - val_loss: 353.2157\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5036 - val_loss: 353.2184\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5039 - val_loss: 353.2210\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5042 - val_loss: 353.2235\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5045 - val_loss: 353.2256\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5048 - val_loss: 353.2274\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5051 - val_loss: 353.2289\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5055 - val_loss: 353.2306\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5058 - val_loss: 353.2317\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5061 - val_loss: 353.2329\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5065 - val_loss: 353.2339\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5068 - val_loss: 353.2346\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5071 - val_loss: 353.2355\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5075 - val_loss: 353.2361\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5077 - val_loss: 353.2365\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5081 - val_loss: 353.2372\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5084 - val_loss: 353.2376\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 21.5087 - val_loss: 353.2380\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5090 - val_loss: 353.2380\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5094 - val_loss: 353.2381\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5097 - val_loss: 353.2383\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5100 - val_loss: 353.2383\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5103 - val_loss: 353.2380\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5107 - val_loss: 353.2378\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5110 - val_loss: 353.2377\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5113 - val_loss: 353.2370\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5116 - val_loss: 353.2367\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5119 - val_loss: 353.2360\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5122 - val_loss: 353.2355\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5125 - val_loss: 353.2352\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5129 - val_loss: 353.2345\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5132 - val_loss: 353.2340\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5134 - val_loss: 353.2333\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5138 - val_loss: 353.2327\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5140 - val_loss: 353.2318\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5143 - val_loss: 353.2311\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5146 - val_loss: 353.2302\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 21.5149 - val_loss: 353.2295\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5153 - val_loss: 353.2289\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5155 - val_loss: 353.2284\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5158 - val_loss: 353.2275\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5161 - val_loss: 353.2271\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5164 - val_loss: 353.2265\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5167 - val_loss: 353.2257\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.5170 - val_loss: 353.2252\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5172 - val_loss: 353.2242\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5175 - val_loss: 353.2236\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5178 - val_loss: 353.2229\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5180 - val_loss: 353.2219\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5183 - val_loss: 353.2215\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5186 - val_loss: 353.2207\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5188 - val_loss: 353.2198\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5192 - val_loss: 353.2191\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5194 - val_loss: 353.2187\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5196 - val_loss: 353.2178\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5199 - val_loss: 353.2173\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5201 - val_loss: 353.2165\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5204 - val_loss: 353.2159\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 21.5206 - val_loss: 353.2151\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5209 - val_loss: 353.2144\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5212 - val_loss: 353.2138\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5214 - val_loss: 353.2130\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5216 - val_loss: 353.2122\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5218 - val_loss: 353.2111\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5221 - val_loss: 353.2103\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5223 - val_loss: 353.2094\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5225 - val_loss: 353.2085\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5227 - val_loss: 353.2076\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5230 - val_loss: 353.2071\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5232 - val_loss: 353.2064\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5234 - val_loss: 353.2057\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5237 - val_loss: 353.2050\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5239 - val_loss: 353.2043\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5241 - val_loss: 353.2035\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5243 - val_loss: 353.2026\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5245 - val_loss: 353.2019\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5247 - val_loss: 353.2011\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5249 - val_loss: 353.2003\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5251 - val_loss: 353.2000\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 21.5253 - val_loss: 353.1992\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5255 - val_loss: 353.1987\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5257 - val_loss: 353.1981\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5259 - val_loss: 353.1974\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5261 - val_loss: 353.1970\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5263 - val_loss: 353.1963\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5265 - val_loss: 353.1961\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5266 - val_loss: 353.1954\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.5268 - val_loss: 353.1946\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5270 - val_loss: 353.1941\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5272 - val_loss: 353.1935\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5274 - val_loss: 353.1929\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5275 - val_loss: 353.1921\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5278 - val_loss: 353.1916\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.5279 - val_loss: 353.1911\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.5281 - val_loss: 353.1907\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.5282 - val_loss: 353.1900\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5284 - val_loss: 353.1896\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.5285 - val_loss: 353.1889\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 21.5287 - val_loss: 353.1884\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5289 - val_loss: 353.1878\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5290 - val_loss: 353.1877\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5291 - val_loss: 353.1869\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5293 - val_loss: 353.1866\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5295 - val_loss: 353.1864\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5296 - val_loss: 353.1861\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5298 - val_loss: 353.1856\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.5298 - val_loss: 353.1850\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5300 - val_loss: 353.1846\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5302 - val_loss: 353.1841\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5303 - val_loss: 353.1835\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.5304 - val_loss: 353.1830\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.5306 - val_loss: 353.1825\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5307 - val_loss: 353.1821\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5308 - val_loss: 353.1813\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5309 - val_loss: 353.1805\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5311 - val_loss: 353.1803\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5312 - val_loss: 353.1799\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5313 - val_loss: 353.1793\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5314 - val_loss: 353.1791\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 21.5316 - val_loss: 353.1788\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5317 - val_loss: 353.1783\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5318 - val_loss: 353.1782\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5320 - val_loss: 353.1780\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5320 - val_loss: 353.1775\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5321 - val_loss: 353.1770\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5322 - val_loss: 353.1763\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 389ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.23208917e+01, 6.23180906e+01, 6.23152895e+01, 6.23124883e+01,\n",
       "        6.23096872e+01, 6.23068861e+01, 6.23040850e+01, 6.23012838e+01,\n",
       "        6.22893791e+01, 6.22697712e+01, 6.22501634e+01, 6.22305556e+01,\n",
       "        6.22109477e+01, 6.21913399e+01, 6.21717320e+01, 6.21521242e+01,\n",
       "        6.21325163e+01, 6.21129085e+01, 6.20933007e+01, 6.20736928e+01,\n",
       "        6.20540850e+01, 6.20344771e+01, 6.20148693e+01, 6.19952614e+01,\n",
       "        6.19756536e+01, 6.19560458e+01, 6.19364379e+01, 6.19168301e+01,\n",
       "        6.18972222e+01, 6.18776144e+01, 6.18580065e+01, 6.18383987e+01,\n",
       "        6.18187908e+01, 6.17991830e+01, 6.17795752e+01, 6.17599673e+01,\n",
       "        6.17403595e+01, 6.17207516e+01, 6.17011438e+01, 6.16815359e+01,\n",
       "        6.16619281e+01, 6.16423203e+01, 6.16227124e+01, 6.16031046e+01,\n",
       "        6.15919841e+01, 6.15824603e+01, 6.15729365e+01, 6.39678105e+01,\n",
       "        6.39089869e+01, 6.38501634e+01, 6.37913399e+01, 6.37325163e+01,\n",
       "        6.36736928e+01, 6.36148693e+01, 6.35560458e+01, 6.34972222e+01,\n",
       "        6.34383987e+01, 6.33795752e+01, 6.33207516e+01, 6.32510504e+01,\n",
       "        6.31754202e+01, 6.30997899e+01, 6.30241597e+01, 6.29485294e+01,\n",
       "        6.28728992e+01, 6.27972689e+01, 6.27216387e+01, 6.26460084e+01,\n",
       "        6.25703782e+01, 6.24947479e+01, 6.24191176e+01, 6.23937208e+01,\n",
       "        6.23853175e+01, 6.95426636e+01, 0.00000000e+00, 4.58282290e-01,\n",
       "        1.80712970e-01, 8.05609170e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.04137650e+01, 0.00000000e+00, 4.00745988e-01, 1.03494644e-01,\n",
       "        0.00000000e+00, 8.21726918e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.51493770e-01, 9.70554471e-01, 6.11513257e-01,\n",
       "        6.49816617e-02, 0.00000000e+00, 0.00000000e+00, 6.82190061e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.14040160e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59.95057423, 59.94627918, 59.94198413, 59.93768908, 59.93339402,\n",
       "       59.92909897, 59.92480392, 59.92050887, 59.91621382, 59.91191877,\n",
       "       59.90762372, 59.90332866, 59.89768908, 59.8874183 , 59.87714753,\n",
       "       59.86687675, 59.85660598, 59.8463352 , 59.83606443, 59.82579365,\n",
       "       59.81552288, 59.8052521 , 59.79498133, 59.78471055, 59.77443978,\n",
       "       59.764169  , 59.75389823, 59.74362745, 59.73335668, 59.7230859 ,\n",
       "       59.71281513, 59.70254435, 59.69227358, 59.6820028 , 59.67173203,\n",
       "       59.66146125, 59.65119048, 59.6409197 , 59.63064893, 59.62037815,\n",
       "       59.61010738, 59.5998366 , 59.58956583, 59.57929505, 59.56902428,\n",
       "       59.5587535 , 59.54848273, 59.53821195, 59.52794118, 59.5176704 ,\n",
       "       59.50739963, 59.49712885, 59.48685808, 59.4765873 , 59.46631653,\n",
       "       59.45604575, 59.44577498, 59.4355042 , 59.42523343, 59.41496265,\n",
       "       59.40469188, 59.3944211 , 59.38415033, 59.37387955, 59.36360878,\n",
       "       59.353338  , 59.34306723, 59.33279645, 59.32252568, 59.3122549 ,\n",
       "       59.30198413, 59.29171335, 59.28144258, 59.2711718 , 59.26090103,\n",
       "       59.25063025, 59.24035948, 59.2300887 , 59.21981793, 59.20954715,\n",
       "       59.19927638, 59.1890056 , 59.17873483, 59.16846405, 59.15819328,\n",
       "       59.1479225 , 59.13765173, 59.12738095, 59.11711018, 59.1068394 ,\n",
       "       59.09656863, 59.08629785, 59.07602708, 59.0657563 , 59.05548553,\n",
       "       59.04521475, 59.03494398, 59.0246732 , 59.01440243, 59.00413165])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.575186301313387\n",
      "16.85951613049276\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
