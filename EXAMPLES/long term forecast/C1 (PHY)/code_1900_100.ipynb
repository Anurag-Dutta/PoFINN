{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1995    57.591667\n",
       "1996    57.575794\n",
       "1997    57.559921\n",
       "1998    57.544048\n",
       "1999    57.528175\n",
       "Name: C1, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_1900_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1895     0.682190\n",
       "1896     0.000000\n",
       "1897     0.000000\n",
       "1898     0.714040\n",
       "1899     0.000000\n",
       "Name: C1, Length: 1900, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1900)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1450, 1, 251) (1450, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 4s 47ms/step - loss: 4589.9268 - val_loss: 3316.8733\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4491.4932 - val_loss: 3261.4922\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4425.7969 - val_loss: 3209.3267\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4369.5625 - val_loss: 3164.8662\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4312.1455 - val_loss: 3120.0186\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4255.3198 - val_loss: 3076.1230\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4199.6011 - val_loss: 3033.0964\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 4144.8115 - val_loss: 2990.7917\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 4090.8035 - val_loss: 2949.1223\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 4037.4900 - val_loss: 2908.0349\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3984.8176 - val_loss: 2867.4954\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3932.7495 - val_loss: 2827.4802\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3881.2612 - val_loss: 2787.9705\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3830.3333 - val_loss: 2748.9531\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3779.9509 - val_loss: 2710.4163\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 3730.1018 - val_loss: 2672.3508\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3680.7747 - val_loss: 2634.7488\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3631.9622 - val_loss: 2597.6025\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 3583.6558 - val_loss: 2560.9060\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3535.8479 - val_loss: 2524.6526\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 3488.5327 - val_loss: 2488.8381\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3441.7043 - val_loss: 2453.4624\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3381.5193 - val_loss: 2404.0891\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3328.1299 - val_loss: 2365.4451\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3277.7930 - val_loss: 2328.0754\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3228.8606 - val_loss: 2291.6897\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3181.0083 - val_loss: 2256.0999\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3134.0396 - val_loss: 2221.1956\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3087.8413 - val_loss: 2186.9094\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 3042.3406 - val_loss: 2153.1970\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 2997.4861 - val_loss: 2120.0247\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 2953.2427 - val_loss: 2087.3687\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 2909.5820 - val_loss: 2055.2087\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2866.4819 - val_loss: 2023.5299\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2823.9246 - val_loss: 1992.3185\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2781.8943 - val_loss: 1961.5636\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2740.3789 - val_loss: 1931.2550\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 2699.3672 - val_loss: 1901.3840\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2658.8489 - val_loss: 1871.9431\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2618.8152 - val_loss: 1842.9252\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2579.2583 - val_loss: 1814.3231\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2540.1704 - val_loss: 1786.1311\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2501.5444 - val_loss: 1758.3435\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2463.3745 - val_loss: 1730.9552\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2425.6545 - val_loss: 1703.9608\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2388.3787 - val_loss: 1677.3558\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2351.5425 - val_loss: 1651.1356\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2315.1401 - val_loss: 1625.2959\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2279.1663 - val_loss: 1598.7024\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2238.9602 - val_loss: 1568.6843\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2197.5122 - val_loss: 1539.8727\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2157.6189 - val_loss: 1512.3015\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 2119.0984 - val_loss: 1479.7675\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2070.9482 - val_loss: 1449.5813\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2028.3955 - val_loss: 1420.5797\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1987.7556 - val_loss: 1392.9988\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1948.7689 - val_loss: 1366.5094\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1911.0554 - val_loss: 1340.9042\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1874.3846 - val_loss: 1316.0594\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1838.6138 - val_loss: 1291.8911\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1803.6470 - val_loss: 1268.3259\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1763.0848 - val_loss: 1238.2324\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1723.0260 - val_loss: 1212.1295\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1685.2274 - val_loss: 1187.3876\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1649.0607 - val_loss: 1163.7057\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1614.1547 - val_loss: 1140.8839\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1580.2805 - val_loss: 1118.8019\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1547.2990 - val_loss: 1097.3829\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1515.1169 - val_loss: 1076.5712\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1483.6678 - val_loss: 1056.3262\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1452.9003 - val_loss: 1036.6144\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1422.7753 - val_loss: 1017.4100\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1393.2594 - val_loss: 998.6910\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1364.3257 - val_loss: 980.4385\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1335.9507 - val_loss: 962.6358\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1308.1145 - val_loss: 945.2681\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1280.7990 - val_loss: 928.3228\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1253.9884 - val_loss: 911.7879\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1227.6682 - val_loss: 895.6528\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1201.8254 - val_loss: 879.9066\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1176.4484 - val_loss: 864.5415\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1151.5260 - val_loss: 849.5483\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1127.0482 - val_loss: 834.9189\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1103.0050 - val_loss: 820.6455\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1079.3882 - val_loss: 806.7214\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1056.1893 - val_loss: 793.1393\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1033.4000 - val_loss: 779.8936\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1011.0132 - val_loss: 766.9772\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 989.0217 - val_loss: 754.3842\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 967.4185 - val_loss: 742.1089\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 946.1969 - val_loss: 730.1460\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 925.3512 - val_loss: 718.4896\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 904.8745 - val_loss: 707.1353\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 884.7615 - val_loss: 696.0769\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 865.0067 - val_loss: 685.3106\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 845.6046 - val_loss: 674.8315\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 826.5500 - val_loss: 664.6344\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 807.8377 - val_loss: 654.7153\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 789.4627 - val_loss: 645.0691\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 771.4199 - val_loss: 635.6919\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 753.7051 - val_loss: 626.5793\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 736.3130 - val_loss: 617.7268\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 719.2396 - val_loss: 609.1309\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 702.4800 - val_loss: 600.7870\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 686.0303 - val_loss: 592.6914\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 669.8860 - val_loss: 584.8401\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 654.0431 - val_loss: 577.2290\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 638.4973 - val_loss: 569.8548\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 623.2446 - val_loss: 562.7131\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 608.2811 - val_loss: 555.8006\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 593.6031 - val_loss: 549.1136\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 579.2062 - val_loss: 542.6482\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 565.0873 - val_loss: 536.4012\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 551.2422 - val_loss: 530.3684\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 537.6673 - val_loss: 524.5472\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 524.3591 - val_loss: 518.9335\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 511.3140 - val_loss: 513.5239\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 498.5276 - val_loss: 508.3147\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 485.9972 - val_loss: 503.3031\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 473.7191 - val_loss: 498.4854\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 461.6900 - val_loss: 493.8585\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 449.9064 - val_loss: 489.4187\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 438.3651 - val_loss: 485.1631\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 427.0626 - val_loss: 481.0886\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 415.9953 - val_loss: 477.1913\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 405.1602 - val_loss: 473.4684\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 394.5541 - val_loss: 469.9168\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 384.1736 - val_loss: 466.5331\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 374.0157 - val_loss: 463.3145\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 364.0771 - val_loss: 460.2574\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 354.3543 - val_loss: 457.3590\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 344.8449 - val_loss: 454.6164\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 335.5455 - val_loss: 452.0262\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 326.4527 - val_loss: 449.5855\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 317.5638 - val_loss: 447.2913\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 308.8756 - val_loss: 445.1405\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 300.3852 - val_loss: 443.1302\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 292.0896 - val_loss: 441.2574\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 283.9857 - val_loss: 439.5194\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 276.0708 - val_loss: 437.9129\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 268.3418 - val_loss: 436.4352\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 260.7956 - val_loss: 435.0833\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 253.4296 - val_loss: 433.8545\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 246.2409 - val_loss: 432.7459\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 239.2267 - val_loss: 431.7545\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 232.3840 - val_loss: 430.8777\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 225.7102 - val_loss: 430.1125\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 219.2022 - val_loss: 429.4564\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 212.8574 - val_loss: 428.9064\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 206.6733 - val_loss: 428.4599\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 200.6468 - val_loss: 428.1141\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.7754 - val_loss: 427.8663\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 189.0563 - val_loss: 427.7140\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 183.4868 - val_loss: 427.6542\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 178.0643 - val_loss: 427.6846\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 172.7863 - val_loss: 427.8024\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 167.6498 - val_loss: 428.0050\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 162.6527 - val_loss: 428.2899\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 157.7921 - val_loss: 428.6545\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 153.0656 - val_loss: 429.0962\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 148.4705 - val_loss: 429.6127\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 144.0044 - val_loss: 430.2013\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 139.6647 - val_loss: 430.8596\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 135.4491 - val_loss: 431.5852\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 131.3548 - val_loss: 432.3756\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 127.3797 - val_loss: 433.2285\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 123.5212 - val_loss: 434.1416\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 119.7768 - val_loss: 435.1124\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 116.1444 - val_loss: 436.1386\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 112.6216 - val_loss: 437.2177\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 109.2062 - val_loss: 438.3479\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 105.8955 - val_loss: 439.5267\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 102.6873 - val_loss: 440.7519\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 99.5795 - val_loss: 442.0212\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 96.5699 - val_loss: 443.3328\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 93.6561 - val_loss: 444.6841\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 90.8360 - val_loss: 446.0734\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 88.1074 - val_loss: 447.4985\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 85.4681 - val_loss: 448.9571\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 82.9160 - val_loss: 450.4476\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 80.4491 - val_loss: 451.9678\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 78.0652 - val_loss: 453.5157\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 75.7623 - val_loss: 455.0897\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 73.5385 - val_loss: 456.6876\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 71.3916 - val_loss: 458.3076\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 69.3198 - val_loss: 459.9480\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 67.3210 - val_loss: 461.6069\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 65.3933 - val_loss: 463.2826\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 63.5350 - val_loss: 464.9733\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 61.7440 - val_loss: 466.6774\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 60.0187 - val_loss: 468.3932\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 58.3572 - val_loss: 470.1191\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 56.7576 - val_loss: 471.8537\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 55.2182 - val_loss: 473.5953\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 53.7372 - val_loss: 475.3423\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52.3131 - val_loss: 477.0935\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50.9441 - val_loss: 478.8473\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49.6285 - val_loss: 480.6023\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48.3648 - val_loss: 482.3569\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.1514 - val_loss: 484.1104\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 45.9867 - val_loss: 485.8610\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44.8692 - val_loss: 487.6080\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 43.7973 - val_loss: 489.3497\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 42.7697 - val_loss: 491.0850\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 41.7849 - val_loss: 492.8129\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 40.8414 - val_loss: 494.5324\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39.9380 - val_loss: 496.2419\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39.0732 - val_loss: 497.9411\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 38.2457 - val_loss: 499.6286\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 37.4543 - val_loss: 501.3038\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36.6976 - val_loss: 502.9656\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 35.9745 - val_loss: 504.6129\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 35.2837 - val_loss: 506.2454\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 34.6241 - val_loss: 507.8618\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 33.9945 - val_loss: 509.4617\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 33.3938 - val_loss: 511.0443\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 32.8209 - val_loss: 512.6091\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 32.2747 - val_loss: 514.1551\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 31.7543 - val_loss: 515.6818\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 31.2586 - val_loss: 517.1887\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 30.7866 - val_loss: 518.6755\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 30.3373 - val_loss: 520.1418\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 29.9099 - val_loss: 521.5868\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 29.5035 - val_loss: 523.0098\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 29.1172 - val_loss: 524.4111\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 28.7502 - val_loss: 525.7897\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 28.4016 - val_loss: 527.1458\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 28.0706 - val_loss: 528.4785\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 27.7566 - val_loss: 529.7883\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 27.4588 - val_loss: 531.0743\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 27.1763 - val_loss: 532.3370\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 26.9086 - val_loss: 533.5756\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 26.6550 - val_loss: 534.7902\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 26.4148 - val_loss: 535.9808\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 26.1874 - val_loss: 537.1470\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 25.9723 - val_loss: 538.2889\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 25.7689 - val_loss: 539.4070\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 25.5764 - val_loss: 540.5003\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 25.3946 - val_loss: 541.5695\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 25.2227 - val_loss: 542.6147\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 25.0605 - val_loss: 543.6353\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 24.9073 - val_loss: 544.6324\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 24.7627 - val_loss: 545.6056\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 24.6263 - val_loss: 546.5544\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 24.4977 - val_loss: 547.4801\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 24.3764 - val_loss: 548.3819\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 24.2621 - val_loss: 549.2606\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 24.1544 - val_loss: 550.1164\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 24.0530 - val_loss: 550.9492\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 23.9575 - val_loss: 551.7594\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 23.8677 - val_loss: 552.5474\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 23.7831 - val_loss: 553.3130\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 23.7035 - val_loss: 554.0570\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 23.6287 - val_loss: 554.7793\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 23.5584 - val_loss: 555.4806\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 23.4923 - val_loss: 556.1606\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 23.4302 - val_loss: 556.8203\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 23.3719 - val_loss: 557.4595\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 23.3171 - val_loss: 558.0790\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 23.2656 - val_loss: 558.6788\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 23.2173 - val_loss: 559.2593\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 23.1720 - val_loss: 559.8210\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 23.1295 - val_loss: 560.3642\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 23.0896 - val_loss: 560.8893\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 23.0521 - val_loss: 561.3965\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 23.0170 - val_loss: 561.8863\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.9841 - val_loss: 562.3591\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.9532 - val_loss: 562.8152\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.9243 - val_loss: 563.2553\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 22.8971 - val_loss: 563.6795\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 22.8717 - val_loss: 564.0880\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.8479 - val_loss: 564.4817\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.8256 - val_loss: 564.8604\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.8047 - val_loss: 565.2248\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.7851 - val_loss: 565.5752\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.7667 - val_loss: 565.9122\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.7496 - val_loss: 566.2360\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.7335 - val_loss: 566.5470\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 22.7184 - val_loss: 566.8457\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.7043 - val_loss: 567.1322\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.6910 - val_loss: 567.4069\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.6787 - val_loss: 567.6703\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.6671 - val_loss: 567.9226\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.6562 - val_loss: 568.1644\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.6461 - val_loss: 568.3955\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.6366 - val_loss: 568.6170\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.6277 - val_loss: 568.8285\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.6194 - val_loss: 569.0310\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.6116 - val_loss: 569.2241\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.6043 - val_loss: 569.4081\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5975 - val_loss: 569.5847\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.5912 - val_loss: 569.7526\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.5852 - val_loss: 569.9128\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.5797 - val_loss: 570.0652\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5745 - val_loss: 570.2111\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5697 - val_loss: 570.3498\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5652 - val_loss: 570.4816\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5609 - val_loss: 570.6069\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5570 - val_loss: 570.7261\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5534 - val_loss: 570.8394\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5500 - val_loss: 570.9474\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5468 - val_loss: 571.0494\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5439 - val_loss: 571.1468\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5411 - val_loss: 571.2386\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5386 - val_loss: 571.3257\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.5362 - val_loss: 571.4083\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5340 - val_loss: 571.4866\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5320 - val_loss: 571.5604\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5302 - val_loss: 571.6305\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5284 - val_loss: 571.6967\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5268 - val_loss: 571.7596\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 22.5253 - val_loss: 571.8183\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5240 - val_loss: 571.8741\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5228 - val_loss: 571.9265\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5217 - val_loss: 571.9763\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 22.5207 - val_loss: 572.0228\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5198 - val_loss: 572.0667\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5189 - val_loss: 572.1078\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5182 - val_loss: 572.1471\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5174 - val_loss: 572.1835\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5169 - val_loss: 572.2178\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5164 - val_loss: 572.2502\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5159 - val_loss: 572.2804\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5155 - val_loss: 572.3085\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5152 - val_loss: 572.3353\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5148 - val_loss: 572.3600\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5146 - val_loss: 572.3830\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5144 - val_loss: 572.4047\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5143 - val_loss: 572.4252\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5142 - val_loss: 572.4437\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5141 - val_loss: 572.4612\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5141 - val_loss: 572.4777\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5141 - val_loss: 572.4927\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5141 - val_loss: 572.5067\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5142 - val_loss: 572.5200\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5143 - val_loss: 572.5322\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 22.5145 - val_loss: 572.5439\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5146 - val_loss: 572.5545\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5148 - val_loss: 572.5641\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5150 - val_loss: 572.5731\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5152 - val_loss: 572.5813\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5154 - val_loss: 572.5889\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5157 - val_loss: 572.5959\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5159 - val_loss: 572.6022\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5162 - val_loss: 572.6078\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5165 - val_loss: 572.6129\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5168 - val_loss: 572.6179\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5172 - val_loss: 572.6224\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5175 - val_loss: 572.6265\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5178 - val_loss: 572.6299\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5182 - val_loss: 572.6332\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5185 - val_loss: 572.6360\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5189 - val_loss: 572.6387\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 22.5193 - val_loss: 572.6406\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 22.5197 - val_loss: 572.6431\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5200 - val_loss: 572.6446\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5204 - val_loss: 572.6459\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5208 - val_loss: 572.6472\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5212 - val_loss: 572.6481\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5216 - val_loss: 572.6490\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5220 - val_loss: 572.6495\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5224 - val_loss: 572.6497\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5228 - val_loss: 572.6498\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5232 - val_loss: 572.6504\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5236 - val_loss: 572.6503\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5241 - val_loss: 572.6503\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5245 - val_loss: 572.6501\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5249 - val_loss: 572.6501\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5253 - val_loss: 572.6496\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5257 - val_loss: 572.6490\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5261 - val_loss: 572.6483\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5265 - val_loss: 572.6478\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5269 - val_loss: 572.6470\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 22.5273 - val_loss: 572.6467\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5277 - val_loss: 572.6458\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5281 - val_loss: 572.6451\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5285 - val_loss: 572.6446\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5289 - val_loss: 572.6436\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5293 - val_loss: 572.6427\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5296 - val_loss: 572.6414\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5301 - val_loss: 572.6402\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5305 - val_loss: 572.6390\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5308 - val_loss: 572.6376\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5312 - val_loss: 572.6367\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 22.5316 - val_loss: 572.6357\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 22.5320 - val_loss: 572.6345\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5324 - val_loss: 572.6337\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5327 - val_loss: 572.6326\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5331 - val_loss: 572.6312\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5335 - val_loss: 572.6301\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5338 - val_loss: 572.6288\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 22.5342 - val_loss: 572.6279\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5345 - val_loss: 572.6268\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5349 - val_loss: 572.6260\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5352 - val_loss: 572.6247\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5355 - val_loss: 572.6233\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 22.5359 - val_loss: 572.6219\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5363 - val_loss: 572.6210\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5366 - val_loss: 572.6199\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5369 - val_loss: 572.6188\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5373 - val_loss: 572.6176\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5376 - val_loss: 572.6168\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5379 - val_loss: 572.6157\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5382 - val_loss: 572.6145\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5385 - val_loss: 572.6136\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5388 - val_loss: 572.6122\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5391 - val_loss: 572.6114\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5394 - val_loss: 572.6105\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5397 - val_loss: 572.6093\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 22.5400 - val_loss: 572.6083\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5403 - val_loss: 572.6073\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5406 - val_loss: 572.6063\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5409 - val_loss: 572.6052\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5411 - val_loss: 572.6042\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5414 - val_loss: 572.6030\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5417 - val_loss: 572.6024\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5420 - val_loss: 572.6016\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5422 - val_loss: 572.6005\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5424 - val_loss: 572.5995\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5427 - val_loss: 572.5985\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5429 - val_loss: 572.5974\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5432 - val_loss: 572.5967\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 22.5435 - val_loss: 572.5960\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5437 - val_loss: 572.5949\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5439 - val_loss: 572.5938\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5442 - val_loss: 572.5932\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5444 - val_loss: 572.5926\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5446 - val_loss: 572.5916\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5448 - val_loss: 572.5904\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5451 - val_loss: 572.5897\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 22.5453 - val_loss: 572.5890\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5455 - val_loss: 572.5884\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5457 - val_loss: 572.5872\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5460 - val_loss: 572.5867\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5461 - val_loss: 572.5857\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5464 - val_loss: 572.5851\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5465 - val_loss: 572.5839\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5468 - val_loss: 572.5831\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5469 - val_loss: 572.5825\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5471 - val_loss: 572.5819\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.5474 - val_loss: 572.5809\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5475 - val_loss: 572.5803\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5477 - val_loss: 572.5795\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5479 - val_loss: 572.5789\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5481 - val_loss: 572.5779\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5483 - val_loss: 572.5776\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5484 - val_loss: 572.5766\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5486 - val_loss: 572.5760\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 22.5488 - val_loss: 572.5757\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5489 - val_loss: 572.5748\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5491 - val_loss: 572.5742\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5492 - val_loss: 572.5735\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5494 - val_loss: 572.5730\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5496 - val_loss: 572.5726\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5497 - val_loss: 572.5717\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5499 - val_loss: 572.5714\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5500 - val_loss: 572.5707\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5502 - val_loss: 572.5701\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.5503 - val_loss: 572.5695\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5505 - val_loss: 572.5693\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5505 - val_loss: 572.5683\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5507 - val_loss: 572.5681\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.5509 - val_loss: 572.5678\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5510 - val_loss: 572.5673\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.5511 - val_loss: 572.5669\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.5513 - val_loss: 572.5665\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5513 - val_loss: 572.5662\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5515 - val_loss: 572.5652\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 22.5516 - val_loss: 572.5649\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5517 - val_loss: 572.5643\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.5519 - val_loss: 572.5640\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5520 - val_loss: 572.5635\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5521 - val_loss: 572.5629\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5522 - val_loss: 572.5627\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5523 - val_loss: 572.5618\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5524 - val_loss: 572.5616\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5525 - val_loss: 572.5614\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5526 - val_loss: 572.5611\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5527 - val_loss: 572.5605\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5528 - val_loss: 572.5601\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5529 - val_loss: 572.5596\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5530 - val_loss: 572.5592\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5531 - val_loss: 572.5583\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5532 - val_loss: 572.5581\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5533 - val_loss: 572.5579\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 22.5534 - val_loss: 572.5574\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5535 - val_loss: 572.5569\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5536 - val_loss: 572.5567\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5536 - val_loss: 572.5563\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5538 - val_loss: 572.5563\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5538 - val_loss: 572.5557\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5539 - val_loss: 572.5555\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5540 - val_loss: 572.5549\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5541 - val_loss: 572.5547\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5542 - val_loss: 572.5543\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5542 - val_loss: 572.5540\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.5543 - val_loss: 572.5536\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5544 - val_loss: 572.5531\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.5545 - val_loss: 572.5529\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5545 - val_loss: 572.5528\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 748ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61.79264706, 61.77303922, 61.75343137, 61.73382353, 61.71421569,\n",
       "        61.69460784, 61.675     , 61.65539216, 61.63578431, 61.61617647,\n",
       "        61.59833333, 61.58880952, 61.57928571, 64.0200747 , 63.94820261,\n",
       "        63.88937908, 63.83055556, 63.77173203, 63.7129085 , 63.65408497,\n",
       "        63.59526144, 63.53643791, 63.47761438, 63.41879085, 63.35996732,\n",
       "        63.30114379, 63.22584034, 63.15021008, 63.07457983, 62.99894958,\n",
       "        62.92331933, 62.84768908, 62.77205882, 62.69642857, 62.62079832,\n",
       "        62.54516807, 62.46953782, 62.39932306, 62.3909197 , 62.38251634,\n",
       "         0.        ,  0.20421855,  0.61028612,  0.28336877,  0.27068555,\n",
       "         0.        ,  0.22790316, 63.3142157 , 63.2426471 , 63.1670168 ,\n",
       "        63.0913866 , 63.0157563 , 62.9401261 , 62.8644958 , 62.7888655 ,\n",
       "        62.7132353 , 62.637605  , 62.5619748 , 62.4863445 , 62.4107143 ,\n",
       "        62.3927871 , 62.3843837 , 62.3759804 , 62.367577  , 62.3591737 ,\n",
       "        62.3507703 , 62.3423669 , 62.3339636 , 62.3255602 , 62.3171569 ,\n",
       "        62.3087535 , 62.3003501 , 62.2436274 , 69.1144409 ,  0.        ,\n",
       "         0.49128151,  0.33295783,  0.        ,  0.        ,  0.28975713,\n",
       "        61.75678635,  0.07443897,  0.50925428,  0.        ,  0.        ,\n",
       "         0.28427166,  0.11085498,  0.50166839,  0.        ,  0.4965252 ,\n",
       "         0.        ,  0.        ,  0.        ,  0.53235954,  0.        ,\n",
       "         0.44235113,  0.26223385,  0.14824872,  0.2936219 ,  0.706635  ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58.99386088, 58.9835901 , 58.97331933, 58.96304855, 58.95277778,\n",
       "       58.942507  , 58.93223623, 58.92196545, 58.91169468, 58.9014239 ,\n",
       "       58.89115313, 58.88088235, 58.87061158, 58.8603408 , 58.85007003,\n",
       "       58.83979925, 58.82952848, 58.8192577 , 58.80898693, 58.79801587,\n",
       "       58.78214286, 58.76626984, 58.75039683, 58.73452381, 58.71865079,\n",
       "       58.70277778, 58.68690476, 58.67103175, 58.65515873, 58.63928571,\n",
       "       58.6234127 , 58.60753968, 58.59166667, 58.57579365, 58.55992063,\n",
       "       58.54404762, 58.5281746 , 58.51230159, 58.49642857, 58.48055556,\n",
       "       58.46468254, 58.44880952, 58.43293651, 58.41706349, 58.40119048,\n",
       "       58.38531746, 58.36944444, 58.35357143, 58.33769841, 58.3218254 ,\n",
       "       58.30595238, 58.29007937, 58.27420635, 58.25833333, 58.24246032,\n",
       "       58.2265873 , 58.21071429, 58.19484127, 58.17896825, 58.16309524,\n",
       "       58.14722222, 58.13134921, 58.11547619, 58.09960317, 58.08373016,\n",
       "       58.06785714, 58.05198413, 58.03611111, 58.0202381 , 58.00436508,\n",
       "       57.98849206, 57.97261905, 57.95674603, 57.94087302, 57.925     ,\n",
       "       57.90912698, 57.89325397, 57.87738095, 57.86150794, 57.84563492,\n",
       "       57.8297619 , 57.81388889, 57.79801587, 57.78214286, 57.76626984,\n",
       "       57.75039683, 57.73452381, 57.71865079, 57.70277778, 57.68690476,\n",
       "       57.67103175, 57.65515873, 57.63928571, 57.6234127 , 57.60753968,\n",
       "       57.59166667, 57.57579365, 57.55992063, 57.54404762, 57.5281746 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.81391892226013\n",
      "21.328833141971504\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
