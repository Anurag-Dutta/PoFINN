{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2195    54.858468\n",
       "2196    54.849723\n",
       "2197    54.840978\n",
       "2198    54.832233\n",
       "2199    54.823488\n",
       "Name: C1, Length: 2200, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_2100_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2095     0.000000\n",
       "2096     0.075181\n",
       "2097     0.000000\n",
       "2098     0.146630\n",
       "2099     0.282301\n",
       "Name: C1, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2100)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAld0lEQVR4nO3deXgc1Z3u8e9Pu2XJkrVY3hdhG2Kz2RhsYrBDSDAhcwcymSErQyYEbhJyk8xMbm4me+7M5Elyb/aQhayELEwmJBAmwcYmgAlgQDYY7ys2trE221psa9eZP7olt5aWuquX6pLez/P4UXd1VdfpeuS3j3516pQ55xARkeDJ8rsBIiLijQJcRCSgFOAiIgGlABcRCSgFuIhIQOWkc2cVFRVu7ty56dyliEjgbd68udE5Vzl4eVoDfO7cudTU1KRzlyIigWdmh4dbrhKKiEhAKcBFRAJKAS4iElAKcBGRgFKAi4gElAJcRCSgFOAiIgEViAB/8MVj/GLTsMMgRUTGrUAE+Lodtdz12H40d7mIyDmBCPCV8ys43tzOwcYzfjdFRCRjBCPAz6sA4On9jT63REQkcwQiwOeUFzKjdAJ/UYCLiPQLRICbGVfNr+CZAyfo6VUdXEQEAhLgACsXVNDS3s0ftx33uykiIhkhMAF+3aIqlswu5WO/2cpTKqWIiAQnwAtys/npey5nXsVEbv95DVteOeV3k0REfBWYAAcoLczj3tuuoKIon7f94Bk+9+B2Glo7/G6WiIgvAhXgAFMmFfDbD1zJ3142i188+wqr/99jfG39Xlrbu/xumohIWlk6r25ctmyZS+Yt1Q40nOZrj+zlj9uOUzYxjzuvmc+7V8wmPyc7afsQEfGbmW12zi0bvDxwPfBI51UWcde7lvLgnSt5zbRi/vW/drLm6xt5/tBJv5smIpJygQ7wPpfMKuWX71vBPe+9gh7nuPkHz/CFh3bQ1tnjd9NERFJmTAR4n9ULK1n7kVX8/Yo5/PSpQ1z/zY0897J64yIyNo2pAAeYmJ/DF268kF/fvgLn4G13P8O9mopWRMagMRfgfa48r5y1H72aay+Ywmce2M4vn1WIi8jYMmYDHKAwL4e73rWUay+Ywqd+v51fPfuK300SEUmamALczP7RzHaY2XYz+7WZFZjZPDN71sz2m9l/mFleqhvrRX5ONt9991Jef8EUPvn7bQpxERkzRg1wM5sBfBhY5py7EMgG3g58Gfi6c24+cAq4LZUNTUR+Tjbfe/dSrjm/kk/+fhu/fk4hLiLBF2sJJQeYYGY5QCFwHHg98Nvw6/cANyW9dUkUCvHLWL2wkn/53TZu/clz/OrZV3QpvogE1qgB7pw7Bvx/4BVCwd0MbAaanHPd4dWOAjNS1chkKcjN5ge3XMYHX3ceLzee4ZO/38YVX9zA333/aX705EGOnDzrdxNFRGI26qX0ZjYZuB94G9AE/Cehnvfnw+UTzGwW8HC4xDJ4+zuAOwBmz5592eHDmTEaxDnHruOtrNtRy7odteyubQVg0bRJrFk8lTUXVnF+VTFm5nNLRWS8i3YpfSwB/nfA9c6528LP/x64Evg7YKpzrtvMriQU6GtGeq9kz4WSTIdPnOGRHXWs3VHLlldO4RzMLS9kzeKpXLd4KktmlZKVpTAXkfRLJMCXAz8BLgfagJ8BNcAq4H7n3H1m9n3gJefcd0d6r0wO8Ej1re2s31nHuh11PHOgka4ex5TifN64qIrrL5zKiupycrPH9AhMEckgngM8vPEXCJVQuoEXgPcRqnnfB5SFl73bOTfiGcGgBHik5rYuHttdz7odtTy+p4G2rh4mFeRw7WuqWLO4ilULKynMy/G7mSIyhiUU4MkSxACP1N7Vw5P7Glm7vZZHd9fRdLaLgtwsVi2oZM3iqVz7mimUFmbkcHgRCbBoAa6uYxwKcrN546Iq3rioiu6eXp57+WT4JGgdj+ysIzvLuLK6nDWLq7hu8VSqJhX43WQRGcPUA0+C3l7HS8ea+0e0HGw4A8Cls0pDI1oWV1FdWeRzK0UkqFRCSaP99a2s3R7qmW871gzAwqoirjl/Cq+dX8EVc8uYkKe7BolIbBTgPjnW1MYjO2p5ZEcdNYdP0tXjyMvOYsnsUq6aX8Fr51dwycwScjSqRUSiUIBngLOd3Tx/6BRP7W/kqf2N7DzegnNQnJ/D8uoyVs6vYOX8ChZMKdIFRCLSTycxM0BhXg6rF1ayemElACfPdPLMgRM8dSAU6Bt21QNQWZzPyvPKueaCKdxw0TSNOReRYakHnkGOnDzL0wcaeWr/CZ4+0Ejj6U5mlE7gf66u5uZlsyjIVd1cZDxSCSVgnHM8vqeB7zy2n82HT1FRlMdtV1Xz7hWzKS7I9bt5IpJGCvCAcs7x7Msnueux/Ty5r5FJBTm857Vzec/KeZRN1EVDIuOBAnwMeOloE9997ABrd9QyITebdy6fze1XVzO1RBcMiYxlCvAxZF9dK997/AAPbn2VbDPeetlM3r+6mjnlE/1umoikgAJ8DDpy8izff+IA/1lzlO7eXv76kul84HXzOX9qsd9NE5EkUoCPYfUt7fzoLy/zi02HOdvZwxsXVXHnNfO5dFap300TkSRQgI8Dp8508rOnD/Gzpw/R3NbFBVOLWVFdzorqcpbPK2OyTnqKBJICfBw53dHNfc+9wmN76tl8+BTtXb0AEYFexhXzyjWKRSQgFODjVGd3Ly8dbWLTwRNsOniSmsMn+wP9/KpiVlSXsaK6nCvmlVFelO9za0VkOApwAUKBvu1YE5sOnmTTwRPUHDpFW1cPEJoxsa/kcsW8MioU6CIZQQEuwwoFenO4h36CzYdPcbYzFOgLpoQCPTTJVrmuAJV+X3tkD+t31fPwR672uykjamnvYsn/Xc+Pb13G686f4ndzPNNkVjKsvJwsLpszmcvmTObOa+bT1RMZ6Ce5f8tR7t10mOwsY+nsUlYtqGTVwkoumlFCVpZmTByvvvXn/Z62a27r4pIvPMJd71zKmy+eFte2fZ3NeGbq3FPbSk+v4zt/3h93gH/mge2s31nHpk9eG9d24K2tXijAZYDc7CyWzp7M0tmT+eDrQj30La+cYuPeBjbua+Cr6/fy1fV7mVyYy1ULKlm1oIJVCyt1+ziJycGG0wDcvfFA3AF++883s2FXHYe+9OaYt+npDQVplocgvXfT4bi3AahvbeeKf3+UL77lIt65fLan94iVAlxGlJeT1V8X//j1F9B4uoO/7GsMB3ojD219FQiNcFm1sJJVCypZNneyZk6UYYXz1FPPdMOuOg/7Cwd4GmdkPtR4FoDfbTmqAJfMUlGUz01LZnDTkhn09jp21bbwZDjQf/bUIe7eeJCC3CwunF7C1JICpk4qCP0MP64K/8vL0Rzn41FfaSE7TeW3vlN8RvrKfee+NFK/TwW4eJaVZSyeXsLi6SW8f/V5nO3sZtPBE2zc28iu4y1sP9bMhl11/cMWI5VPzKMqHO5VkwqY1hfwfaE/qYBJE3J0Z6Ixpq8Hnq7TJ370wPv3mYbPqACXpCnMy+H1F1Tx+guq+pc552hp66a2pZ3jzW3UtbRT29xBbUt7+HE7W480ceJM5zDvl82c8olUV06kuiL0c15FEfMqJlIyQSNigqg3TSf3zu0v9NNLDdwrl8Z9KsAlpcyMksJcSgpzR5xkq6O7h/qWULDXNofC/VhTG4caz7DjWDNrt9f2n5ACqCjKY17FRKoripgXEfCzygrJz1H9PVP19qavdwqRvWEfSigKcBkv8nOymVVWyKyywmFf7+zu5ZWTZznYcJqXG89wsOEMLzee4dHd9TTWdPSvl2VQXVnEVfMrWL2wkuXVZRTm6dc8U/R9B6erBp7uLwyIPFGb+n3pN1sCIS8ni/lTipg/pWjIa81tXRxqPMPBxtO83HCGrUebue/5V/jZ04fIy87i8nmTWb0wNH79/Kpi1dV91F9CSdNJRT9KKL0JDF2MlwJcAq9kQi6XzCrlkojpc9u7enj+0Ek27m3gib0NfPFPu/nin3ZTNSmfqxdUsnphJVfNr9AMjWl2rgaenv2l64KaSDqJKZKggtxsrl5QydULKvnUm+F4cxtP7m3kiX0NrN9Zx283H8UMLplZyqqFlaxeWMElM0vJydbwxlRy6S6hpDFM++gkpkiSTSuZwM2Xz+Lmy2fR0+vYerSpv3f+nT/v41uP7mNSQQ4r51dQXTmxf8x63xj2ion5Y3rqgPauHj7/hx2cP7WYNYunMr10Qkr2k8iVkbH63ZajTC0p4LXnVUStude1tPP19Xv58LULkv5Ze9LY61eAy7gTmtclNF3AR9+wkKaznTy1/wRP7K3nmYMneGRn3YARLwA5WcaU4vz+cer94T7o8YS8YI6A2XW8hfuePwLAFx7aySUzS1hz4VTWLJ7KeZVDzztEOt3RzdmObqbEMJ1COnrEX1m7h8bTHXzrHUuilmxqDp3ivuePcN/zR9j4v69hdnno5Pnpjm6K8keOxZNnOsnLyYq63rmLlRL8IDFQgMu4V1qYx5svntY/N0dPr+PE6YFDGmvD49frWtrZW9fKk/saOd3RPeS9JhXkMK1kQjjo85leOoEZff8mT2BayYSMvAq1szt0sdW/3nQhre1drNtey1fW7uEra/ewYEoRb7poGjdeOn3YMP/sA9v53QvHWD6vjLcuncmbLpoadebKRC6lj1V7dw89zvGhX23h9RdMGXZ/XT3nLi57xw83cd8dK9hd28oHfrGZb759yYjztLzzh5vYXdvK5k+/Ydg59HvTePWnAlxkkOwsY8qkAqZMKuDimdHXO93RfS7gm9sHXJxU19LO7uMtNJzuIHLGZjOoLMpnxuQJTC+dwMxwsE8vCf0sn5hHbnYWOdlGbnYWudlZaakXd/acu2vT5XPL+ODr5vNqUxuP7Khl7Y5avh0uM10ys4SblswYsG1TWxelhbnUt3bw8ftf4jMPbue6xVP5m6UzWDKrlOKC3P7P4CJ64M45NuyqZ055IdNKCpiYl5OUMlVndy9vv3w2hxrPsGFXPQDZgwK87wvr7lsu4+P3v8Q7friJtyyZQXev48P3vTBs7/mhra/ycuMZdte2AnDbPTX84n3LKcrPoba5newso7I4P61XfyrARTwqys+JOrSxT0d3D7XN7Rw71caxpvC/U2282tzGjmPNrN9R1x+e0ZhBblYWudlGTjjUQ4/DIZ91LvAnTchlSnE+lcX5ET8L+h9PjPJnf1+g5UUk1/TSCbxn5Tzes3Ietc3tPLT1VR548RhfeGjnkO1nlxXy4J0reeFIE7/fcoyHXnq1f6KzvmM1qSCHV5vbgdCX5N6609z+83P3BzDrWy+X4oIcFk8v4ZoLKrl6fiUlhQN79N/csI9fPnuY6aUTuPK8cq45fwpLZ4dOQnd29zK5MJdP37qMxZ9bB0D+oL96OsLH/NLZpdz73uXc9N2n+HZ4itw55YW8/xdbhnzGLz28m2NNbf3Ptx5t4qLPr2N2WSGHT4QmsCotzO3/K0UnMUUCLj8nNB3AnPKJw77e2+toPNPRH/CnznbR3dNLd4+jq7eXrm5Hd28vXT2Orp5eunt66exxoXV6HZ3hZX2vN53tZF9dKw2tHXQPquMDTMzL7g/1ynCoVxbnUxsO1mjlnaklBdy+qprbV1Wzt66V676+ccg6ZufOLXzmrxbx5L4GDp84S0t7Fy1t3bS0d3Gg4TQvvNLEwqpiOrpDNw654aKpXDqrlNb2blrbQ+s1ne1iw6467t9ylOws47LZkwfsa+vRJtq7esjLzuKHGw/yvccPUFyQw6oFlXT3OvJyspiYn8OGf1rNG772BBeHh5ie6ejmY/+5lfrW0MVf+dnZXDSzhOsXT+WP244DoV7543sa+Lc/7gLg3mcOccuVc1lYVdQf4NctquK2q+bx5z31/OCJg/3tunRWKY/vaQAU4CJjXlaWhXvIBSwZFFKJ6O11nDrbScPpDupbOmho7aC+te9nOw2tHew63sLGvR20hmv5ZjC5cPRx8Qurinn3itk8vK0WOFcWiZSXk8W1r6kasrzxdAfL/m0D5RHj79+6dOaw63b39LL1aBOP7W7gsT31Q16fUz6R37z/Slrbu3hqfyOP7zm3Xt/tACcVhCKurzJzoOE0D28PtXtiXnb/SecZk8+NRJmYn8P7rq7mQMNpfv3cET7z4A5uuXLukDr68upyLppZ0h/gNy+byZf+5mL+6Tcv8sCLrzK5MPXz9cQU4GZWCvwIuBBwwHuBPcB/AHOBQ8DNzrlTqWikiMQnK8soL8qnvCifC6aOvO7Zzm4aWztxOKaWZM6NOXKys7hsThmXzSnjY2vO5/33bh42yIsLcrn+wmlcf+E0nHMcPdXGtFE+x7ffsYTl1WWjnFAeGNiRX1TROtdZWcYnb3gND7z4KgtHmPsnWWIts38TWOucuwC4BNgFfAJ41Dm3AHg0/FxEAqYwL4fZ5YVRyzyx8FIsiPd2vJE1/Gj38jUzZpUVDrkg69//uIsjJ8/2Py/My2ZKceZ8WXk1aoCbWQmwCvgxgHOu0znXBNwI3BNe7R7gptQ0UUQyUSK3Q4/cNh1XuZ/t7OFDv9oS9UvDBjyOvUGR66bzphF9YumBzwMagJ+a2Qtm9iMzmwhUOeeOh9epBYYWsQAzu8PMasyspqGhITmtFhFfRYZVPEGezIiLKfgj1umJt8sfALEEeA6wFPiec24JcIZB5RIX+ntm2KPjnLvbObfMObessrIy0faKyBjhJU6jlU7iFUv4D15nwF8NMXwVpeP7IpYAPwocdc49G37+W0KBXmdm0wDCP4eeXRCR8SGBOkispYfIXWRiX7q/fWmspIwa4M65WuCImZ0fXnQtsBP4A3BreNmtwIMpaaGIZKS+3rCXnqZf1Yyou40I3Xi+i/yeWj7WceD/C/ilmeUBB4F/IBT+vzGz24DDwM2paaKIZBqvwZXMOVBiK4GnJmH9Du4+MQW4c+5FYNkwL12b1NaIyLjhpZ6drI57LME+eI14m5uOPzIyb1o0EQmchDqkMW4cuVqySzADhwN6fA8b+l6ppgAXEU/coJ9xbZuMBPZQx0jWKJZMoQAXkbh57qUmtRUx7C/aDj00JN0XH8VCAS4ivvDWc/e+bbwSDuk09PYV4CKSsETCLtZNkzGCJVqkDnhrz8MIbZhlqaUAF5GE+DWaJEOqGL5SgIuIJ14qBJlSO/Y2e2LEdLIZ8vWhABeRuA0uZ6RjOtnQNm7Az9EkErOJhrTGgYvImJfKO9QPltLpZPvHgaePAlxE0s6nYeDJkxkVFAW4iHjj5eTlwN6tfxfVpLPXn0oKcBFJWCKBGM+W8UZ+OoM60blTvFCAi0hC0nV1+uAs9hbN0e6lOfSxl5s+hJZpLhQRGcOCOCNJ5BdVphRgFOAi4omnEI68q04CKZ5orz9TAjhRCnARiVtyyhnDv9eI4gzuWOvSXsd8Dxh+OPgempoLRUQynUtTQWRwyKaq1pzorS01DlxExjS/5+X2kv2RX1SZMgxRAS4i3iQ4F0oiEZ6uXn+mU4CLSNyGljOS914jiX8ceGzbJ+MmzYM/h+ZCEZGMF6xx4LHsxwb8jH/7ZLZmZApwERl3vIw60ThwERkzvHS8k3Vn+TF2b2LPFOAiEreh5YwE5kJJYXd2SF06pulk43n/iMdDxoHH8UYeKcBFJCHp7A0PuCuOj3WMkfadzrv1KMBFJO2ci38seDJj0dM48Aws2yjARcQTT/OBD5Oc6bodW2i75KbwgFkMk/rOsVGAi0jchoSVD+kVU6ki1nZFjudO0mfROHARyXjpvCoyWXuKJaOHXgQUeVf6BN88SRTgIpJ2zkPsD7wMPwML0j5QgItI2gzbOU1jjzXqpfQe32/ApfQ+DItRgIuIJ31h6JxPVyamaKfJGgao+cBFJCP5NQY73kyM2s6Yzn9GvwhopN625kIRkTEtNA48vm0iQzMTx2QPtvnwKdq7elK6DwW4iCQs1l7nsHdxT2MBJuql9ClowsPba/n0A9uT/8YRYg5wM8s2sxfM7L/Cz+eZ2bNmtt/M/sPM8lLXTBHJNH1h6FdnOGWxn8Q33l3bkrw3G0Y8PfCPALsinn8Z+Lpzbj5wCrgtmQ0Tkczl1y3F4h0+GL0EPnr7R7oZxEhbZ9w9Mc1sJvBm4Efh5wa8HvhteJV7gJtS0D4RGYMciYVxJpXA/ZxUK9Ye+DeAjwO94eflQJNzrjv8/CgwY7gNzewOM6sxs5qGhoZE2ioiGSrWOvZw63m/nVn820T70khGHd6PIB81wM3sr4B659xmLztwzt3tnFvmnFtWWVnp5S1EJAP1h2EmdYdjNOJ0sNFei7WGkkY5MayzEvhrM7sBKAAmAd8ESs0sJ9wLnwkcS10zRSSTJCW/PAR/IkMP45WMqzNTbdQeuHPuX5xzM51zc4G3A392zr0LeAz42/BqtwIPpqyVIjKmeLq/ZDKK4CkYRmj9P4N1Kf3/Af7JzPYTqon/ODlNEpGgSWQcuOd9Zkodw0exlFD6OeceBx4PPz4IXJH8JolIEJwbB+7ImKJwjLwMAxw4nWxmfF5diSki8UtCfnmpgvRPoBXj1n7EbMaNAxcRSaYBvdkY6yrJ6PXGM51s7GUhi2v9ZFKAi0hCnPMnvFK1T7+uMvVCAS4ingRw+Hc/LyE9cDrZJDYmAQpwEYlbUsoZCRTBY902HUHrZ5YrwEUk7bz0ZpMRxvFMJxtvL71/PLhu6CAiQREaRBjjichkjgNP5OKbkS6l9/62aacAFxFvglwE9yADp0JRgItI/JJSzvDwDdC3TaxbDrmvZQq+dYIwnayISErEmn+D10vm1ZDD1bvjffe+t0jnVZoKcBFJiHMu9hORGVJ8GPFS+igvOudGXSfdFOAi4otE7izvgnBb+jRQgIuIJ8mqJ8fTm000t1OR+31/VfhxBacCXETilmhUeelBD87HWPIyoUxN463evFKAi0hC4oniTKkdjzwOfPgXXQzrpJsCXER8kUg1I6Mq4BpGKCJBk7x6cvoSMOp0sklogh85rgAXkbgNrUfHF19ewz95Pe/R25spZZKRKMBFJCHxhHFi5xTTE6jRx4GPvk66KcBFxBeJjOX23INPwThCTScrIoGTrCj02ptN5rjrpPTudUs1EQmCyMDzck96r+Efbw86WsZ7GUMe8wRaGgcuImNRZK853hDPlLozZE5bFOAi4isvWei5B+9xu5FoOlkRCRy/J5RKZm4mZxy45kIRkQAYEHhxTCcbsYkncZddooRqLNPJDlnHDbyYPt59poICXETSZkC0xZnGA7fNnIvp/bzgRwEuIr5K6zSs0e5Kn4S39qMWrgAXEU/87gMndlf6DBlGkiAFuIjEbUAJHC/jwL3Ff7yVEy85HdN0siNNR6tx4CIyFkWGW9whnsAYci9ivs+nhhGKyHjlNf+8jR8fPvo1nayIjCsZNBAkbmOjAq4AFxEvIssZLn3zgcfLS1DHNJ1skvfplQJcRNLGBgV/XNtGPPY+nWw8+4stikdaK9VfVKMGuJnNMrPHzGynme0ws4+El5eZ2Xoz2xf+OTm1TRWRsWisTCebqePAu4F/ds4tAlYAd5rZIuATwKPOuQXAo+HnIjLOeB0S6CcvYRv5OTNlhMqoAe6cO+6c2xJ+3ArsAmYANwL3hFe7B7gpRW0UkQznZT7wTLqrTqR4P8vgvwTSeZFQXDVwM5sLLAGeBaqcc8fDL9UCVcltmohkqqTOBBhrrdnDGPLBYRpXDTwAQ1ViDnAzKwLuBz7qnGuJfM2FvhKHPTRmdoeZ1ZhZTUNDQ0KNFRHpk8wbJKdqOlnfT2ICmFkuofD+pXPud+HFdWY2Lfz6NKB+uG2dc3c755Y555ZVVlYmo80ikkFCwwj9bkXqDRxGmBkfOJZRKAb8GNjlnPtaxEt/AG4NP74VeDD5zRORTOa5Hu28n/p0LrU923hr2IPXjnye6i+2nBjWWQncAmwzsxfDyz4JfAn4jZndBhwGbk5JC0Uk4yQ2E6C39/LS6x28RTy5P3Dc+ehb+vFXyKgB7pz7C9HLTdcmtzkiIrFJ5pdIUOlKTBFJSKhzOkYScQQDauAxftyMOIkpIjKcRO5t6bV+nuox5MNl84ibeSwJJYMCXETilsgoDM/Txw7ZcPR3iv2KyWFWTPBkpoe3iJsCXEQkBpk4YYACXEQS4hg7JwUhts9iUR6nmwJcRDxLaCy3520TGEOehu0SmTI3XgpwEYlbMu8IH/s48PjbEO2inCFj0WPYXww7i3eLhCnARURiEDmCJdarNXUSU0QymnPO2w2GM/GsIB4upffxBIACXEQ88z6WO6I36yH+Pe83zePHU00BLiJxS2wq18T0RWmqp5NNRsdaJzFFRBhbQxWTRQEuIgmLN1xDPdMMLYIPw2tLdRJTRDJWMiLY+13pvWw1fIuTkbOZeld6EZEB/JzKNRl15bFSjlGAi0hC0jUcMN3D9Qaf6Iw2nexIzdJJTBHJePEOBUxkSlgS2DYV2/k5nl0BLiK+8lwDT2RK2yFzeCfeux+uPTqJKSIZy0vvM9E7unufyioxfu13JApwEYnbgBn3MjDYkmGk3nPkl5CfJ0QV4CKSMC/jwBOJfa9fGt6nk42+pZ/1cQW4iKTXkKlcvXVhExrKGMOl9HG/p8aBi0iQ+FE+8WvUh5e70uskpohkNOe8BVW8QRy5j3SEeORHytSpbxXgIpJ2A6aTTWPpIVoQJ+VS+iS8R7wU4CKSVskKOj8v54+VTmKKSMZKdDRJkER+zgF3pdcwQhEJkqE3BfZwV504oz9yH6kYDjhkfzF+pJF62TqJKSJjT+SIDo9vkdCl9EMWJOFSeg0jFJGxLqhTuXq9D2cqKcBFJCHpDrZMyFFNJysigTWkfJH2ceCpvyv9gPleNJ2siEjIgBEd3ovgng09CZu44aak1UlMERlTEp1O1i8ZULkZQgEuIp75MQ48E6avjext+3lSNse/XYtIUCVagjhy8mz8+4x47H0cuNftom/Z3NYVfbtMPolpZteb2R4z229mn0hWo0QkGH6w8QAHG87wwitNcW338PZa7t54MPwszvtpOi9bwfZjLXz41y8Mu89EetF97XnghWNDXmvv6uGJvQ109/R638EIPPfAzSwbuAt4I3AUeN7M/uCc25msxolIZlq7vRaAb2zYB8CxpraYt23r6vG0z5eONQOw+HPrAFg0bZKn9wHo6B7Yhtrm9iHr7K1r7X+86LPrBrxWmJc9ZP199aeHLDvQcIZbf/IcAFs/ex0lhbme2htNIj3wK4D9zrmDzrlO4D7gxuQ0S0Qy2YtHmpL2Xm2dsQX60VMDvyTau7z3ageXPU6c6RyyzuN7GqJun5sdf3SeONMR9zajSSTAZwBHIp4fDS8bwMzuMLMaM6tpaIh+QEQkONb/46oBz3/7/itj3vYrb72Y5fPK+p8vmh5bT/obb7uUSQXnigbvWj47pu3+ZumQWGL5vPIBzz/4uvNYNG0SX3zLRf3L7v/AawesUzIhl0f/eTVzywv5HxdP71/+5beGtln30XPH5KfvuXzAtresmEN1ZVFM7Y2HeR0Qb2Z/C1zvnHtf+PktwHLn3IeibbNs2TJXU1PjaX8iIuOVmW12zi0bvDyRHvgxYFbE85nhZSIikgaJBPjzwAIzm2dmecDbgT8kp1kiIjIaz6NQnHPdZvYhYB2QDfzEObcjaS0TEZERJXQhj3PuT8CfktQWERGJgy6lFxEJKAW4iEhAKcBFRAJKAS4iElCeL+TxtDOzBuCwx80rgMYkNmcs0jEamY7P6HSMRubX8ZnjnKscvDCtAZ4IM6sZ7kokOUfHaGQ6PqPTMRpZph0flVBERAJKAS4iElBBCvC7/W5AAOgYjUzHZ3Q6RiPLqOMTmBq4iIgMFKQeuIiIRFCAi4gEVCACXDdPDjGzQ2a2zcxeNLOa8LIyM1tvZvvCPyeHl5uZfSt8zF4ys6X+tj41zOwnZlZvZtsjlsV9TMzs1vD6+8zsVj8+SypEOT6fN7Nj4d+jF83shojX/iV8fPaY2ZqI5WPy/6CZzTKzx8xsp5ntMLOPhJcH43fIOZfR/whNVXsAqAbygK3AIr/b5dOxOARUDFr2FeAT4cefAL4cfnwD8DCh22+vAJ71u/0pOiargKXAdq/HBCgDDoZ/Tg4/nuz3Z0vh8fk88LFh1l0U/v+VD8wL/7/LHsv/B4FpwNLw42Jgb/g4BOJ3KAg9cN08eWQ3AveEH98D3BSx/OcuZBNQambTfGhfSjnnNgInBy2O95isAdY75046504B64HrU974NIhyfKK5EbjPOdfhnHsZ2E/o/9+Y/T/onDvunNsSftwK7CJ0b99A/A4FIcBjunnyOOGAR8xss5ndEV5W5Zw7Hn5cC1SFH4/n4xbvMRmPx+pD4RLAT/rKA4zz42Nmc4ElwLME5HcoCAEu51zlnFsKvAm408wG3Brchf6W07jQCDomw/oecB5wKXAc+KqvrckAZlYE3A981DnXEvlaJv8OBSHAdfPkMOfcsfDPeuD3hP60resrjYR/1odXH8/HLd5jMq6OlXOuzjnX45zrBX5I6PcIxunxMbNcQuH9S+fc78KLA/E7FIQA182TATObaGbFfY+B64DthI5F3xnvW4EHw4//APx9+Kz5CqA54k/CsS7eY7IOuM7MJofLCdeFl41Jg86FvIXQ7xGEjs/bzSzfzOYBC4DnGMP/B83MgB8Du5xzX4t4KRi/Q36fBY7xTPENhM4OHwA+5Xd7fDoG1YTO/m8FdvQdB6AceBTYB2wAysLLDbgrfMy2Acv8/gwpOi6/JlQG6CJUd7zNyzEB3kvopN1+4B/8/lwpPj73hj//S4QCaVrE+p8KH589wJsilo/J/4PAVYTKIy8BL4b/3RCU3yFdSi8iElBBKKGIiMgwFOAiIgGlABcRCSgFuIhIQCnARUQCSgEuIhJQCnARkYD6b0q3w/2tN1UVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 1, 251) (1650, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 2s 27ms/step - loss: 4419.6943 - val_loss: 2828.6160\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4330.0127 - val_loss: 2785.1621\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4258.9590 - val_loss: 2745.9180\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4188.4487 - val_loss: 2706.3267\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4115.8389 - val_loss: 2665.3989\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4038.5190 - val_loss: 2613.5776\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3950.2913 - val_loss: 2569.1265\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3873.0459 - val_loss: 2526.3484\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3798.1531 - val_loss: 2484.0754\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3715.9546 - val_loss: 2434.7654\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3634.3965 - val_loss: 2389.7083\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3556.3906 - val_loss: 2346.6309\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3481.0637 - val_loss: 2305.0588\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3407.8289 - val_loss: 2264.7134\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3336.3538 - val_loss: 2225.4326\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3266.4380 - val_loss: 2187.1135\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3197.9490 - val_loss: 2149.6851\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3130.7937 - val_loss: 2113.0950\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3064.9016 - val_loss: 2077.3020\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3000.2185 - val_loss: 2042.2737\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2936.6990 - val_loss: 2007.9777\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2873.1082 - val_loss: 1972.5859\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2805.8286 - val_loss: 1937.1154\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2740.1289 - val_loss: 1902.9604\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2676.6799 - val_loss: 1869.8901\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2615.0225 - val_loss: 1837.7455\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2554.8835 - val_loss: 1806.4351\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2496.1057 - val_loss: 1775.9008\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2438.5879 - val_loss: 1746.1021\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2382.2571 - val_loss: 1717.0079\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2327.0598 - val_loss: 1688.5938\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2272.9529 - val_loss: 1660.8396\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2219.8999 - val_loss: 1633.7283\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2167.8711 - val_loss: 1607.2462\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2116.8398 - val_loss: 1581.3812\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2062.7854 - val_loss: 1546.5551\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1999.8423 - val_loss: 1517.9985\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1946.1906 - val_loss: 1490.9685\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1894.8091 - val_loss: 1465.1963\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1845.2139 - val_loss: 1440.4214\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1797.0858 - val_loss: 1416.4998\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1750.2460 - val_loss: 1393.3451\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1704.5817 - val_loss: 1370.9004\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1660.0148 - val_loss: 1349.1230\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1616.4877 - val_loss: 1327.9816\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1573.9561 - val_loss: 1307.4493\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1532.3816 - val_loss: 1287.5046\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1491.7329 - val_loss: 1268.1285\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1451.9835 - val_loss: 1249.3037\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1413.1080 - val_loss: 1231.0161\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1375.0852 - val_loss: 1213.2511\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1337.8951 - val_loss: 1195.9966\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1301.5195 - val_loss: 1179.2402\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1265.9403 - val_loss: 1162.9711\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1231.1418 - val_loss: 1147.1788\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1197.1091 - val_loss: 1131.8529\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1163.8268 - val_loss: 1116.9839\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1131.2815 - val_loss: 1102.5629\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1099.4600 - val_loss: 1088.5804\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1068.3486 - val_loss: 1075.0281\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1037.9360 - val_loss: 1061.8976\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1008.2093 - val_loss: 1049.1805\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 979.1561 - val_loss: 1036.8687\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 950.7661 - val_loss: 1024.9546\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 923.0270 - val_loss: 1013.4304\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 895.9286 - val_loss: 1002.2885\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 869.4598 - val_loss: 991.5221\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 843.6101 - val_loss: 981.1231\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 818.3692 - val_loss: 971.0850\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 793.7271 - val_loss: 961.4004\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 769.6736 - val_loss: 952.0624\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 746.1986 - val_loss: 943.0643\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 723.2924 - val_loss: 934.3990\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 700.9457 - val_loss: 926.0606\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 679.1494 - val_loss: 918.0419\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 657.8937 - val_loss: 910.3367\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 637.1697 - val_loss: 902.9385\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 616.9679 - val_loss: 895.8406\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 597.2795 - val_loss: 889.0371\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 578.0955 - val_loss: 882.5217\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 559.4078 - val_loss: 876.2881\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 541.2067 - val_loss: 870.3305\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 523.4842 - val_loss: 864.6424\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 506.2315 - val_loss: 859.2182\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 489.4404 - val_loss: 854.0518\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 473.1025 - val_loss: 849.1372\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 457.2093 - val_loss: 844.4688\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 441.7525 - val_loss: 840.0405\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 426.7242 - val_loss: 835.8470\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 412.1165 - val_loss: 831.8823\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 397.9213 - val_loss: 828.1409\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 384.1307 - val_loss: 824.6173\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 370.7370 - val_loss: 821.3058\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 357.7323 - val_loss: 818.2012\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 345.1087 - val_loss: 815.2979\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 332.8589 - val_loss: 812.5903\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 320.9752 - val_loss: 810.0735\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 309.4500 - val_loss: 807.7419\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 298.2763 - val_loss: 805.5906\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 287.4465 - val_loss: 803.6143\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 276.9532 - val_loss: 801.8079\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 266.7896 - val_loss: 800.1661\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 256.9483 - val_loss: 798.6842\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 247.4222 - val_loss: 797.3570\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 238.2043 - val_loss: 796.1798\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 229.2879 - val_loss: 795.1477\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 220.6659 - val_loss: 794.2558\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 212.3316 - val_loss: 793.4995\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 204.2783 - val_loss: 792.8738\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 196.4993 - val_loss: 792.3745\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 188.9882 - val_loss: 791.9966\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 181.7384 - val_loss: 791.7360\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 174.7432 - val_loss: 791.5880\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 167.9965 - val_loss: 791.5480\n",
      "Epoch 115/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 161.4921 - val_loss: 791.6121\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 155.2236 - val_loss: 791.7757\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 149.1850 - val_loss: 792.0347\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 143.3702 - val_loss: 792.3850\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 137.7735 - val_loss: 792.8223\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 132.3885 - val_loss: 793.3428\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 127.2097 - val_loss: 793.9424\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 122.2313 - val_loss: 794.6173\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 117.4477 - val_loss: 795.3637\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 112.8532 - val_loss: 796.1776\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 108.4426 - val_loss: 797.0556\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 104.2100 - val_loss: 797.9938\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 100.1506 - val_loss: 798.9890\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 96.2588 - val_loss: 800.0373\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 92.5296 - val_loss: 801.1356\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 88.9578 - val_loss: 802.2805\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 85.5385 - val_loss: 803.4686\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 82.2670 - val_loss: 804.6970\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 79.1383 - val_loss: 805.9622\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 76.1477 - val_loss: 807.2617\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 73.2905 - val_loss: 808.5920\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 70.5622 - val_loss: 809.9504\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 67.9585 - val_loss: 811.3342\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 65.4749 - val_loss: 812.7405\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 63.1070 - val_loss: 814.1667\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 60.8510 - val_loss: 815.6104\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 58.7025 - val_loss: 817.0692\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 56.6577 - val_loss: 818.5400\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 54.7126 - val_loss: 820.0211\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 52.8634 - val_loss: 821.5103\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 51.1063 - val_loss: 823.0048\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 49.4379 - val_loss: 824.5033\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 47.8545 - val_loss: 826.0031\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 46.3527 - val_loss: 827.5024\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44.9291 - val_loss: 828.9998\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43.5804 - val_loss: 830.4933\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42.3035 - val_loss: 831.9809\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41.0954 - val_loss: 833.4611\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 39.9531 - val_loss: 834.9325\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 38.8736 - val_loss: 836.3935\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 37.8541 - val_loss: 837.8429\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 36.8920 - val_loss: 839.2788\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 35.9846 - val_loss: 840.7006\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 35.1292 - val_loss: 842.1068\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 34.3236 - val_loss: 843.4964\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 33.5651 - val_loss: 844.8683\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 32.8517 - val_loss: 846.2216\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 32.1811 - val_loss: 847.5553\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 31.5510 - val_loss: 848.8688\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 30.9595 - val_loss: 850.1611\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 30.4045 - val_loss: 851.4316\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 29.8843 - val_loss: 852.6793\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 29.3969 - val_loss: 853.9042\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 28.9405 - val_loss: 855.1057\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 28.5135 - val_loss: 856.2828\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 28.1144 - val_loss: 857.4356\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 27.7415 - val_loss: 858.5637\n",
      "Epoch 172/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 27.3933 - val_loss: 859.6667\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 27.0684 - val_loss: 860.7444\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 26.7655 - val_loss: 861.7968\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 26.4833 - val_loss: 862.8232\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 26.2206 - val_loss: 863.8240\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 25.9762 - val_loss: 864.7993\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 25.7490 - val_loss: 865.7487\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 25.5378 - val_loss: 866.6720\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 25.3418 - val_loss: 867.5698\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 25.1600 - val_loss: 868.4420\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 24.9914 - val_loss: 869.2889\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 24.8352 - val_loss: 870.1104\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 24.6906 - val_loss: 870.9069\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 24.5568 - val_loss: 871.6783\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 24.4331 - val_loss: 872.4253\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 24.3188 - val_loss: 873.1483\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 24.2133 - val_loss: 873.8472\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 24.1159 - val_loss: 874.5227\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 24.0261 - val_loss: 875.1747\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.9433 - val_loss: 875.8041\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.8671 - val_loss: 876.4109\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.7970 - val_loss: 876.9955\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.7325 - val_loss: 877.5586\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.6732 - val_loss: 878.1006\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.6187 - val_loss: 878.6218\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.5688 - val_loss: 879.1226\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.5229 - val_loss: 879.6038\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.4808 - val_loss: 880.0659\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.4422 - val_loss: 880.5089\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.4069 - val_loss: 880.9335\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.3746 - val_loss: 881.3403\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 23.3450 - val_loss: 881.7296\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 23.3180 - val_loss: 882.1024\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.2933 - val_loss: 882.4584\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.2707 - val_loss: 882.7988\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.2501 - val_loss: 883.1237\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.2313 - val_loss: 883.4335\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.2141 - val_loss: 883.7291\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1985 - val_loss: 884.0107\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1842 - val_loss: 884.2791\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1713 - val_loss: 884.5343\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1595 - val_loss: 884.7770\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1487 - val_loss: 885.0078\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1390 - val_loss: 885.2269\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1301 - val_loss: 885.4349\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1221 - val_loss: 885.6323\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1148 - val_loss: 885.8192\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1081 - val_loss: 885.9963\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1021 - val_loss: 886.1639\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 23.0967 - val_loss: 886.3223\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 23.0918 - val_loss: 886.4720\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 23.0874 - val_loss: 886.6133\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0835 - val_loss: 886.7468\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 23.0799 - val_loss: 886.8727\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0766 - val_loss: 886.9915\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 23.0738 - val_loss: 887.1031\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.0712 - val_loss: 887.2081\n",
      "Epoch 229/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.0689 - val_loss: 887.3070\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.0669 - val_loss: 887.4001\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 23.0651 - val_loss: 887.4871\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0635 - val_loss: 887.5690\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0621 - val_loss: 887.6454\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0609 - val_loss: 887.7172\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0599 - val_loss: 887.7844\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0590 - val_loss: 887.8470\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0583 - val_loss: 887.9056\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0576 - val_loss: 887.9604\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0571 - val_loss: 888.0114\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0567 - val_loss: 888.0588\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0565 - val_loss: 888.1032\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0562 - val_loss: 888.1442\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0562 - val_loss: 888.1827\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0561 - val_loss: 888.2183\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0562 - val_loss: 888.2510\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0563 - val_loss: 888.2814\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0565 - val_loss: 888.3098\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0567 - val_loss: 888.3355\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0570 - val_loss: 888.3593\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0573 - val_loss: 888.3815\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0578 - val_loss: 888.4020\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0581 - val_loss: 888.4203\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 23.0586 - val_loss: 888.4373\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 23.0591 - val_loss: 888.4529\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.0597 - val_loss: 888.4673\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.0602 - val_loss: 888.4803\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.0608 - val_loss: 888.4921\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.0614 - val_loss: 888.5029\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 23.0621 - val_loss: 888.5128\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.0627 - val_loss: 888.5216\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.0634 - val_loss: 888.5297\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.0641 - val_loss: 888.5369\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0648 - val_loss: 888.5434\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0655 - val_loss: 888.5490\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0663 - val_loss: 888.5541\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0670 - val_loss: 888.5587\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.0678 - val_loss: 888.5622\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.0686 - val_loss: 888.5656\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0694 - val_loss: 888.5685\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.0702 - val_loss: 888.5707\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.0710 - val_loss: 888.5728\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.0718 - val_loss: 888.5744\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0727 - val_loss: 888.5757\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 23.0734 - val_loss: 888.5765\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0743 - val_loss: 888.5771\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0751 - val_loss: 888.5776\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0760 - val_loss: 888.5779\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.0768 - val_loss: 888.5778\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.0776 - val_loss: 888.5778\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.0784 - val_loss: 888.5776\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0793 - val_loss: 888.5770\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.0801 - val_loss: 888.5764\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0809 - val_loss: 888.5754\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0818 - val_loss: 888.5743\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0826 - val_loss: 888.5730\n",
      "Epoch 286/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0835 - val_loss: 888.5719\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 23.0843 - val_loss: 888.5703\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 23.0851 - val_loss: 888.5692\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.0859 - val_loss: 888.5673\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 23.0868 - val_loss: 888.5662\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0876 - val_loss: 888.5641\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0884 - val_loss: 888.5628\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.0892 - val_loss: 888.5611\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 23.0901 - val_loss: 888.5596\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0908 - val_loss: 888.5580\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0916 - val_loss: 888.5560\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0924 - val_loss: 888.5546\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 23.0932 - val_loss: 888.5529\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0940 - val_loss: 888.5508\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0948 - val_loss: 888.5493\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0956 - val_loss: 888.5474\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0963 - val_loss: 888.5457\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0971 - val_loss: 888.5438\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.0978 - val_loss: 888.5419\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.0986 - val_loss: 888.5398\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.0993 - val_loss: 888.5379\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1001 - val_loss: 888.5360\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1008 - val_loss: 888.5344\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1015 - val_loss: 888.5326\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1022 - val_loss: 888.5304\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1029 - val_loss: 888.5285\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1036 - val_loss: 888.5267\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1044 - val_loss: 888.5247\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1051 - val_loss: 888.5229\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1057 - val_loss: 888.5212\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1064 - val_loss: 888.5194\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1071 - val_loss: 888.5177\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1077 - val_loss: 888.5159\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1084 - val_loss: 888.5141\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1091 - val_loss: 888.5121\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1097 - val_loss: 888.5109\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1104 - val_loss: 888.5091\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1110 - val_loss: 888.5075\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 23.1116 - val_loss: 888.5058\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1122 - val_loss: 888.5040\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1128 - val_loss: 888.5024\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1134 - val_loss: 888.5009\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1140 - val_loss: 888.4991\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1146 - val_loss: 888.4976\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1152 - val_loss: 888.4959\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1158 - val_loss: 888.4943\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1164 - val_loss: 888.4927\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 23.1169 - val_loss: 888.4916\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 23.1175 - val_loss: 888.4901\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1180 - val_loss: 888.4886\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1185 - val_loss: 888.4871\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1191 - val_loss: 888.4857\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1196 - val_loss: 888.4842\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1201 - val_loss: 888.4830\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1206 - val_loss: 888.4815\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1212 - val_loss: 888.4802\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1216 - val_loss: 888.4789\n",
      "Epoch 343/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1221 - val_loss: 888.4777\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1226 - val_loss: 888.4763\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1231 - val_loss: 888.4749\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 23.1236 - val_loss: 888.4738\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1240 - val_loss: 888.4725\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1245 - val_loss: 888.4711\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1249 - val_loss: 888.4699\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1254 - val_loss: 888.4688\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1258 - val_loss: 888.4673\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1263 - val_loss: 888.4662\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1267 - val_loss: 888.4650\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1271 - val_loss: 888.4642\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1276 - val_loss: 888.4631\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1279 - val_loss: 888.4620\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1283 - val_loss: 888.4610\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1287 - val_loss: 888.4600\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1291 - val_loss: 888.4591\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1295 - val_loss: 888.4576\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1299 - val_loss: 888.4566\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1302 - val_loss: 888.4557\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1306 - val_loss: 888.4545\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1310 - val_loss: 888.4537\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1313 - val_loss: 888.4528\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1317 - val_loss: 888.4518\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1320 - val_loss: 888.4509\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 23.1323 - val_loss: 888.4500\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1327 - val_loss: 888.4492\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1330 - val_loss: 888.4483\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 23.1333 - val_loss: 888.4474\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1336 - val_loss: 888.4467\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1339 - val_loss: 888.4456\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1343 - val_loss: 888.4448\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1346 - val_loss: 888.4442\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1349 - val_loss: 888.4433\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1351 - val_loss: 888.4427\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1354 - val_loss: 888.4418\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1357 - val_loss: 888.4410\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1360 - val_loss: 888.4404\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1363 - val_loss: 888.4396\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1365 - val_loss: 888.4387\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1368 - val_loss: 888.4382\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1370 - val_loss: 888.4377\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1372 - val_loss: 888.4368\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 23.1375 - val_loss: 888.4362\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1378 - val_loss: 888.4356\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1380 - val_loss: 888.4351\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1382 - val_loss: 888.4344\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1385 - val_loss: 888.4335\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1387 - val_loss: 888.4330\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1389 - val_loss: 888.4325\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1391 - val_loss: 888.4316\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1394 - val_loss: 888.4312\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1396 - val_loss: 888.4305\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1397 - val_loss: 888.4299\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1400 - val_loss: 888.4296\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1402 - val_loss: 888.4291\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1404 - val_loss: 888.4285\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1406 - val_loss: 888.4279\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1408 - val_loss: 888.4275\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1409 - val_loss: 888.4269\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1411 - val_loss: 888.4265\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1413 - val_loss: 888.4261\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1415 - val_loss: 888.4257\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1416 - val_loss: 888.4252\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1418 - val_loss: 888.4247\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 23.1420 - val_loss: 888.4241\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1421 - val_loss: 888.4234\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1423 - val_loss: 888.4230\n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1425 - val_loss: 888.4229\n",
      "Epoch 412/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1426 - val_loss: 888.4225\n",
      "Epoch 413/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1428 - val_loss: 888.4220\n",
      "Epoch 414/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1429 - val_loss: 888.4216\n",
      "Epoch 415/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1430 - val_loss: 888.4211\n",
      "Epoch 416/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1432 - val_loss: 888.4207\n",
      "Epoch 417/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1434 - val_loss: 888.4203\n",
      "Epoch 418/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1435 - val_loss: 888.4201\n",
      "Epoch 419/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1436 - val_loss: 888.4196\n",
      "Epoch 420/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1437 - val_loss: 888.4189\n",
      "Epoch 421/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1439 - val_loss: 888.4186\n",
      "Epoch 422/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1441 - val_loss: 888.4186\n",
      "Epoch 423/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1441 - val_loss: 888.4185\n",
      "Epoch 424/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1442 - val_loss: 888.4181\n",
      "Epoch 425/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1444 - val_loss: 888.4179\n",
      "Epoch 426/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1445 - val_loss: 888.4175\n",
      "Epoch 427/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1446 - val_loss: 888.4174\n",
      "Epoch 428/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1447 - val_loss: 888.4172\n",
      "Epoch 429/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1448 - val_loss: 888.4169\n",
      "Epoch 430/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 23.1449 - val_loss: 888.4163\n",
      "Epoch 431/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1450 - val_loss: 888.4159\n",
      "Epoch 432/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1452 - val_loss: 888.4159\n",
      "Epoch 433/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1452 - val_loss: 888.4157\n",
      "Epoch 434/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1453 - val_loss: 888.4154\n",
      "Epoch 435/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1454 - val_loss: 888.4150\n",
      "Epoch 436/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1455 - val_loss: 888.4149\n",
      "Epoch 437/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1456 - val_loss: 888.4150\n",
      "Epoch 438/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1457 - val_loss: 888.4146\n",
      "Epoch 439/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1458 - val_loss: 888.4142\n",
      "Epoch 440/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1459 - val_loss: 888.4138\n",
      "Epoch 441/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1459 - val_loss: 888.4135\n",
      "Epoch 442/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1460 - val_loss: 888.4131\n",
      "Epoch 443/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1461 - val_loss: 888.4128\n",
      "Epoch 444/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1462 - val_loss: 888.4127\n",
      "Epoch 445/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1463 - val_loss: 888.4125\n",
      "Epoch 446/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1464 - val_loss: 888.4125\n",
      "Epoch 447/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1464 - val_loss: 888.4120\n",
      "Epoch 448/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1465 - val_loss: 888.4119\n",
      "Epoch 449/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1466 - val_loss: 888.4116\n",
      "Epoch 450/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1467 - val_loss: 888.4116\n",
      "Epoch 451/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1468 - val_loss: 888.4113\n",
      "Epoch 452/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1468 - val_loss: 888.4111\n",
      "Epoch 453/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1469 - val_loss: 888.4111\n",
      "Epoch 454/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 23.1470 - val_loss: 888.4110\n",
      "Epoch 455/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1471 - val_loss: 888.4109\n",
      "Epoch 456/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1471 - val_loss: 888.4108\n",
      "Epoch 457/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1472 - val_loss: 888.4105\n",
      "Epoch 458/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1472 - val_loss: 888.4103\n",
      "Epoch 459/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1473 - val_loss: 888.4102\n",
      "Epoch 460/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1473 - val_loss: 888.4100\n",
      "Epoch 461/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1474 - val_loss: 888.4095\n",
      "Epoch 462/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1475 - val_loss: 888.4095\n",
      "Epoch 463/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1475 - val_loss: 888.4095\n",
      "Epoch 464/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1476 - val_loss: 888.4092\n",
      "Epoch 465/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1476 - val_loss: 888.4091\n",
      "Epoch 466/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1476 - val_loss: 888.4088\n",
      "Epoch 467/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1477 - val_loss: 888.4087\n",
      "Epoch 468/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1478 - val_loss: 888.4087\n",
      "Epoch 469/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1478 - val_loss: 888.4087\n",
      "Epoch 470/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1479 - val_loss: 888.4085\n",
      "Epoch 471/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1479 - val_loss: 888.4085\n",
      "Epoch 472/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1480 - val_loss: 888.4085\n",
      "Epoch 473/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1480 - val_loss: 888.4084\n",
      "Epoch 474/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1481 - val_loss: 888.4084\n",
      "Epoch 475/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1481 - val_loss: 888.4085\n",
      "Epoch 476/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1481 - val_loss: 888.4083\n",
      "Epoch 477/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 23.1482 - val_loss: 888.4081\n",
      "Epoch 478/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1483 - val_loss: 888.4083\n",
      "Epoch 479/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1483 - val_loss: 888.4081\n",
      "Epoch 480/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1483 - val_loss: 888.4080\n",
      "Epoch 481/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1483 - val_loss: 888.4078\n",
      "Epoch 482/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1484 - val_loss: 888.4077\n",
      "Epoch 483/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1484 - val_loss: 888.4078\n",
      "Epoch 484/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1484 - val_loss: 888.4076\n",
      "Epoch 485/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.1485 - val_loss: 888.4076\n",
      "Epoch 486/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1485 - val_loss: 888.4074\n",
      "Epoch 487/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1486 - val_loss: 888.4072\n",
      "Epoch 488/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1486 - val_loss: 888.4071\n",
      "Epoch 489/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1486 - val_loss: 888.4070\n",
      "Epoch 490/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1486 - val_loss: 888.4068\n",
      "Epoch 491/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1487 - val_loss: 888.4067\n",
      "Epoch 492/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1487 - val_loss: 888.4066\n",
      "Epoch 493/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1488 - val_loss: 888.4067\n",
      "Epoch 494/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1488 - val_loss: 888.4067\n",
      "Epoch 495/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1488 - val_loss: 888.4067\n",
      "Epoch 496/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1488 - val_loss: 888.4066\n",
      "Epoch 497/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1489 - val_loss: 888.4064\n",
      "Epoch 498/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 23.1489 - val_loss: 888.4064\n",
      "Epoch 499/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 23.1490 - val_loss: 888.4064\n",
      "Epoch 500/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 23.1489 - val_loss: 888.4062\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 460ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.23367647e+01, 6.23283613e+01, 6.23199580e+01, 6.23115546e+01,\n",
       "        6.23031513e+01, 6.22632353e+01, 6.22044118e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.62436104e-01, 2.44988350e-02, 5.97582459e-01,\n",
       "        1.18719362e-01, 6.25283613e+01, 6.24527311e+01, 6.23974556e+01,\n",
       "        6.23890523e+01, 6.23806489e+01, 6.23722456e+01, 6.23638422e+01,\n",
       "        6.23554388e+01, 6.23470355e+01, 6.23386321e+01, 6.23302288e+01,\n",
       "        6.23218254e+01, 6.23134220e+01, 6.23050187e+01, 6.22763072e+01,\n",
       "        6.22174837e+01, 6.21586601e+01, 6.20998366e+01, 6.20410131e+01,\n",
       "        6.19821895e+01, 6.19233660e+01, 6.18645425e+01, 6.18057189e+01,\n",
       "        6.17468954e+01, 6.16880719e+01, 6.16292484e+01, 6.15856349e+01,\n",
       "        0.00000000e+00, 1.05700340e-01, 7.49445000e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.16387020e-01, 0.00000000e+00, 6.23152895e+01,\n",
       "        6.23068861e+01, 6.22893791e+01, 6.22305556e+01, 6.21717320e+01,\n",
       "        6.21129085e+01, 6.20540850e+01, 6.19952614e+01, 6.19364379e+01,\n",
       "        6.18776144e+01, 6.18187908e+01, 6.17599673e+01, 6.17011438e+01,\n",
       "        6.16423203e+01, 6.15919841e+01, 6.39678105e+01, 6.37913399e+01,\n",
       "        6.36148693e+01, 6.34383987e+01, 6.32510504e+01, 6.30241597e+01,\n",
       "        6.27972689e+01, 6.25703782e+01, 6.23937208e+01, 0.00000000e+00,\n",
       "        8.05609170e-01, 6.04137650e+01, 1.03494644e-01, 0.00000000e+00,\n",
       "        4.51493770e-01, 6.49816620e-02, 6.82190061e-01, 7.14040160e-01,\n",
       "        5.22042122e+01, 4.16456401e-01, 7.05238283e-01, 1.86739072e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.10181570e-01, 7.57524252e-01, 2.27574646e-01,\n",
       "        4.14854854e-01, 0.00000000e+00, 1.81573749e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.91437149e-01, 3.23886007e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55.925     , 55.90912698, 55.89325397, 55.87738095, 55.86150794,\n",
       "       55.84563492, 55.8297619 , 55.81388889, 55.79801587, 55.78214286,\n",
       "       55.76626984, 55.75039683, 55.73452381, 55.71865079, 55.70277778,\n",
       "       55.68690476, 55.67103175, 55.65515873, 55.63928571, 55.6234127 ,\n",
       "       55.60753968, 55.59166667, 55.57579365, 55.55992063, 55.54404762,\n",
       "       55.5281746 , 55.51230159, 55.49642857, 55.48055556, 55.46468254,\n",
       "       55.44880952, 55.43293651, 55.41706349, 55.40119048, 55.39191091,\n",
       "       55.38316595, 55.37442099, 55.36567603, 55.35693107, 55.3481861 ,\n",
       "       55.33944114, 55.33069618, 55.32195122, 55.31320626, 55.3044613 ,\n",
       "       55.29571634, 55.28697137, 55.27822641, 55.26948145, 55.26073649,\n",
       "       55.25199153, 55.24324657, 55.23450161, 55.22575664, 55.21701168,\n",
       "       55.20826672, 55.19952176, 55.1907768 , 55.18203184, 55.17328688,\n",
       "       55.16454191, 55.15579695, 55.14705199, 55.13830703, 55.12956207,\n",
       "       55.12081711, 55.11207215, 55.10332718, 55.09458222, 55.08583726,\n",
       "       55.0770923 , 55.06834734, 55.05960238, 55.05085742, 55.04211245,\n",
       "       55.03336749, 55.02462253, 55.01587757, 55.00713261, 54.99838765,\n",
       "       54.98964269, 54.98089772, 54.97215276, 54.9634078 , 54.95466284,\n",
       "       54.94591788, 54.93717292, 54.92842796, 54.919683  , 54.91093803,\n",
       "       54.90219307, 54.89344811, 54.88470315, 54.87595819, 54.86721323,\n",
       "       54.85846827, 54.8497233 , 54.84097834, 54.83223338, 54.82348842])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.126151122939135\n",
      "26.028911745305308\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
