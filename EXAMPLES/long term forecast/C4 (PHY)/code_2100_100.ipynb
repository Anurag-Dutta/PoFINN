{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "2195    58.738471\n",
       "2196    58.726173\n",
       "2197    58.713876\n",
       "2198    58.701578\n",
       "2199    58.689281\n",
       "Name: C4, Length: 2200, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_2100_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "2095     0.205797\n",
       "2096     0.000000\n",
       "2097     1.284090\n",
       "2098     0.000000\n",
       "2099     0.000000\n",
       "Name: C4, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2100)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 1, 251) (1650, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 3s 30ms/step - loss: 5390.6738 - val_loss: 3593.1726\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5320.3857 - val_loss: 3559.1924\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5242.1880 - val_loss: 3502.5955\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5156.2432 - val_loss: 3465.5542\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5091.0195 - val_loss: 3424.4397\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5014.0801 - val_loss: 3385.8879\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4947.2012 - val_loss: 3348.9609\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4881.9033 - val_loss: 3313.0435\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4817.6855 - val_loss: 3276.1243\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4749.8018 - val_loss: 3237.3406\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4666.0469 - val_loss: 3190.3230\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4592.0000 - val_loss: 3151.4849\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4522.9990 - val_loss: 3114.0149\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4456.0386 - val_loss: 3077.5671\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4390.6279 - val_loss: 3041.9387\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4326.4839 - val_loss: 3007.0115\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4263.4409 - val_loss: 2972.7100\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4201.3867 - val_loss: 2938.9817\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4140.2471 - val_loss: 2905.7886\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4079.9622 - val_loss: 2873.1018\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4020.4912 - val_loss: 2840.8979\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3961.7974 - val_loss: 2809.1584\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3903.8516 - val_loss: 2777.8672\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3846.6318 - val_loss: 2747.0117\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3790.1174 - val_loss: 2716.5798\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3734.2900 - val_loss: 2686.5620\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3679.1345 - val_loss: 2656.9490\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3624.6367 - val_loss: 2627.7327\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3570.7849 - val_loss: 2598.9060\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3517.5674 - val_loss: 2570.4624\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3464.9739 - val_loss: 2542.3958\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3412.9951 - val_loss: 2514.7000\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3361.6221 - val_loss: 2487.3704\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3310.8459 - val_loss: 2460.4009\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3260.6592 - val_loss: 2433.7871\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3211.0544 - val_loss: 2407.5249\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3162.0247 - val_loss: 2381.6099\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3113.5627 - val_loss: 2356.0378\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3065.6628 - val_loss: 2330.8047\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3018.3191 - val_loss: 2305.9067\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2971.5242 - val_loss: 2281.3403\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2925.2739 - val_loss: 2257.1016\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2879.5618 - val_loss: 2233.1877\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2834.3828 - val_loss: 2209.5950\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2789.7310 - val_loss: 2186.3196\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2745.6021 - val_loss: 2163.3591\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2701.9905 - val_loss: 2140.7104\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2658.8914 - val_loss: 2118.3701\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2616.3010 - val_loss: 2096.3352\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2574.2134 - val_loss: 2074.6028\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2532.6248 - val_loss: 2053.1702\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2491.5308 - val_loss: 2032.0344\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2450.9255 - val_loss: 2011.1927\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2410.8066 - val_loss: 1990.6428\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2371.1694 - val_loss: 1970.3816\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 2332.0088 - val_loss: 1950.4062\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2293.3206 - val_loss: 1930.7144\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2255.1018 - val_loss: 1911.3035\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2217.3477 - val_loss: 1892.1710\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2180.0547 - val_loss: 1873.3142\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2143.2192 - val_loss: 1854.7311\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2106.8364 - val_loss: 1836.4189\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2070.9036 - val_loss: 1818.3750\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2035.4158 - val_loss: 1800.5975\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2000.3698 - val_loss: 1783.0839\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1965.7625 - val_loss: 1765.8320\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1931.5902 - val_loss: 1748.8389\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1897.8485 - val_loss: 1732.1024\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1864.5344 - val_loss: 1715.6208\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1831.6436 - val_loss: 1699.3917\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1799.1741 - val_loss: 1683.4124\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1767.1210 - val_loss: 1667.6809\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1735.4822 - val_loss: 1652.1953\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1704.2532 - val_loss: 1636.9532\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1673.4309 - val_loss: 1621.9523\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1643.0121 - val_loss: 1607.1906\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1612.9930 - val_loss: 1592.6659\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1583.3710 - val_loss: 1578.3760\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1554.1421 - val_loss: 1564.3191\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1525.3038 - val_loss: 1550.4930\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1496.8528 - val_loss: 1536.8955\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1468.7859 - val_loss: 1523.5248\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1441.0992 - val_loss: 1510.3784\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1413.7903 - val_loss: 1497.4543\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1386.8558 - val_loss: 1484.7510\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1360.2925 - val_loss: 1472.2662\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1334.0973 - val_loss: 1459.9977\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1308.2671 - val_loss: 1447.9437\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1282.7992 - val_loss: 1436.1019\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1257.6897 - val_loss: 1424.4711\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1232.9368 - val_loss: 1413.0483\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1208.5370 - val_loss: 1401.8325\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1184.4867 - val_loss: 1390.8212\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1160.7836 - val_loss: 1380.0125\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1137.4248 - val_loss: 1369.4047\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1114.4072 - val_loss: 1358.9956\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1091.7275 - val_loss: 1348.7834\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1069.3828 - val_loss: 1338.7662\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1047.3706 - val_loss: 1328.9423\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1025.6882 - val_loss: 1319.3093\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1004.3323 - val_loss: 1309.8657\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 983.2994 - val_loss: 1300.6095\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 962.5881 - val_loss: 1291.5391\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 942.1940 - val_loss: 1282.6517\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 922.1155 - val_loss: 1273.9467\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 902.3495 - val_loss: 1265.4216\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 882.8930 - val_loss: 1257.0746\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 863.7430 - val_loss: 1248.9036\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 844.8968 - val_loss: 1240.9071\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 826.3520 - val_loss: 1233.0834\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 808.1055 - val_loss: 1225.4301\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 790.1545 - val_loss: 1217.9457\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 772.4963 - val_loss: 1210.6284\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 755.1281 - val_loss: 1203.4764\n",
      "Epoch 115/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 738.0474 - val_loss: 1196.4878\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 721.2512 - val_loss: 1189.6609\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 704.7371 - val_loss: 1182.9935\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 688.5017 - val_loss: 1176.4841\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 672.5429 - val_loss: 1170.1311\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 656.8578 - val_loss: 1163.9324\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 641.4436 - val_loss: 1157.8859\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 626.2980 - val_loss: 1151.9905\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 611.4182 - val_loss: 1146.2440\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 596.8013 - val_loss: 1140.6448\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 582.4446 - val_loss: 1135.1909\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 568.3457 - val_loss: 1129.8806\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 554.5016 - val_loss: 1124.7122\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 540.9101 - val_loss: 1119.6836\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 527.5680 - val_loss: 1114.7936\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 514.4730 - val_loss: 1110.0398\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 501.6224 - val_loss: 1105.4208\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 489.0135 - val_loss: 1100.9346\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 476.6436 - val_loss: 1096.5796\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 464.5103 - val_loss: 1092.3539\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 452.6107 - val_loss: 1088.2557\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 440.9422 - val_loss: 1084.2836\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 429.5023 - val_loss: 1080.4353\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 418.2881 - val_loss: 1076.7094\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 407.2974 - val_loss: 1073.1040\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 396.5275 - val_loss: 1069.6172\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 385.9759 - val_loss: 1066.2477\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 375.6397 - val_loss: 1062.9934\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 365.5166 - val_loss: 1059.8525\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 355.6036 - val_loss: 1056.8234\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 345.8985 - val_loss: 1053.9043\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 336.3986 - val_loss: 1051.0935\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 327.1012 - val_loss: 1048.3892\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 318.0040 - val_loss: 1045.7896\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 309.1043 - val_loss: 1043.2931\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 300.3997 - val_loss: 1040.8981\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 291.8874 - val_loss: 1038.6024\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 283.5650 - val_loss: 1036.4047\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 275.4299 - val_loss: 1034.3030\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 267.4794 - val_loss: 1032.2958\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 259.7111 - val_loss: 1030.3811\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 252.1223 - val_loss: 1028.5574\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 244.7109 - val_loss: 1026.8229\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 237.4741 - val_loss: 1025.1760\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 230.4092 - val_loss: 1023.6147\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 223.5137 - val_loss: 1022.1377\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 216.7856 - val_loss: 1020.7431\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 210.2222 - val_loss: 1019.4291\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 203.8207 - val_loss: 1018.1942\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 197.5789 - val_loss: 1017.0366\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 191.4943 - val_loss: 1015.9547\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 185.5642 - val_loss: 1014.9466\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 179.7863 - val_loss: 1014.0110\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 174.1583 - val_loss: 1013.1460\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 168.6775 - val_loss: 1012.3500\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 163.3415 - val_loss: 1011.6213\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 158.1479 - val_loss: 1010.9583\n",
      "Epoch 172/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 153.0943 - val_loss: 1010.3593\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 148.1784 - val_loss: 1009.8228\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 143.3975 - val_loss: 1009.3468\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 138.7495 - val_loss: 1008.9303\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 134.2317 - val_loss: 1008.5713\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 129.8423 - val_loss: 1008.2686\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 125.5784 - val_loss: 1008.0198\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 121.4377 - val_loss: 1007.8240\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 117.4181 - val_loss: 1007.6796\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 113.5170 - val_loss: 1007.5848\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 109.7322 - val_loss: 1007.5381\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 106.0616 - val_loss: 1007.5381\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 102.5026 - val_loss: 1007.5831\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 99.0532 - val_loss: 1007.6717\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 95.7109 - val_loss: 1007.8025\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 92.4735 - val_loss: 1007.9737\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 89.3387 - val_loss: 1008.1842\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 86.3045 - val_loss: 1008.4322\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 83.3686 - val_loss: 1008.7165\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 80.5289 - val_loss: 1009.0356\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 77.7833 - val_loss: 1009.3881\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 75.1294 - val_loss: 1009.7725\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 72.5653 - val_loss: 1010.1874\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 70.0888 - val_loss: 1010.6317\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 67.6977 - val_loss: 1011.1037\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 65.3901 - val_loss: 1011.6021\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 63.1638 - val_loss: 1012.1259\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 61.0170 - val_loss: 1012.6735\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 58.9476 - val_loss: 1013.2438\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 56.9535 - val_loss: 1013.8354\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 55.0329 - val_loss: 1014.4471\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 53.1838 - val_loss: 1015.0778\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51.4042 - val_loss: 1015.7260\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49.6923 - val_loss: 1016.3909\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48.0462 - val_loss: 1017.0710\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46.4640 - val_loss: 1017.7655\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 44.9440 - val_loss: 1018.4728\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43.4844 - val_loss: 1019.1921\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42.0835 - val_loss: 1019.9224\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40.7393 - val_loss: 1020.6625\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 39.4504 - val_loss: 1021.4114\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 38.2149 - val_loss: 1022.1683\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 37.0312 - val_loss: 1022.9318\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 35.8977 - val_loss: 1023.7011\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 34.8126 - val_loss: 1024.4757\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 33.7747 - val_loss: 1025.2540\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 32.7823 - val_loss: 1026.0355\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 31.8338 - val_loss: 1026.8192\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.9277 - val_loss: 1027.6044\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0625 - val_loss: 1028.3904\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.2370 - val_loss: 1029.1760\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 28.4496 - val_loss: 1029.9608\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 27.6990 - val_loss: 1030.7439\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 26.9838 - val_loss: 1031.5247\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 26.3028 - val_loss: 1032.3024\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.6546 - val_loss: 1033.0763\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 25.0381 - val_loss: 1033.8461\n",
      "Epoch 229/500\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 24.4521 - val_loss: 1034.6105\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.8952 - val_loss: 1035.3696\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 23.3664 - val_loss: 1036.1227\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 22.8645 - val_loss: 1036.8693\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 22.3884 - val_loss: 1037.6086\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.9370 - val_loss: 1038.3403\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.5094 - val_loss: 1039.0640\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.1046 - val_loss: 1039.7792\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.7214 - val_loss: 1040.4855\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.3590 - val_loss: 1041.1825\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 20.0164 - val_loss: 1041.8701\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 19.6928 - val_loss: 1042.5475\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 19.3873 - val_loss: 1043.2148\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 19.0990 - val_loss: 1043.8718\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8272 - val_loss: 1044.5176\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.5711 - val_loss: 1045.1523\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.3299 - val_loss: 1045.7761\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.1029 - val_loss: 1046.3883\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 17.8893 - val_loss: 1046.9888\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.6886 - val_loss: 1047.5776\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 17.5001 - val_loss: 1048.1547\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.3231 - val_loss: 1048.7196\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.1570 - val_loss: 1049.2722\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.0013 - val_loss: 1049.8127\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.8554 - val_loss: 1050.3409\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 16.7187 - val_loss: 1050.8571\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.5908 - val_loss: 1051.3607\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.4713 - val_loss: 1051.8523\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.3595 - val_loss: 1052.3313\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2551 - val_loss: 1052.7981\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1577 - val_loss: 1053.2526\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.0668 - val_loss: 1053.6952\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.9820 - val_loss: 1054.1256\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.9031 - val_loss: 1054.5439\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.8295 - val_loss: 1054.9504\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.7611 - val_loss: 1055.3448\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.6975 - val_loss: 1055.7278\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.6383 - val_loss: 1056.0991\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.5834 - val_loss: 1056.4591\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.5324 - val_loss: 1056.8077\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.4851 - val_loss: 1057.1451\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 15.4413 - val_loss: 1057.4718\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.4007 - val_loss: 1057.7875\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.3631 - val_loss: 1058.0927\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.3283 - val_loss: 1058.3872\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.2961 - val_loss: 1058.6716\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.2663 - val_loss: 1058.9457\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.2388 - val_loss: 1059.2101\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 15.2134 - val_loss: 1059.4650\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 15.1900 - val_loss: 1059.7106\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 15.1684 - val_loss: 1059.9464\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 15.1485 - val_loss: 1060.1733\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 15.1302 - val_loss: 1060.3916\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.1133 - val_loss: 1060.6014\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.0978 - val_loss: 1060.8029\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 15.0835 - val_loss: 1060.9960\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 15.0703 - val_loss: 1061.1810\n",
      "Epoch 286/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 15.0583 - val_loss: 1061.3588\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 15.0471 - val_loss: 1061.5288\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 15.0370 - val_loss: 1061.6915\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 15.0276 - val_loss: 1061.8475\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 15.0191 - val_loss: 1061.9963\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 15.0112 - val_loss: 1062.1384\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 15.0041 - val_loss: 1062.2744\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9975 - val_loss: 1062.4042\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9914 - val_loss: 1062.5275\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9859 - val_loss: 1062.6455\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9809 - val_loss: 1062.7578\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9763 - val_loss: 1062.8646\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9721 - val_loss: 1062.9663\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9683 - val_loss: 1063.0629\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9648 - val_loss: 1063.1549\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9617 - val_loss: 1063.2421\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9588 - val_loss: 1063.3246\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 14.9562 - val_loss: 1063.4031\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 14.9538 - val_loss: 1063.4777\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9517 - val_loss: 1063.5480\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9498 - val_loss: 1063.6147\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 14.9481 - val_loss: 1063.6780\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9465 - val_loss: 1063.7375\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9451 - val_loss: 1063.7939\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9438 - val_loss: 1063.8469\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9427 - val_loss: 1063.8972\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9417 - val_loss: 1063.9441\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9409 - val_loss: 1063.9888\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9401 - val_loss: 1064.0308\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9394 - val_loss: 1064.0704\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9388 - val_loss: 1064.1073\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9384 - val_loss: 1064.1422\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9380 - val_loss: 1064.1750\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9376 - val_loss: 1064.2057\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9373 - val_loss: 1064.2341\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9371 - val_loss: 1064.2610\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9370 - val_loss: 1064.2865\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9369 - val_loss: 1064.3098\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9368 - val_loss: 1064.3317\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9368 - val_loss: 1064.3523\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9368 - val_loss: 1064.3711\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 14.9369 - val_loss: 1064.3889\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9370 - val_loss: 1064.4054\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9371 - val_loss: 1064.4208\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9373 - val_loss: 1064.4349\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9375 - val_loss: 1064.4485\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9377 - val_loss: 1064.4606\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9380 - val_loss: 1064.4722\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9383 - val_loss: 1064.4824\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9386 - val_loss: 1064.4921\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9389 - val_loss: 1064.5010\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9392 - val_loss: 1064.5090\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9396 - val_loss: 1064.5168\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9399 - val_loss: 1064.5237\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9403 - val_loss: 1064.5299\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 14.9407 - val_loss: 1064.5355\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9411 - val_loss: 1064.5410\n",
      "Epoch 343/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9415 - val_loss: 1064.5458\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9420 - val_loss: 1064.5504\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9424 - val_loss: 1064.5542\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9428 - val_loss: 1064.5576\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9433 - val_loss: 1064.5605\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9437 - val_loss: 1064.5635\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9442 - val_loss: 1064.5659\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 14.9447 - val_loss: 1064.5679\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9452 - val_loss: 1064.5703\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9456 - val_loss: 1064.5720\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9461 - val_loss: 1064.5735\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9466 - val_loss: 1064.5747\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9471 - val_loss: 1064.5759\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9476 - val_loss: 1064.5770\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9481 - val_loss: 1064.5778\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9486 - val_loss: 1064.5786\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9491 - val_loss: 1064.5787\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9496 - val_loss: 1064.5791\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9501 - val_loss: 1064.5791\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9506 - val_loss: 1064.5792\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9511 - val_loss: 1064.5792\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9516 - val_loss: 1064.5793\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9521 - val_loss: 1064.5792\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9526 - val_loss: 1064.5791\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9531 - val_loss: 1064.5787\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9535 - val_loss: 1064.5784\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9541 - val_loss: 1064.5778\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9545 - val_loss: 1064.5773\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9550 - val_loss: 1064.5767\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 14.9555 - val_loss: 1064.5762\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9560 - val_loss: 1064.5757\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9565 - val_loss: 1064.5748\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9570 - val_loss: 1064.5741\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9574 - val_loss: 1064.5732\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9579 - val_loss: 1064.5726\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9584 - val_loss: 1064.5719\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9589 - val_loss: 1064.5710\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9594 - val_loss: 1064.5703\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9598 - val_loss: 1064.5695\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9603 - val_loss: 1064.5686\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9607 - val_loss: 1064.5679\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9612 - val_loss: 1064.5673\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9616 - val_loss: 1064.5662\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9621 - val_loss: 1064.5653\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9625 - val_loss: 1064.5647\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9630 - val_loss: 1064.5638\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9634 - val_loss: 1064.5631\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9638 - val_loss: 1064.5619\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9643 - val_loss: 1064.5609\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9647 - val_loss: 1064.5602\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 14.9651 - val_loss: 1064.5592\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9655 - val_loss: 1064.5585\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9659 - val_loss: 1064.5575\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9663 - val_loss: 1064.5564\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9667 - val_loss: 1064.5555\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 14.9671 - val_loss: 1064.5547\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9675 - val_loss: 1064.5537\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9679 - val_loss: 1064.5527\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9683 - val_loss: 1064.5521\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9687 - val_loss: 1064.5513\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9691 - val_loss: 1064.5504\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9694 - val_loss: 1064.5498\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9698 - val_loss: 1064.5490\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9702 - val_loss: 1064.5482\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9705 - val_loss: 1064.5475\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9709 - val_loss: 1064.5468\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9712 - val_loss: 1064.5461\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9716 - val_loss: 1064.5453\n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9719 - val_loss: 1064.5447\n",
      "Epoch 412/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9722 - val_loss: 1064.5439\n",
      "Epoch 413/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9726 - val_loss: 1064.5432\n",
      "Epoch 414/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 14.9729 - val_loss: 1064.5425\n",
      "Epoch 415/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9732 - val_loss: 1064.5419\n",
      "Epoch 416/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9736 - val_loss: 1064.5411\n",
      "Epoch 417/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9739 - val_loss: 1064.5405\n",
      "Epoch 418/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9742 - val_loss: 1064.5396\n",
      "Epoch 419/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9745 - val_loss: 1064.5391\n",
      "Epoch 420/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9748 - val_loss: 1064.5383\n",
      "Epoch 421/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9751 - val_loss: 1064.5377\n",
      "Epoch 422/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9754 - val_loss: 1064.5370\n",
      "Epoch 423/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9757 - val_loss: 1064.5365\n",
      "Epoch 424/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9760 - val_loss: 1064.5359\n",
      "Epoch 425/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9762 - val_loss: 1064.5353\n",
      "Epoch 426/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9765 - val_loss: 1064.5345\n",
      "Epoch 427/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9768 - val_loss: 1064.5339\n",
      "Epoch 428/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9771 - val_loss: 1064.5333\n",
      "Epoch 429/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9773 - val_loss: 1064.5327\n",
      "Epoch 430/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9776 - val_loss: 1064.5322\n",
      "Epoch 431/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9779 - val_loss: 1064.5316\n",
      "Epoch 432/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9781 - val_loss: 1064.5310\n",
      "Epoch 433/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9784 - val_loss: 1064.5309\n",
      "Epoch 434/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9786 - val_loss: 1064.5300\n",
      "Epoch 435/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 14.9789 - val_loss: 1064.5295\n",
      "Epoch 436/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9791 - val_loss: 1064.5289\n",
      "Epoch 437/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9793 - val_loss: 1064.5286\n",
      "Epoch 438/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9796 - val_loss: 1064.5280\n",
      "Epoch 439/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9798 - val_loss: 1064.5273\n",
      "Epoch 440/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9800 - val_loss: 1064.5267\n",
      "Epoch 441/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9802 - val_loss: 1064.5262\n",
      "Epoch 442/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9805 - val_loss: 1064.5260\n",
      "Epoch 443/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9807 - val_loss: 1064.5254\n",
      "Epoch 444/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9809 - val_loss: 1064.5251\n",
      "Epoch 445/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9811 - val_loss: 1064.5245\n",
      "Epoch 446/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9813 - val_loss: 1064.5242\n",
      "Epoch 447/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9815 - val_loss: 1064.5236\n",
      "Epoch 448/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9817 - val_loss: 1064.5233\n",
      "Epoch 449/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9819 - val_loss: 1064.5226\n",
      "Epoch 450/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9821 - val_loss: 1064.5225\n",
      "Epoch 451/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9823 - val_loss: 1064.5221\n",
      "Epoch 452/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9825 - val_loss: 1064.5216\n",
      "Epoch 453/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9826 - val_loss: 1064.5211\n",
      "Epoch 454/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9828 - val_loss: 1064.5209\n",
      "Epoch 455/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 14.9830 - val_loss: 1064.5204\n",
      "Epoch 456/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9831 - val_loss: 1064.5200\n",
      "Epoch 457/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9833 - val_loss: 1064.5194\n",
      "Epoch 458/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9835 - val_loss: 1064.5193\n",
      "Epoch 459/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9837 - val_loss: 1064.5188\n",
      "Epoch 460/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9838 - val_loss: 1064.5183\n",
      "Epoch 461/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9840 - val_loss: 1064.5181\n",
      "Epoch 462/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9841 - val_loss: 1064.5177\n",
      "Epoch 463/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9843 - val_loss: 1064.5173\n",
      "Epoch 464/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9845 - val_loss: 1064.5171\n",
      "Epoch 465/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9846 - val_loss: 1064.5168\n",
      "Epoch 466/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9847 - val_loss: 1064.5166\n",
      "Epoch 467/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9849 - val_loss: 1064.5162\n",
      "Epoch 468/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9850 - val_loss: 1064.5159\n",
      "Epoch 469/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9851 - val_loss: 1064.5155\n",
      "Epoch 470/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9853 - val_loss: 1064.5153\n",
      "Epoch 471/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9854 - val_loss: 1064.5148\n",
      "Epoch 472/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9856 - val_loss: 1064.5145\n",
      "Epoch 473/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9857 - val_loss: 1064.5143\n",
      "Epoch 474/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9858 - val_loss: 1064.5140\n",
      "Epoch 475/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 14.9859 - val_loss: 1064.5139\n",
      "Epoch 476/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9860 - val_loss: 1064.5134\n",
      "Epoch 477/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9862 - val_loss: 1064.5131\n",
      "Epoch 478/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9863 - val_loss: 1064.5128\n",
      "Epoch 479/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9864 - val_loss: 1064.5126\n",
      "Epoch 480/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9865 - val_loss: 1064.5126\n",
      "Epoch 481/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9866 - val_loss: 1064.5125\n",
      "Epoch 482/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9867 - val_loss: 1064.5121\n",
      "Epoch 483/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9868 - val_loss: 1064.5116\n",
      "Epoch 484/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9869 - val_loss: 1064.5112\n",
      "Epoch 485/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9871 - val_loss: 1064.5111\n",
      "Epoch 486/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9871 - val_loss: 1064.5109\n",
      "Epoch 487/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9872 - val_loss: 1064.5107\n",
      "Epoch 488/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.9873 - val_loss: 1064.5104\n",
      "Epoch 489/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9874 - val_loss: 1064.5101\n",
      "Epoch 490/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9875 - val_loss: 1064.5098\n",
      "Epoch 491/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9876 - val_loss: 1064.5096\n",
      "Epoch 492/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9877 - val_loss: 1064.5095\n",
      "Epoch 493/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9878 - val_loss: 1064.5093\n",
      "Epoch 494/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 14.9879 - val_loss: 1064.5092\n",
      "Epoch 495/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 14.9880 - val_loss: 1064.5089\n",
      "Epoch 496/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9880 - val_loss: 1064.5085\n",
      "Epoch 497/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9882 - val_loss: 1064.5084\n",
      "Epoch 498/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9882 - val_loss: 1064.5082\n",
      "Epoch 499/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9883 - val_loss: 1064.5079\n",
      "Epoch 500/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9884 - val_loss: 1064.5079\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 372ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.99102941e+01, 6.98850840e+01, 6.98598739e+01, 6.98346639e+01,\n",
       "        6.98094538e+01, 6.96949580e+01, 6.95268908e+01, 2.08795503e-01,\n",
       "        2.78723180e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.28298060e-02, 7.01427871e+01, 7.01175770e+01, 7.00923669e+01,\n",
       "        7.00671569e+01, 7.00419468e+01, 7.00167367e+01, 6.99915266e+01,\n",
       "        6.99663165e+01, 6.99411064e+01, 6.99158964e+01, 6.98906863e+01,\n",
       "        6.98654762e+01, 6.98402661e+01, 6.98150560e+01, 6.97323063e+01,\n",
       "        6.95642390e+01, 6.93961718e+01, 6.92281046e+01, 6.90600374e+01,\n",
       "        6.88919701e+01, 6.87239029e+01, 6.85558357e+01, 6.83877684e+01,\n",
       "        6.82197012e+01, 6.80516340e+01, 6.78835668e+01, 6.77547922e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.72302759e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.58016789e-01, 0.00000000e+00, 6.98458684e+01,\n",
       "        6.98206583e+01, 6.97696545e+01, 6.96015873e+01, 6.94335201e+01,\n",
       "        6.92654529e+01, 6.90973856e+01, 6.89293184e+01, 6.87612512e+01,\n",
       "        6.85931839e+01, 6.84251167e+01, 6.82570495e+01, 6.80889823e+01,\n",
       "        6.79209150e+01, 6.77747736e+01, 7.06862045e+01, 7.06115742e+01,\n",
       "        7.05349440e+01, 7.04593137e+01, 7.03836835e+01, 7.03070532e+01,\n",
       "        7.02324230e+01, 7.01567927e+01, 7.00811625e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.99502182e+01, 3.87018085e-01, 1.13371469e-01,\n",
       "        6.67963266e-01, 0.00000000e+00, 1.56377852e-01, 9.91702080e-01,\n",
       "        6.37546730e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.96059048e-03, 8.90238881e-02, 7.67748475e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 9.00180340e-01, 1.48277313e-01, 0.00000000e+00,\n",
       "        1.61020607e-01, 1.22826293e-01, 3.49388152e-01, 0.00000000e+00,\n",
       "        2.69604623e-02, 0.00000000e+00, 0.00000000e+00, 2.57641405e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60.16397059, 60.14389589, 60.1238212 , 60.1037465 , 60.0836718 ,\n",
       "       60.06359711, 60.04352241, 60.02344771, 60.00337302, 59.98329832,\n",
       "       59.96322362, 59.94314893, 59.92307423, 59.90299953, 59.88292484,\n",
       "       59.86285014, 59.84277544, 59.82270075, 59.80262605, 59.78255135,\n",
       "       59.76247666, 59.74240196, 59.72232726, 59.70225257, 59.68217787,\n",
       "       59.66210317, 59.64202848, 59.62195378, 59.60187908, 59.58180439,\n",
       "       59.56172969, 59.541655  , 59.5215803 , 59.5015056 , 59.48862472,\n",
       "       59.47632712, 59.46402951, 59.45173191, 59.43943431, 59.42713671,\n",
       "       59.41483911, 59.4025415 , 59.3902439 , 59.3779463 , 59.3656487 ,\n",
       "       59.3533511 , 59.34105349, 59.32875589, 59.31645829, 59.30416069,\n",
       "       59.29186309, 59.27956548, 59.26726788, 59.25497028, 59.24267268,\n",
       "       59.23037508, 59.21807747, 59.20577987, 59.19348227, 59.18118467,\n",
       "       59.16888707, 59.15658947, 59.14429186, 59.13199426, 59.11969666,\n",
       "       59.10739906, 59.09510146, 59.08280385, 59.07050625, 59.05820865,\n",
       "       59.04591105, 59.03361345, 59.02131584, 59.00901824, 58.99672064,\n",
       "       58.98442304, 58.97212544, 58.95982783, 58.94753023, 58.93523263,\n",
       "       58.92293503, 58.91063743, 58.89833982, 58.88604222, 58.87374462,\n",
       "       58.86144702, 58.84914942, 58.83685181, 58.82455421, 58.81225661,\n",
       "       58.79995901, 58.78766141, 58.7753638 , 58.7630662 , 58.7507686 ,\n",
       "       58.738471  , 58.7261734 , 58.71387579, 58.70157819, 58.68928059])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.069372745820466\n",
      "29.507132126297257\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
