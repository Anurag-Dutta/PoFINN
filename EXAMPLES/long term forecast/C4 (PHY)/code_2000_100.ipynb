{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "2095    60.264344\n",
       "2096    60.244269\n",
       "2097    60.224195\n",
       "2098    60.204120\n",
       "2099    60.184045\n",
       "Name: C4, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_2000_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1995     0.000000\n",
       "1996     0.000000\n",
       "1997     0.000000\n",
       "1998     0.231346\n",
       "1999     0.000000\n",
       "Name: C4, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2000)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1550, 1, 251) (1550, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 26ms/step - loss: 5282.7446 - val_loss: 3807.7593\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5200.0947 - val_loss: 3760.4600\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5135.6782 - val_loss: 3714.4370\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5071.8154 - val_loss: 3668.9937\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5003.3667 - val_loss: 3614.9246\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4930.3359 - val_loss: 3567.5742\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4864.7305 - val_loss: 3521.2170\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4800.3462 - val_loss: 3475.7278\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4736.9692 - val_loss: 3430.9604\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4674.4512 - val_loss: 3386.8342\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4612.7046 - val_loss: 3343.2998\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4551.6782 - val_loss: 3300.3264\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4491.3379 - val_loss: 3257.8918\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4431.6587 - val_loss: 3215.9800\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4372.6191 - val_loss: 3174.5779\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4314.2090 - val_loss: 3133.6746\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4256.4131 - val_loss: 3093.2622\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4199.2202 - val_loss: 3053.3318\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4142.6230 - val_loss: 3013.8770\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4086.6125 - val_loss: 2974.8916\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4031.1807 - val_loss: 2936.3694\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3976.3225 - val_loss: 2898.3052\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3922.0286 - val_loss: 2860.6938\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3868.2964 - val_loss: 2823.5303\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3815.1187 - val_loss: 2786.8103\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3762.4895 - val_loss: 2750.5283\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3710.4041 - val_loss: 2714.6790\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3658.8577 - val_loss: 2679.2563\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3607.8452 - val_loss: 2644.2446\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3556.4077 - val_loss: 2599.0024\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3489.0435 - val_loss: 2559.6233\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3432.6133 - val_loss: 2521.4570\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3378.1069 - val_loss: 2484.6458\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3325.1780 - val_loss: 2448.8484\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3273.4507 - val_loss: 2413.8687\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3222.7144 - val_loss: 2379.5940\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3172.8452 - val_loss: 2345.9546\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3123.7612 - val_loss: 2312.9033\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3075.4062 - val_loss: 2280.4041\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3027.7405 - val_loss: 2248.4319\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2980.7312 - val_loss: 2216.9651\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2934.3525 - val_loss: 2185.9875\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2888.5850 - val_loss: 2155.4844\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2843.4097 - val_loss: 2125.4431\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2798.8123 - val_loss: 2095.8538\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2754.7803 - val_loss: 2066.7070\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2711.3003 - val_loss: 2037.9944\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2668.3640 - val_loss: 2009.7079\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2625.9607 - val_loss: 1981.8403\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2584.0828 - val_loss: 1954.3861\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2542.7217 - val_loss: 1927.3385\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 2501.8701 - val_loss: 1900.6919\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 2461.5210 - val_loss: 1874.4415\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2421.6680 - val_loss: 1848.5819\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2382.3049 - val_loss: 1823.1079\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2343.4255 - val_loss: 1798.0149\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2305.0249 - val_loss: 1773.2992\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2267.0974 - val_loss: 1748.9561\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2229.6375 - val_loss: 1724.9812\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2192.6406 - val_loss: 1701.3707\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2156.1021 - val_loss: 1678.1204\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2120.0168 - val_loss: 1655.2274\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2084.3809 - val_loss: 1632.6873\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2049.1890 - val_loss: 1610.4962\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2014.4369 - val_loss: 1588.6510\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1980.1213 - val_loss: 1567.1484\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1946.2377 - val_loss: 1545.9846\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1912.7815 - val_loss: 1525.1565\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1879.7496 - val_loss: 1504.6603\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1847.1367 - val_loss: 1484.4937\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1814.9407 - val_loss: 1464.6525\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1783.1566 - val_loss: 1445.1343\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1751.7812 - val_loss: 1425.9355\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1720.8119 - val_loss: 1407.0535\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1690.2433 - val_loss: 1388.4850\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1660.0730 - val_loss: 1370.2273\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1630.2971 - val_loss: 1352.2766\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1600.9121 - val_loss: 1334.6307\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1571.9144 - val_loss: 1317.2871\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1543.3014 - val_loss: 1300.2421\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1515.0697 - val_loss: 1283.4932\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1487.2156 - val_loss: 1267.0375\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1459.7356 - val_loss: 1250.8724\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1432.6271 - val_loss: 1234.9945\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1405.8862 - val_loss: 1219.4019\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1379.5096 - val_loss: 1204.0912\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1353.4951 - val_loss: 1189.0602\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1327.8392 - val_loss: 1174.3060\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1302.5386 - val_loss: 1159.8257\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1277.5905 - val_loss: 1145.6172\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1252.9916 - val_loss: 1131.6769\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1228.7386 - val_loss: 1118.0028\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1204.8291 - val_loss: 1104.5925\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1181.2599 - val_loss: 1091.4431\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1158.0282 - val_loss: 1078.5520\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1135.1305 - val_loss: 1065.9165\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1112.5646 - val_loss: 1053.5345\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1090.3271 - val_loss: 1041.4034\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1068.4152 - val_loss: 1029.5200\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1046.8264 - val_loss: 1017.8824\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1025.5571 - val_loss: 1006.4882\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1004.6055 - val_loss: 995.3344\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 983.9678 - val_loss: 984.4185\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 963.6417 - val_loss: 973.7382\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 943.6239 - val_loss: 963.2913\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 923.9117 - val_loss: 953.0749\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 904.5028 - val_loss: 943.0865\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 885.3940 - val_loss: 933.3242\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 866.5829 - val_loss: 923.7850\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 848.0668 - val_loss: 914.4667\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 829.8424 - val_loss: 905.3669\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 811.9074 - val_loss: 896.4830\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 794.2595 - val_loss: 887.8130\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 776.8953 - val_loss: 879.3541\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 759.8121 - val_loss: 871.1038\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 743.0075 - val_loss: 863.0600\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 726.4789 - val_loss: 855.2202\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 710.2234 - val_loss: 847.5820\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 694.2386 - val_loss: 840.1428\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 678.5215 - val_loss: 832.9006\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 663.0699 - val_loss: 825.8530\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 647.8809 - val_loss: 818.9975\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 632.9520 - val_loss: 812.3317\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 618.2805 - val_loss: 805.8533\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 603.8638 - val_loss: 799.5598\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 589.6990 - val_loss: 793.4491\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 575.7841 - val_loss: 787.5188\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 562.1165 - val_loss: 781.7662\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 548.6931 - val_loss: 776.1897\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 535.5112 - val_loss: 770.7863\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 522.5690 - val_loss: 765.5539\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 509.8636 - val_loss: 760.4900\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 497.3923 - val_loss: 755.5927\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 485.1528 - val_loss: 750.8594\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 473.1424 - val_loss: 746.2878\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 461.3587 - val_loss: 741.8754\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 449.7987 - val_loss: 737.6202\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 438.4603 - val_loss: 733.5198\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 427.3408 - val_loss: 729.5717\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 416.4378 - val_loss: 725.7736\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 405.7489 - val_loss: 722.1234\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 395.2713 - val_loss: 718.6185\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 385.0028 - val_loss: 715.2567\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 374.9408 - val_loss: 712.0355\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 365.0826 - val_loss: 708.9520\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 355.4260 - val_loss: 706.0032\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 345.9685 - val_loss: 703.1843\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 336.7073 - val_loss: 700.4850\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 327.6405 - val_loss: 698.4903\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 313.6089 - val_loss: 693.6242\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 301.8541 - val_loss: 690.7745\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 291.1861 - val_loss: 688.2564\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 281.2305 - val_loss: 685.9979\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 271.8075 - val_loss: 683.9556\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 262.8123 - val_loss: 682.1028\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 254.1823 - val_loss: 680.4220\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 245.8758 - val_loss: 678.9002\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 237.8638 - val_loss: 677.5270\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 230.1242 - val_loss: 676.2947\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 222.6402 - val_loss: 675.1955\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 215.3971 - val_loss: 674.2237\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 208.3836 - val_loss: 673.3734\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 201.5890 - val_loss: 672.6398\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 195.0047 - val_loss: 672.0182\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 188.6224 - val_loss: 671.5041\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 182.4355 - val_loss: 671.0938\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 176.4371 - val_loss: 670.7831\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.6213 - val_loss: 670.5684\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 164.9824 - val_loss: 670.4462\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 159.5152 - val_loss: 670.4134\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 154.2150 - val_loss: 670.4665\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 149.0768 - val_loss: 670.6023\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 144.0963 - val_loss: 670.8178\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 139.2694 - val_loss: 671.1101\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 134.5918 - val_loss: 671.4763\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 130.0597 - val_loss: 671.9135\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 125.6692 - val_loss: 672.4189\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 121.4169 - val_loss: 672.9901\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 117.2990 - val_loss: 673.6242\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 113.3122 - val_loss: 674.3187\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 109.4533 - val_loss: 675.0710\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 105.7190 - val_loss: 675.8787\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 102.1061 - val_loss: 676.7394\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 98.6116 - val_loss: 677.6506\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 95.2323 - val_loss: 678.6102\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 91.9653 - val_loss: 679.6156\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 88.8080 - val_loss: 680.6647\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 85.7572 - val_loss: 681.7552\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 82.8102 - val_loss: 682.8851\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 79.9646 - val_loss: 684.0521\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 77.2175 - val_loss: 685.2543\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 74.5663 - val_loss: 686.4895\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 72.0085 - val_loss: 687.7556\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 69.5417 - val_loss: 689.0508\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 67.1632 - val_loss: 690.3731\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 64.8707 - val_loss: 691.7205\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 62.6620 - val_loss: 693.0912\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 60.5346 - val_loss: 694.4836\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 58.4860 - val_loss: 695.8956\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 56.5146 - val_loss: 697.3253\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 54.6177 - val_loss: 698.7712\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 52.7932 - val_loss: 700.2320\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 51.0390 - val_loss: 701.7056\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 49.3531 - val_loss: 703.1904\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 47.7336 - val_loss: 704.6848\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 46.1783 - val_loss: 706.1876\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 44.6850 - val_loss: 707.6971\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 43.2522 - val_loss: 709.2119\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 41.8778 - val_loss: 710.7308\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 40.5599 - val_loss: 712.2519\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 39.2969 - val_loss: 713.7740\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 38.0869 - val_loss: 715.2961\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 36.9283 - val_loss: 716.8168\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 35.8191 - val_loss: 718.3349\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 34.7579 - val_loss: 719.8491\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 33.7429 - val_loss: 721.3583\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 32.7727 - val_loss: 722.8617\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 31.8455 - val_loss: 724.3578\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.9600 - val_loss: 725.8458\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.1145 - val_loss: 727.3245\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 29.3077 - val_loss: 728.7933\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 28.5382 - val_loss: 730.2511\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 27.8045 - val_loss: 731.6971\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 27.1053 - val_loss: 733.1302\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 26.4393 - val_loss: 734.5499\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 25.8053 - val_loss: 735.9556\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 25.2018 - val_loss: 737.3461\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.6280 - val_loss: 738.7208\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.0823 - val_loss: 740.0793\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.5639 - val_loss: 741.4209\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.0714 - val_loss: 742.7453\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.6039 - val_loss: 744.0515\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.1603 - val_loss: 745.3391\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.7396 - val_loss: 746.6077\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.3408 - val_loss: 747.8569\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.9629 - val_loss: 749.0864\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.6051 - val_loss: 750.2957\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.2664 - val_loss: 751.4844\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.9459 - val_loss: 752.6523\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6430 - val_loss: 753.7993\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.3566 - val_loss: 754.9247\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.0860 - val_loss: 756.0289\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.8306 - val_loss: 757.1111\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.5896 - val_loss: 758.1716\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.3622 - val_loss: 759.2100\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.1479 - val_loss: 760.2268\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.9458 - val_loss: 761.2211\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.7556 - val_loss: 762.1934\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.5765 - val_loss: 763.1437\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.4080 - val_loss: 764.0719\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.2494 - val_loss: 764.9777\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.1004 - val_loss: 765.8616\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9604 - val_loss: 766.7237\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.8289 - val_loss: 767.5639\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.7054 - val_loss: 768.3825\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.5896 - val_loss: 769.1793\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.4810 - val_loss: 769.9544\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.3791 - val_loss: 770.7090\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.2837 - val_loss: 771.4423\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 16.1943 - val_loss: 772.1545\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1106 - val_loss: 772.8465\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.0323 - val_loss: 773.5178\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.9590 - val_loss: 774.1694\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.8905 - val_loss: 774.8010\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.8265 - val_loss: 775.4133\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7666 - val_loss: 776.0062\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7107 - val_loss: 776.5803\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.6585 - val_loss: 777.1357\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.6098 - val_loss: 777.6730\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.5643 - val_loss: 778.1921\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.5219 - val_loss: 778.6940\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.4824 - val_loss: 779.1785\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.4455 - val_loss: 779.6458\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.4112 - val_loss: 780.0968\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.3792 - val_loss: 780.5317\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.3493 - val_loss: 780.9506\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.3216 - val_loss: 781.3538\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.2958 - val_loss: 781.7426\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.2717 - val_loss: 782.1159\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.2493 - val_loss: 782.4755\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.2285 - val_loss: 782.8206\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.2091 - val_loss: 783.1527\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.1910 - val_loss: 783.4712\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.1743 - val_loss: 783.7768\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.1587 - val_loss: 784.0696\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.1442 - val_loss: 784.3503\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.1307 - val_loss: 784.6191\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.1183 - val_loss: 784.8768\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.1067 - val_loss: 785.1231\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0959 - val_loss: 785.3590\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0859 - val_loss: 785.5844\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0766 - val_loss: 785.7999\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0679 - val_loss: 786.0056\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0599 - val_loss: 786.2018\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0524 - val_loss: 786.3889\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0455 - val_loss: 786.5673\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0391 - val_loss: 786.7374\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0332 - val_loss: 786.8989\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 15.0277 - val_loss: 787.0531\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0226 - val_loss: 787.1999\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0178 - val_loss: 787.3389\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0134 - val_loss: 787.4712\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0094 - val_loss: 787.5968\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0056 - val_loss: 787.7160\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0022 - val_loss: 787.8290\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9989 - val_loss: 787.9359\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9960 - val_loss: 788.0377\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9932 - val_loss: 788.1335\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9907 - val_loss: 788.2245\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9884 - val_loss: 788.3102\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9863 - val_loss: 788.3916\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9843 - val_loss: 788.4684\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9825 - val_loss: 788.5407\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9809 - val_loss: 788.6092\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9794 - val_loss: 788.6733\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9780 - val_loss: 788.7339\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 14.9767 - val_loss: 788.7909\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9756 - val_loss: 788.8443\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9746 - val_loss: 788.8948\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 14.9737 - val_loss: 788.9426\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9728 - val_loss: 788.9868\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9721 - val_loss: 789.0288\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9714 - val_loss: 789.0679\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9708 - val_loss: 789.1047\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9703 - val_loss: 789.1390\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9698 - val_loss: 789.1712\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9694 - val_loss: 789.2009\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9692 - val_loss: 789.2287\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9689 - val_loss: 789.2548\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 14.9687 - val_loss: 789.2792\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 14.9685 - val_loss: 789.3018\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9685 - val_loss: 789.3228\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9683 - val_loss: 789.3425\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9683 - val_loss: 789.3605\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9683 - val_loss: 789.3770\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9684 - val_loss: 789.3928\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9684 - val_loss: 789.4074\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9686 - val_loss: 789.4211\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9687 - val_loss: 789.4333\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9688 - val_loss: 789.4449\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9690 - val_loss: 789.4552\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9692 - val_loss: 789.4648\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9694 - val_loss: 789.4735\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9697 - val_loss: 789.4814\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9699 - val_loss: 789.4888\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9702 - val_loss: 789.4955\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9705 - val_loss: 789.5019\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9708 - val_loss: 789.5074\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9711 - val_loss: 789.5123\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9715 - val_loss: 789.5169\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9719 - val_loss: 789.5211\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9722 - val_loss: 789.5247\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9726 - val_loss: 789.5281\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9729 - val_loss: 789.5306\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9733 - val_loss: 789.5329\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9738 - val_loss: 789.5354\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9741 - val_loss: 789.5372\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9745 - val_loss: 789.5389\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9750 - val_loss: 789.5402\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 14.9754 - val_loss: 789.5414\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9758 - val_loss: 789.5424\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9762 - val_loss: 789.5430\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9766 - val_loss: 789.5436\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9771 - val_loss: 789.5441\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9775 - val_loss: 789.5443\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9779 - val_loss: 789.5444\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9784 - val_loss: 789.5444\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9788 - val_loss: 789.5443\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9792 - val_loss: 789.5438\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9797 - val_loss: 789.5432\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9801 - val_loss: 789.5428\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9806 - val_loss: 789.5421\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9810 - val_loss: 789.5413\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9815 - val_loss: 789.5408\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9819 - val_loss: 789.5402\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9824 - val_loss: 789.5392\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9828 - val_loss: 789.5383\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9832 - val_loss: 789.5375\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9837 - val_loss: 789.5366\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9841 - val_loss: 789.5356\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9846 - val_loss: 789.5345\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9850 - val_loss: 789.5338\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9854 - val_loss: 789.5328\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9858 - val_loss: 789.5317\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9862 - val_loss: 789.5305\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9867 - val_loss: 789.5294\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9871 - val_loss: 789.5284\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9875 - val_loss: 789.5272\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9880 - val_loss: 789.5262\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 14.9884 - val_loss: 789.5253\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9887 - val_loss: 789.5239\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9892 - val_loss: 789.5230\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9896 - val_loss: 789.5219\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9900 - val_loss: 789.5208\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9903 - val_loss: 789.5195\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9907 - val_loss: 789.5184\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9911 - val_loss: 789.5172\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9915 - val_loss: 789.5161\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9919 - val_loss: 789.5148\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9923 - val_loss: 789.5137\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9927 - val_loss: 789.5127\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9930 - val_loss: 789.5117\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9934 - val_loss: 789.5107\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9937 - val_loss: 789.5091\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9941 - val_loss: 789.5079\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9945 - val_loss: 789.5069\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9948 - val_loss: 789.5059\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9952 - val_loss: 789.5048\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9955 - val_loss: 789.5036\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9959 - val_loss: 789.5023\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9962 - val_loss: 789.5013\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9966 - val_loss: 789.5002\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9969 - val_loss: 789.4990\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9972 - val_loss: 789.4976\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9976 - val_loss: 789.4966\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9979 - val_loss: 789.4958\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9982 - val_loss: 789.4944\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9985 - val_loss: 789.4935\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9988 - val_loss: 789.4924\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9991 - val_loss: 789.4915\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 14.9994 - val_loss: 789.4903\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9997 - val_loss: 789.4893\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0001 - val_loss: 789.4888\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0003 - val_loss: 789.4877\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0006 - val_loss: 789.4868\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0009 - val_loss: 789.4860\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0012 - val_loss: 789.4848\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0015 - val_loss: 789.4838\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0018 - val_loss: 789.4828\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0020 - val_loss: 789.4819\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0023 - val_loss: 789.4812\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0026 - val_loss: 789.4802\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0028 - val_loss: 789.4793\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0031 - val_loss: 789.4788\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0033 - val_loss: 789.4778\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0036 - val_loss: 789.4774\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0038 - val_loss: 789.4764\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0041 - val_loss: 789.4756\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0043 - val_loss: 789.4750\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0046 - val_loss: 789.4743\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0048 - val_loss: 789.4739\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0050 - val_loss: 789.4728\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0052 - val_loss: 789.4719\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0055 - val_loss: 789.4714\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0057 - val_loss: 789.4706\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0059 - val_loss: 789.4700\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0061 - val_loss: 789.4695\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 15.0063 - val_loss: 789.4688\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 15.0065 - val_loss: 789.4680\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0068 - val_loss: 789.4675\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0069 - val_loss: 789.4669\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 15.0071 - val_loss: 789.4663\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0073 - val_loss: 789.4656\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0075 - val_loss: 789.4646\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0077 - val_loss: 789.4640\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0079 - val_loss: 789.4634\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0081 - val_loss: 789.4628\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0083 - val_loss: 789.4623\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0085 - val_loss: 789.4620\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0086 - val_loss: 789.4614\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0088 - val_loss: 789.4607\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0090 - val_loss: 789.4599\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0092 - val_loss: 789.4594\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0093 - val_loss: 789.4590\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0095 - val_loss: 789.4583\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0097 - val_loss: 789.4581\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0098 - val_loss: 789.4575\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0099 - val_loss: 789.4570\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0101 - val_loss: 789.4565\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0102 - val_loss: 789.4557\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0104 - val_loss: 789.4553\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0105 - val_loss: 789.4548\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0107 - val_loss: 789.4545\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0108 - val_loss: 789.4539\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0110 - val_loss: 789.4533\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0111 - val_loss: 789.4527\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0112 - val_loss: 789.4525\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0114 - val_loss: 789.4522\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 15.0115 - val_loss: 789.4517\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0116 - val_loss: 789.4515\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0117 - val_loss: 789.4511\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.0119 - val_loss: 789.4508\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0120 - val_loss: 789.4503\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0121 - val_loss: 789.4498\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0122 - val_loss: 789.4496\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0123 - val_loss: 789.4492\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0124 - val_loss: 789.4490\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0125 - val_loss: 789.4483\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0127 - val_loss: 789.4479\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0128 - val_loss: 789.4478\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0129 - val_loss: 789.4473\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0130 - val_loss: 789.4472\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0131 - val_loss: 789.4469\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0132 - val_loss: 789.4466\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0133 - val_loss: 789.4460\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0134 - val_loss: 789.4458\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0135 - val_loss: 789.4454\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0135 - val_loss: 789.4449\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0136 - val_loss: 789.4446\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.0137 - val_loss: 789.4443\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 346ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.01904062e+01, 7.01651961e+01, 7.01399860e+01, 7.01147759e+01,\n",
       "        7.00897658e+01, 7.00643557e+01, 7.00391457e+01, 6.44442618e-01,\n",
       "        6.12748000e-03, 1.63515449e-01, 7.30717063e-01, 3.29938740e-01,\n",
       "        0.00000000e+00, 7.04228992e+01, 7.03976891e+01, 7.03724790e+01,\n",
       "        7.03472689e+01, 7.03220588e+01, 7.02978487e+01, 7.02716387e+01,\n",
       "        7.02464286e+01, 7.02212185e+01, 7.01960084e+01, 7.01707983e+01,\n",
       "        7.01455882e+01, 7.01203781e+01, 7.00951681e+01, 7.00699580e+01,\n",
       "        7.00447479e+01, 7.00195378e+01, 6.99943277e+01, 6.99691177e+01,\n",
       "        6.99439076e+01, 6.99186975e+01, 6.98934874e+01, 6.98682773e+01,\n",
       "        6.98430672e+01, 6.98178571e+01, 6.97509804e+01, 6.95829132e+01,\n",
       "        3.72043848e-01, 1.93131804e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.01259804e+01,\n",
       "        7.01007703e+01, 7.00755602e+01, 7.00503501e+01, 7.00251401e+01,\n",
       "        6.99999300e+01, 6.99747199e+01, 6.99495098e+01, 6.99242997e+01,\n",
       "        6.98990896e+01, 6.98738795e+01, 6.98486695e+01, 6.98234594e+01,\n",
       "        6.97883287e+01, 6.96202614e+01, 6.94521942e+01, 6.92841270e+01,\n",
       "        6.91160598e+01, 6.89479925e+01, 6.87799253e+01, 6.86118581e+01,\n",
       "        6.84437908e+01, 6.82757236e+01, 6.81076564e+01, 6.79395892e+01,\n",
       "        6.77847642e+01, 7.49386597e+01, 0.00000000e+00, 4.88929820e-02,\n",
       "        3.88379961e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.22684860e+01, 1.89366862e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.82064436e-02, 0.00000000e+00, 1.68435514e-01, 2.85244942e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.05797285e-01, 0.00000000e+00,\n",
       "        1.28409028e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([62.17144024, 62.15136555, 62.13129085, 62.11121615, 62.09114146,\n",
       "       62.07106676, 62.05099206, 62.03091737, 62.01084267, 61.99076797,\n",
       "       61.97069328, 61.95061858, 61.93054388, 61.91046919, 61.89039449,\n",
       "       61.87031979, 61.8502451 , 61.8301704 , 61.8100957 , 61.79002101,\n",
       "       61.76994631, 61.74987162, 61.72979692, 61.70972222, 61.68964753,\n",
       "       61.66957283, 61.64949813, 61.62942344, 61.60934874, 61.58927404,\n",
       "       61.56919935, 61.54912465, 61.52904995, 61.50897526, 61.48890056,\n",
       "       61.46882586, 61.44875117, 61.42867647, 61.40860177, 61.38852708,\n",
       "       61.36845238, 61.34837768, 61.32830299, 61.30822829, 61.28815359,\n",
       "       61.2680789 , 61.2480042 , 61.22792951, 61.20785481, 61.18778011,\n",
       "       61.16770542, 61.14763072, 61.12755602, 61.10748133, 61.08740663,\n",
       "       61.06733193, 61.04725724, 61.02718254, 61.00710784, 60.98703315,\n",
       "       60.96695845, 60.94688375, 60.92680906, 60.90673436, 60.88665966,\n",
       "       60.86658497, 60.84651027, 60.82643557, 60.80636088, 60.78628618,\n",
       "       60.76621148, 60.74613679, 60.72606209, 60.70598739, 60.6859127 ,\n",
       "       60.665838  , 60.64576331, 60.62568861, 60.60561391, 60.58553922,\n",
       "       60.56546452, 60.54538982, 60.52531513, 60.50524043, 60.48516573,\n",
       "       60.46509104, 60.44501634, 60.42494164, 60.40486695, 60.38479225,\n",
       "       60.36471755, 60.34464286, 60.32456816, 60.30449346, 60.28441877,\n",
       "       60.26434407, 60.24426937, 60.22419468, 60.20411998, 60.18404528])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.017170497314986\n",
      "28.315420456651765\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
