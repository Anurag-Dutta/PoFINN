{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1895    64.000630\n",
       "1896    63.992227\n",
       "1897    63.983824\n",
       "1898    63.975420\n",
       "1899    63.967017\n",
       "Name: C4, Length: 1900, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_1800_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1795     0.000000\n",
       "1796     0.358017\n",
       "1797     0.000000\n",
       "1798     0.000000\n",
       "1799     0.000000\n",
       "Name: C4, Length: 1800, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1800)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeJ0lEQVR4nO3deXRcZ5nn8e+jzVqszZYsy/Km2E6CHJPEUUIgJE0TCCHQhKWHTncDYTs5zGl6oJk5THo409MzffrQDNP00DMsJ00CoU/SLAEmgYbOBiFAwI4TO3G8xI7j3ZItW5a8SLK2Z/6oK7lkl6xS1a2qe8u/zzk6qrpVdevRlf27r9563/eauyMiIvFTUugCREQkMwpwEZGYUoCLiMSUAlxEJKYU4CIiMVWWzzdramry5cuX5/MtRURi77nnnjvq7s3nbs9rgC9fvpwNGzbk8y1FRGLPzPam2q4uFBGRmFKAi4jElAJcRCSmFOAiIjGlABcRiSkFuIhITCnARURiKhYB/q8vdvHAupTDIEVELlrxCPDNh/jioy8zNDJW6FJERCIjFgH+J9cto29ghEe3dBe6FBGRyIhFgL9hxXyWza/mgXX7Cl2KiEhkxCLAS0qMO65dyvrdvTz18pFClyMiEgmxCHCAO65dQntTDR/+5rN89qEX6B8YKXRJIiIFFZsAb6yp4GefupFP/N4KfvD8QW7+0i/5xyd3sml/H2PjujCziFx8LJ9Xpe/s7PQwlpN96WA//+PHW1m/pxeA+qpy3riyiRtXNXHjpc20NVRl/R4iIlFhZs+5e+d52+MY4BOOnTrDb3Yd41c7enh6Zw+HT5wBYEVzDbetaeX2q9pYuWBuaO8nIlIIRRngydydnUdO8fSOHn7x8hF+u+sY4w5XtNXx7qva+IMrF9FSV5mT9xYRyaWiD/BzHTkxxCMvHOLhTYfYfLCfEoPXr5jP7Ve1cesVC6mrLM9LHSIi2broAjzZrp5TPLzxIP9v0yH29Q5QUVbCTauaeWvHAn7/8gUsqFXLXESi66IO8Anuzsb9fTyy6RCPbz3Mwb5BAK5c0sA1SxtZs7iONW31tDfNpbTEClaniEgyBfg53J3t3Sd5YuthntrRw5ZD/QyNjANQXVHK6kV1XNFWz2sX1yvURaSgFOAzGB0b55WeU2w+0M9LB/vZfLCfrV0nUob6muDrkmaFuojkngI8A6Nj4+zqOc3mg/1sPtCXMtQ7Wqe21BXqIhI2BXhIkkN9sqV+6ASDwVK3yaG+pq2eNYvrWaFQF5EsZBXgZvYXwMcBBzYDHwFage8A84HngA+6+/CF9lMMAZ7K2Lizq+cULx5IHepV5aV0LKqb7HpRqIvIbGQc4GbWBvwa6HD3QTP7HvBT4Dbgh+7+HTP7OvCCu3/tQvsq1gBPZSLUNx/on2ytb5km1K9oq6ejtY72phqqKkoLXLmIRM10AV6W5uvLgCozGwGqgS7gzcCfBI/fD/w1cMEAv5iUlhiXttRyaUst77tmMZAI9VeDlvpEqH/32f1865k9k69rqZvD8vk1ia+mGpbPrw6+K9xFZKoZA9zdD5rZ/wL2AYPAYyS6TPrcfTR42gGgLdXrzewu4C6ApUuXhlFzbJWWGKtaalmVItS3d59k77HT7D46wJ5jp3ly+2GOnpraIzVduC+bX011RbrnYhEpFjP+rzezRuB2oB3oA74P3JruG7j7PcA9kOhCyajKIpYc6uc6MTTCvmMD7D56ejLc96YIdzNYu7SRWzpaeNvqhSxvqsnnjyAiBZJOs+0twG537wEwsx8CNwANZlYWtMIXAwdzV+bFqa6ynCuCPvJznRwaYe+xRGt9R/dJntx+hM//bDuf/9l2Lm2Zyy0dC3nb6oVc0VaHmT4sFSlG6XyI+TrgPuBaEl0o3wI2ADcBP0j6EPNFd//qhfZ1MX2IWQgHjg/w+NbDPLqlm/W7exl3aK2v5JaOFm5ZvZDr2udRXhqba3iISCDbYYT/HfgjYBTYSGJIYRuJYYTzgm0fcPczF9qPAjx/ek8P8/PtR3hsSzdP7+xhaGSc+qpybr58AbesbuGmS5vVby4SE5rIcxEbHB7j6Z09PLblME9uP0zfwAhzykq4cVUzt6xu4ebLFzB/7pxClyki08h2GKHEWFVFKW9bnegTHx0bZ/2eXh7bcpjHtx7miW2HKTHoXD6Pt7xmAS11lVSVl1JVUUp1RSlV5WWJ78FXdXkpZeqGEYkEtcAvYu7OlkMneGxLN49tPcz27pNpva6itITK8hKqK5LCPSn0qyvKWNJYRceielYvqmNxY5U+SBXJgrpQZEY9J89wYmiEweExBobHGBgeZWhk4vZYitujDAyPMTg8xmDw2ODwGKeHRznUN8h48E+rvqqcjtY6Vi+qY3VbHasX1XNJU41a8iJpUheKzKi5dg7NteH0hQ8Oj7G9+wRbDiW+th7q59u/28vwaGIlxzllJVw+EeqLEqF++cJaKss121Qy1zcwzKNbuvmjay+OSYMKcMmJqopSrl7ayNVLGye3TazkuOVQfxDs/fz4hUM8uG4fkJjUtKK5htVB10vHojpWt9ZTX63rl0p6PvO9F/j59iNcuaSByxfWZbSPHYdP8q8vdvEXb7005OrCpwCXvCkrLeGyhbVctrCW965NbHN39vcOTgn137xylB9tPDsvrGluBYsbq1kyr5ql86pYEtxe0lhNa0OlxrbLpO7+IQBGxzLvGn7fV5/h5JlRPvF7KzJef+hvfrKVe3+9mz1/946M60iHAlwKysxYOr+apfOrefua1sntPSfPsOVQ4gIae48OsP/4AJv2H+enm7sYGz/7n7PEoLW+iiXJwZ50u3nuHEq0bO9FY+LfRjZLNQ+NJlYMLcmiXXDvr3dn/uJZUIBLJDXXzuFNly3gTZctmLJ9dGycrv4h9h8f4EDvIPuPD7C/d4D9xwf55Y4ejpycOpesoqyExY2JQG9vqqGjNdE1s6plLnPK1N9ebMaCQRllWQT4xEnAiP6JXwEusVJWWhK0sqthxfmPD42MceD4YBDwiWBPBPwAG/b0cno40boqLzVWLqid/BB1IthrK9XfHmfjQfhm81fXxB94TvTX3lOAS1GpLC9l5YK5rFww97zHxsedvb0Dia6ZYHTMUy/38NBzByafs2x+9dkhj8GHqQvqKvP5I0gWJlrgJRfJvAMFuFw0SkqM9qYa2ptqeOdrF01uP3JiiC1dJ4JQT3yY+rOXuicfb5o7JzEiJqm1vnx+jfrWI2ii+yObLpQ4UYDLRW9BXSUL6ir5/aT+9pNDI2zrOjkZ6FsPneAbv3qVkWB0Q01FKVe01XPV0gauXtLI1UsbaFFLveDGQuhCiRMFuEgKtZXlXNc+j+va501uOzM6xs7DpyZb6psO9HPfr3czMvYqkFi696olDVy9tIGrljSypq1el8HLs7MfQGYvj5PUM6YAF0nTnLLSpAtsLAESH5pu7TrBpn19bNrfx8b9xye7X0pLjMtaarlqaQNXLWlg7dIGLmmae9G0DgthPA6pGyIFuEgWKstLWbu0kbVJM06PnjrDC/uDQN/Xx483nZ1tWltZxpWLG7hsYS01FaVUTiwEFiwGVhncrpzcVpJ0u5TKstKL5gTw4Lp9HOwboK2hmtb6SlobKmmtq6KuqmzaxdGS5whcDBTgIiFrmjuHm1/Tws2vaQESo19ePXqKjfvOhvoD6/YyNDKe0f7nlJVMrgBZORn2U7dNBH6q56R6/NzXzikrKfiJ4q8efonRFIFcXVHKwvpKWusrWVhXxaKGysn7xwdGAHASs3zf89VnOHb6DIvqq2hrqGJR8NXWWEVbQyWLGqpmvLDJ8/uOMzrmiferj9bMXwW4SI6VlCTGnK9cUMu/61wyud3dOTM6Prma4+BIYjXHoeTbo+MMzfB48rbjp0fOPh4858xoZieKyvKSyb8Ozv1LYU7ZROiXTHl87pyyxIe7SxqyXpispMT4+BuW89E3ttPVP0RX/yDd/UOTt7v6h3hm11EOnxgiVcN7bNzZtL+PVQvm4g7rdvfSfWLovFZ6Q3V5IuAbEyGfrH9ghPd97ZnJ/nAzWFA7h9b6xIljSWM1H7h+WWJeQgEowEUKxMwmW8eNMz89Y+PjwYlimpPA4Eji/tDk/fHJbec9PjLG6TOjHD01fN7jySeKitISXru4fvKD4GuWNc5qkpS7MzI2TlVF6WSrmWmO0ujYOD2nztDVP8SXn9jJL3f0THn8XVcu4s9vXjX53CMnz3Cwb5BDfYNnvx8fZN+xAX6769iU154ZHcMdPnj9Mq5oq+NQX+LkcahviO3dJ3li6xEeXL+Pz793zZShqfmiABcpciUlNnlFpVwaG3f6B0d4fu9xnt3Ty7rdvdzz9Kt89aldlBh0LKrj2uXzeF37PK5dPu+Cl/EbG3fcEyeCmZSVltBaX0VrfRXvWNN6XoCf+9yzJ4TUPnjvOn618+iUbZe31qZconbfsQH+w3c28skHN/KrHUf5b+/qyOu1ZhXgIhKK0hJjXk0Fb+lo4S0dif7/geFRNu7rY93uXp7d3cuD6/bxzd/sAWBFcw3Xtc/nuvZGrmufP6X7Yngs0ZovL8usv9k984nwb1jRdF6AT2fp/Gq+/4nX8w+P7+Brv9zFs3t7+T9/fHWG7zx7CnARyZnqijJuWNnEDSubABgeHWfzwX7W7+5l/e5j/OTFQ/zL+sQInbaGqskul0tbaoH0WuBThPi5qztpnQTKS0v47K2X88aVTXz6u5t4z1eeCa+IGSjARSRvKspKuGZZI9csa+Tfv2kFY+PO9u4TrN/dy7N7evnVzp4pa8FXZNgCTzbbZVFSPT+dlQnfsLKJf/v0TXz2oRd4YtuR2b1phhTgIlIwpSUWLBpWz0duaMfd2X30NOt397L72GneGnTFxMW8mgr+6UOdXPu3T3L01JmZX5AlBbiIRIaZcUnzXC5pPn81ydlwD2cqfCb7MDPeu7aNf/7t3uwLmEF0RqSLiGQpVUfHdLM2Z5LteuD5WE9cAS4ikiT1SSD7feSCAlxEilIcrqiTLQW4iMg0on4SUICLSNHItL87lWw/BM3HyrYKcBGRJKnHgc92J2FUMjMFuIgUpUINI8wnBbiIFJ2oB29YFOAiUjTCGAI4IfkckMk+8nEOUYCLiCRJZ92TfOwjHQpwEZFpRL0nRgEuIkUnefx2vlrDhZBWgJtZg5k9ZGbbzWybmb3ezOaZ2eNmtjP4nsurQomIzCjEYeC4Z3kSiNA48C8D/+bulwNXAtuAu4En3X0V8GRwX0QkEjIdiRLGSSDME8mFzBjgZlYP3ATcC+Duw+7eB9wO3B887X7g3bkpUUSkMDzi4xHTaYG3Az3AN81so5l9w8xqgBZ37wqe0w2kXHndzO4ysw1mtqGnZ/qLjYqIhCU5d0NpDWfUgxKN5WTLgLXA19z9auA053SXeOI0lbJad7/H3TvdvbO5uTnbekVEphVqH3gWr43ScrIHgAPuvi64/xCJQD9sZq0Awff8XARORCQNYbSAI96DMnOAu3s3sN/MLgs23QxsBR4B7gy23Qk8nJMKRUQkpXSvifnnwANmVgG8CnyERPh/z8w+BuwF3p+bEkVEZmfKNPhM95Hcj57l63MlrQB3901AZ4qHbg61GhGRLIQyDT6EjvTIDCMUEYmjqPdfh0EBLiJFLV+t4UJQgItI0QllAs6UseSzPwtoOVkRkVlIztlMAzSceT9aTlZEpKCi3o+uABeRohbOBRqiSQEuIkUnjIZztjM587EQlgJcRIpSpgE6tR89+33kkgJcRIqahhGKiFzEonoSUICLSNFxz74fPNsubI0DFxGZhVDWMUm6nfFl2bKuIj0KcBGRmFKAi4jMIJOGfT4mASnARaQIeWH7sPP0qacCXESKRijrmCSFb8Rn0ivARaS4hfPBZjTHESrARURiSgEuIkXHnaz7P9w98+n42b112hTgIlI0UvWWzDZMozrrMhUFuIjIDKIa6gpwESk6iR6Uwo8hyfWSsgpwESkaYY4WyaYbXcvJioiEYLZhGtHekpQU4CIiMaUAF5Gi4x6NCxLnugYFuIgUjTD7nrM5CeRr5qYCXESK2qyjNMVZIIzp+LmgABcRiSkFuIgUHQ9hFLhnNZBwYh+5pQAXkaKRqqNjtt0f4SxJG8JO0qAAFxGZQTR7wBXgIlKkcj2NPQo1KMBFpOiEkptZDSPMDwW4iBSNlMvJznYqfQj7yBcFuIhITKUd4GZWamYbzewnwf12M1tnZq+Y2XfNrCJ3ZYqIzE5IvSgFr+FCZtMC/xSwLen+F4B/cPeVwHHgY2EWJiKSqTD6wLPZRaSGEZrZYuAdwDeC+wa8GXgoeMr9wLtzUJ+IyCykmAY/6z2k2kc0O8HTbYH/b+CzwHhwfz7Q5+6jwf0DQFuqF5rZXWa2wcw29PT0ZFOriIgkmTHAzeydwBF3fy6TN3D3e9y90907m5ubM9mFiMishdKNkvWV7bOv4ULK0njODcC7zOw2oBKoA74MNJhZWdAKXwwczF2ZIiLpm7ISSoYd0tmEb75WL5yxBe7uf+nui919OXAH8HN3/1PgF8AfBk+7E3g4Z1WKiKQhjNy8WMaB/2fgM2b2Cok+8XvDKUlEJHtRuCp9rqXThTLJ3Z8CngpuvwpcF35JIiLRkO1JINcnEc3EFJGik9x/nWnvR3L4RrQHRQEuIsUjlLW8Q9hHvijARaQ4RWAYYa4pwEWkqBVyBEmuTwAKcBGRFDyLoeSRWgtFRCQOwphAE9Ux36kowEWkKIWynKz6wEVECieclQRne2X7iEylFxGJm0KvB54vCnARKRrJ7d7ML0gcn05wBbiIyDSynkqvYYQiIpnL1QqFuX7PdCjARaTohLGIlEd9CAoKcBEpIskt34xDPHkfEc9wBbiIFLVCfiSp5WRFRAps9le2zw8FuIgUnShc0DgfFOAiUjQshP7r+IwCV4CLSJELZxhh/q9snw4FuIhIyDQOXEQkQ07ma5mEsSRtvijARaRohL2OSdQ/yFSAi0hRCyPUM7+yfW4pwEVEUsim9a31wEVEMuTuGa9lMmVJ2oivCq4AF5HikarhW4DVCCfkekEsBbiISMg0jFBEJEOhXNA44t0noAAXkSISyiXVtJysiEg0hHJN+kz7wEN47wtRgIuIxJQCXESKTljLyUa8B0UBLiLFI4x1TGK0FIoCXESKWyihnmFPupaTFRGJmXytaDhjgJvZEjP7hZltNbMtZvapYPs8M3vczHYG3xtzX66ISDo869avk/uZlNlKpwU+CvxHd+8Argf+zMw6gLuBJ919FfBkcF9EpGDCmEmfsrskov3iMwa4u3e5+/PB7ZPANqANuB24P3ja/cC7c1SjiEg8RakP3MyWA1cD64AWd+8KHuoGWqZ5zV1mtsHMNvT09GRTq4hILOSrwZ52gJvZXOAHwKfd/UTyY57oKEp5rnH3e9y90907m5ubsypWRCQdiTHc2TV/3aO/GkpaAW5m5STC+wF3/2Gw+bCZtQaPtwJHclOiiEh6Ug3+mO2AkJT7yKycnEtnFIoB9wLb3P1LSQ89AtwZ3L4TeDj88kRE4ivXbfiyNJ5zA/BBYLOZbQq2/Rfg74DvmdnHgL3A+3NSoYhIBsKaTp+JfM3mnDHA3f3XTP8XxM3hliMikr3k3I3qSoJh0ExMESkaubqYcKYzKzWVXkQkZiI3jFBEJE7CafxGuyNFAS4iRSe56yKMlQRjO4xQRCQuwhj9EeZKgrqkmohIzERmOVkRkTgKYynYiK8mqwAXkeKTHN6ZN4bD2EduKcBFpGiEkbNhZnWuLwihABeRohRGdGa6j3y12BXgIiIphDEUMdcU4CJSdLJpfUe1vzsVBbiIFI+Iha/GgYuIZKCgy8lm/9ZpUYCLSFHLeCXBKfsIp5awKcBFpOhk0/qO6geWqSjARaRoTA3fwk+j1HrgIiIFkvFEHK2FIiKSvUyjVMvJiogUQDZXgw+z8Zzrq9IrwEWkaCSHbyjDCDOtI/u3TosCXESKWigt6oj2oSjARURSyHX3RxgU4CJSfLIaBx4iDSMUEUlP2KPAIz6KUAEuIsUtjJmVUZ2dqQAXEUkh6tfDBAW4iBQhJ5zuj2w/yNRysiIiacp05cGw5avLRQEuIkUtjEyPyHnhPApwEZEU1AcuIlIA7tn0X0/pBM+6jlxSgItI0UjV1VGImfQaBy4iIhekABeRohPGOiZaC0VEJI+mTKUPZRx4diK9HriZ3WpmL5vZK2Z2d1hFiYhk4+DxQf7mJ1uBsIYRzm4nE88eGc1tgJdl+kIzKwW+ArwVOAA8a2aPuPvWsIoTEZmNvoERAO7+4eas9/XzbUdoqC4HMr825k1f/AUA9324kzdf3pJ1TefKpgV+HfCKu7/q7sPAd4DbwylLRGT2+gZHzts2PDa78F3RXAPA3z++g//68BYAjpw8k1VdH/3WBvYdG8hqH6lkE+BtwP6k+weCbVOY2V1mtsHMNvT09GTxdiIiF/bO17ZOuT+vpoI3rJg/q32sXFDL1z+wlhtXNU1ue2vH7FrPN6xsYk1b/eT9ZfOrqSgL/yNHy/RPAzP7Q+BWd/94cP+DwOvc/ZPTvaazs9M3bNiQ0fuJiFyszOw5d+88d3s2p4SDwJKk+4uDbSIikgfZBPizwCozazezCuAO4JFwyhIRkZlkPArF3UfN7JPAo0ApcJ+7bwmtMhERuaCMAxzA3X8K/DSkWkREZBY0E1NEJKYU4CIiMaUAFxGJKQW4iEhMZTyRJ6M3M+sB9mb48ibgaIjl5Epc6oT41Ko6wxeXWlVnwjJ3bz53Y14DPBtmtiHVTKSoiUudEJ9aVWf44lKr6rwwdaGIiMSUAlxEJKbiFOD3FLqANMWlTohPraozfHGpVXVeQGz6wEVEZKo4tcBFRCSJAlxEJKZiEeBRuniymS0xs1+Y2VYz22Jmnwq2/7WZHTSzTcHXbUmv+cug9pfN7G15rHWPmW0O6tkQbJtnZo+b2c7ge2Ow3czsH4M6XzSztXmq8bKkY7bJzE6Y2aejcjzN7D4zO2JmLyVtm/UxNLM7g+fvNLM781TnF81se1DLj8ysIdi+3MwGk47t15Nec03wb+aV4GcJ4ZLAM9Y56991PjJhmlq/m1TnHjPbFGwvzDF190h/kViqdhdwCVABvAB0FLCeVmBtcLsW2AF0AH8N/KcUz+8Iap4DtAc/S2meat0DNJ2z7X8Cdwe37wa+ENy+DfgZiQtqXw+sK9DvuhtYFpXjCdwErAVeyvQYAvOAV4PvjcHtxjzUeQtQFtz+QlKdy5Ofd85+1ge1W/CzvD0Pdc7qd52vTEhV6zmP/z3wV4U8pnFogUfq4snu3uXuzwe3TwLbSHEt0CS3A99x9zPuvht4hcTPVCi3A/cHt+8H3p20/due8DugwcxaU7w+l24Gdrn7hWbr5vV4uvvTQG+KGmZzDN8GPO7uve5+HHgcuDXXdbr7Y+4+Gtz9HYmrZk0rqLXO3X/nieT5Nmd/tpzVeQHT/a7zkgkXqjVoRb8f+JcL7SPXxzQOAZ7WxZMLwcyWA1cD64JNnwz+XL1v4s9qClu/A4+Z2XNmdlewrcXdu4Lb3cDE1VqjcJzvYOp/iKgdzwmzPYZRqPmjJFp/E9rNbKOZ/dLMbgy2tQW1TchnnbP5XUfheN4IHHb3nUnb8n5M4xDgkWRmc4EfAJ929xPA14AVwFVAF4k/rwrtje6+Fng78GdmdlPyg0GLIBLjSC1xWb53Ad8PNkXxeJ4nSsdwOmb2OWAUeCDY1AUsdfergc8AD5pZXaHqIya/63P8MVMbGwU5pnEI8MhdPNnMykmE9wPu/kMAdz/s7mPuPg78E2f/rC9Y/e5+MPh+BPhRUNPhia6R4PuRQtcZeDvwvLsfhmgezySzPYYFq9nMPgy8E/jT4GRD0CVxLLj9HIn+5EuDmpK7WfJSZwa/64L+GzCzMuC9wHcnthXqmMYhwCN18eSg7+teYJu7fylpe3J/8XuAiU+uHwHuMLM5ZtYOrCLxoUau66wxs9qJ2yQ+0HopqGdiFMSdwMNJdX4oGElxPdCf1E2QD1NaNFE7nueY7TF8FLjFzBqD7oFbgm05ZWa3Ap8F3uXuA0nbm82sNLh9CYlj+GpQ6wkzuz74d/6hpJ8tl3XO9ndd6Ex4C7Dd3Se7Rgp2TMP+5DYXXyQ+3d9B4qz2uQLX8kYSfzK/CGwKvm4D/hnYHGx/BGhNes3ngtpfJuRP9S9Q5yUkPp1/AdgycdyA+cCTwE7gCWBesN2ArwR1bgY683hMa4BjQH3StkgcTxInlS5ghET/5ccyOYYk+qBfCb4+kqc6XyHRVzzx7/TrwXPfF/yb2AQ8D/xB0n46SQToLuD/EszWznGds/5d5yMTUtUabP8W8IlznluQY6qp9CIiMRWHLhQREUlBAS4iElMKcBGRmFKAi4jElAJcRCSmFOAiIjGlABcRian/D8CwhwJ91Oy4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1350, 1, 251) (1350, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 2s 29ms/step - loss: 5383.1699 - val_loss: 4262.6157\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5293.4736 - val_loss: 4207.5259\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5235.4204 - val_loss: 4159.7134\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5180.1313 - val_loss: 4112.4468\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5125.4707 - val_loss: 4065.7546\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5071.4038 - val_loss: 4019.5806\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5017.8716 - val_loss: 3973.8828\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4964.8369 - val_loss: 3928.6357\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4912.2729 - val_loss: 3883.8218\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 4860.1646 - val_loss: 3839.4282\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4808.4976 - val_loss: 3795.4441\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4757.2656 - val_loss: 3751.8577\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4703.4761 - val_loss: 3698.7036\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4642.0786 - val_loss: 3651.6843\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4587.3584 - val_loss: 3605.6187\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4533.8101 - val_loss: 3560.5508\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4481.2700 - val_loss: 3516.2791\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4429.5400 - val_loss: 3472.6748\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4378.4990 - val_loss: 3429.6594\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4327.8120 - val_loss: 3382.4426\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4270.2529 - val_loss: 3335.8257\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4215.3652 - val_loss: 3289.9700\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4161.8047 - val_loss: 3245.3547\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4109.5161 - val_loss: 3201.7295\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 4058.2385 - val_loss: 3158.9138\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4007.8005 - val_loss: 3116.7996\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3958.0981 - val_loss: 3075.3154\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3909.0605 - val_loss: 3034.4114\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3860.6394 - val_loss: 2994.0540\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3812.7969 - val_loss: 2954.2153\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3765.5071 - val_loss: 2914.8740\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3718.7468 - val_loss: 2876.0127\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3672.4973 - val_loss: 2837.6169\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3626.7434 - val_loss: 2799.6746\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3581.4724 - val_loss: 2762.1743\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3536.6721 - val_loss: 2725.1077\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3492.3337 - val_loss: 2688.4658\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3448.4480 - val_loss: 2652.2412\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3405.0056 - val_loss: 2616.4272\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3362.0015 - val_loss: 2581.0168\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3319.4270 - val_loss: 2546.0063\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3277.2764 - val_loss: 2511.3872\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3235.5452 - val_loss: 2477.1572\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3194.2266 - val_loss: 2443.3105\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 3153.3164 - val_loss: 2409.8425\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 3112.8098 - val_loss: 2376.7498\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3072.7024 - val_loss: 2344.0271\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3032.9885 - val_loss: 2311.6709\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2993.6660 - val_loss: 2279.6780\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2954.7305 - val_loss: 2248.0442\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2916.1775 - val_loss: 2216.7676\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2878.0046 - val_loss: 2185.8433\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2840.2070 - val_loss: 2155.2681\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2802.7820 - val_loss: 2125.0388\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2765.7258 - val_loss: 2095.1538\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2729.0364 - val_loss: 2065.6084\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2692.7090 - val_loss: 2036.4009\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2656.7424 - val_loss: 2007.5271\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2621.1318 - val_loss: 1978.9852\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2585.8755 - val_loss: 1950.7720\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2550.9709 - val_loss: 1922.8864\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2516.4143 - val_loss: 1895.3232\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2482.2036 - val_loss: 1868.0815\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2448.3357 - val_loss: 1841.1581\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2414.8079 - val_loss: 1814.5505\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2381.6189 - val_loss: 1788.2573\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2348.7644 - val_loss: 1762.2737\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2316.2427 - val_loss: 1736.6001\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2284.0513 - val_loss: 1711.2321\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2252.1877 - val_loss: 1686.1685\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2220.6497 - val_loss: 1661.4061\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2189.4346 - val_loss: 1636.9430\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2158.5403 - val_loss: 1612.7773\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2127.9646 - val_loss: 1588.9060\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2097.7053 - val_loss: 1565.3278\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2067.7595 - val_loss: 1542.0404\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2038.1257 - val_loss: 1519.0404\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2008.8004 - val_loss: 1496.3263\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1979.7833 - val_loss: 1473.8962\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1951.0710 - val_loss: 1451.7483\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1922.6617 - val_loss: 1429.8796\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1894.5532 - val_loss: 1408.2888\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1866.7433 - val_loss: 1386.9740\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1839.2302 - val_loss: 1365.9321\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1812.0115 - val_loss: 1345.1617\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1785.0851 - val_loss: 1324.6614\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1758.4498 - val_loss: 1304.4277\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1732.1023 - val_loss: 1284.4596\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1706.0416 - val_loss: 1264.7552\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1680.2650 - val_loss: 1245.3123\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1654.7708 - val_loss: 1226.1283\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1629.5569 - val_loss: 1207.2023\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1604.6217 - val_loss: 1188.5317\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1579.9631 - val_loss: 1170.1151\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1555.5792 - val_loss: 1151.9501\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1531.4681 - val_loss: 1134.0350\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1507.6276 - val_loss: 1116.3678\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1484.0560 - val_loss: 1098.9469\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1460.7516 - val_loss: 1081.7701\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1437.7125 - val_loss: 1064.8359\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1414.9366 - val_loss: 1048.1425\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1392.4226 - val_loss: 1031.6868\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1370.1672 - val_loss: 1015.4686\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1348.1705 - val_loss: 999.4849\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1326.4296 - val_loss: 983.7350\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1304.9426 - val_loss: 968.2159\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1283.7080 - val_loss: 952.9268\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1262.7240 - val_loss: 937.8651\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1241.9888 - val_loss: 923.0297\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1221.5011 - val_loss: 908.4185\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1201.2582 - val_loss: 894.0296\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1181.2590 - val_loss: 879.8613\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1161.5017 - val_loss: 865.9117\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1141.9838 - val_loss: 852.1793\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1122.7047 - val_loss: 838.6624\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1103.6619 - val_loss: 825.3593\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1084.8538 - val_loss: 812.2673\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1066.2793 - val_loss: 799.3862\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1047.9359 - val_loss: 786.7135\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1029.8225 - val_loss: 774.2475\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1011.9368 - val_loss: 761.9860\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 994.2773 - val_loss: 749.9280\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 976.8428 - val_loss: 738.0717\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 959.6313 - val_loss: 726.4149\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 942.6407 - val_loss: 714.9567\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 925.8702 - val_loss: 703.6947\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 909.3174 - val_loss: 692.6275\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 892.9808 - val_loss: 681.7529\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 876.8591 - val_loss: 671.0699\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 860.9503 - val_loss: 660.5768\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 845.2528 - val_loss: 650.2718\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 829.7653 - val_loss: 640.1529\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 814.4855 - val_loss: 630.2188\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 799.4125 - val_loss: 620.4675\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 784.5441 - val_loss: 610.8975\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 769.8791 - val_loss: 601.5075\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 755.4156 - val_loss: 592.2950\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 741.1521 - val_loss: 583.2591\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 727.0871 - val_loss: 574.3978\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 713.2188 - val_loss: 565.7098\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 699.5458 - val_loss: 557.1932\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 686.0665 - val_loss: 548.8463\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 672.7790 - val_loss: 540.6678\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 659.6823 - val_loss: 532.6555\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 646.7740 - val_loss: 524.8077\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 634.0530 - val_loss: 517.1237\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 621.5178 - val_loss: 509.6010\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 609.1667 - val_loss: 502.2385\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 596.9985 - val_loss: 495.0341\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 585.0110 - val_loss: 487.9866\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 573.2029 - val_loss: 481.0940\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 561.5726 - val_loss: 474.3546\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 550.1184 - val_loss: 467.7675\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 538.8392 - val_loss: 461.3306\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 527.7333 - val_loss: 455.0421\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 516.7989 - val_loss: 448.9010\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 506.0345 - val_loss: 442.9046\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 495.4385 - val_loss: 437.0522\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 485.0095 - val_loss: 431.3423\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 474.7461 - val_loss: 425.7726\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 464.6466 - val_loss: 420.3423\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 454.7093 - val_loss: 415.0489\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 444.9328 - val_loss: 409.8914\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 435.3154 - val_loss: 404.8681\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 425.8560 - val_loss: 399.9773\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 416.5526 - val_loss: 395.2171\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 407.4038 - val_loss: 390.5869\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 398.4086 - val_loss: 386.0840\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 389.5649 - val_loss: 381.7079\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 380.8716 - val_loss: 377.4561\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 372.3270 - val_loss: 373.3274\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 363.9294 - val_loss: 369.3203\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 355.6776 - val_loss: 365.4330\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 347.5702 - val_loss: 361.6641\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 339.6052 - val_loss: 358.0117\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 331.7814 - val_loss: 354.4749\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 324.0974 - val_loss: 351.0515\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 316.5515 - val_loss: 347.7401\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 309.1421 - val_loss: 344.5388\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 301.8678 - val_loss: 341.4467\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 294.7272 - val_loss: 338.4619\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 287.7187 - val_loss: 335.5829\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 280.8411 - val_loss: 332.8080\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 274.0928 - val_loss: 330.1358\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 267.4720 - val_loss: 327.5648\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 260.9774 - val_loss: 325.0932\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 254.6076 - val_loss: 322.7197\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 248.3614 - val_loss: 320.4426\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 242.2368 - val_loss: 318.2604\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 236.2328 - val_loss: 316.1718\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 230.3475 - val_loss: 314.1748\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 224.5798 - val_loss: 312.2683\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 218.9282 - val_loss: 310.4506\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 213.3911 - val_loss: 308.7202\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 207.9671 - val_loss: 307.0755\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 202.6550 - val_loss: 305.5150\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 197.4530 - val_loss: 304.0374\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 192.3599 - val_loss: 302.6411\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 187.3743 - val_loss: 301.3244\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 182.4946 - val_loss: 300.0859\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 177.7193 - val_loss: 298.9243\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 173.0472 - val_loss: 297.8379\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 168.4768 - val_loss: 296.8253\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 164.0067 - val_loss: 295.8849\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 159.6354 - val_loss: 295.0155\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 155.3616 - val_loss: 294.2154\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 151.1839 - val_loss: 293.4833\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 147.1010 - val_loss: 292.8176\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 143.1114 - val_loss: 292.2169\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 139.2137 - val_loss: 291.6799\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 135.4066 - val_loss: 291.2050\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 131.6886 - val_loss: 290.7908\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 128.0584 - val_loss: 290.4359\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 124.5147 - val_loss: 290.1389\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 121.0561 - val_loss: 289.8984\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 117.6810 - val_loss: 289.7130\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 114.3886 - val_loss: 289.5813\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 111.1774 - val_loss: 289.5020\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 108.0458 - val_loss: 289.4736\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 104.9925 - val_loss: 289.4948\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 102.0165 - val_loss: 289.5642\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 99.1165 - val_loss: 289.6805\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 96.2909 - val_loss: 289.8424\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 93.5384 - val_loss: 290.0486\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 90.8578 - val_loss: 290.2976\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 88.2481 - val_loss: 290.5883\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 85.7077 - val_loss: 290.9193\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 83.2354 - val_loss: 291.2893\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 80.8299 - val_loss: 291.6971\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 78.4902 - val_loss: 292.1414\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 76.2149 - val_loss: 292.6208\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 74.0027 - val_loss: 293.1344\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 71.8525 - val_loss: 293.6806\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 69.7630 - val_loss: 294.2585\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 67.7332 - val_loss: 294.8667\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 65.7617 - val_loss: 295.5042\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 63.8473 - val_loss: 296.1695\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 61.9890 - val_loss: 296.8618\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 60.1856 - val_loss: 297.5796\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 58.4359 - val_loss: 298.3220\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 56.7387 - val_loss: 299.0879\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 55.0931 - val_loss: 299.8760\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 53.4976 - val_loss: 300.6854\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 51.9515 - val_loss: 301.5149\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 50.4536 - val_loss: 302.3635\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 49.0026 - val_loss: 303.2300\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 47.5977 - val_loss: 304.1136\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 46.2376 - val_loss: 305.0132\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 44.9215 - val_loss: 305.9276\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 43.6482 - val_loss: 306.8562\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 42.4167 - val_loss: 307.7976\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 41.2260 - val_loss: 308.7511\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 40.0753 - val_loss: 309.7157\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 38.9632 - val_loss: 310.6904\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 37.8891 - val_loss: 311.6746\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 36.8518 - val_loss: 312.6671\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 35.8504 - val_loss: 313.6671\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 34.8841 - val_loss: 314.6738\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.9518 - val_loss: 315.6864\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 33.0528 - val_loss: 316.7038\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 32.1861 - val_loss: 317.7256\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.3508 - val_loss: 318.7508\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 30.5460 - val_loss: 319.7786\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 29.7710 - val_loss: 320.8084\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 29.0248 - val_loss: 321.8394\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 28.3067 - val_loss: 322.8708\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 27.6158 - val_loss: 323.9021\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.9513 - val_loss: 324.9324\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.3125 - val_loss: 325.9613\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.6985 - val_loss: 326.9879\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.1087 - val_loss: 328.0119\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.5422 - val_loss: 329.0325\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.9985 - val_loss: 330.0491\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.4766 - val_loss: 331.0612\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.9760 - val_loss: 332.0681\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.4961 - val_loss: 333.0696\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.0360 - val_loss: 334.0648\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.5951 - val_loss: 335.0539\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.1728 - val_loss: 336.0357\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.7685 - val_loss: 337.0101\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.3815 - val_loss: 337.9763\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.0113 - val_loss: 338.9345\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.6574 - val_loss: 339.8839\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.3190 - val_loss: 340.8245\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.9956 - val_loss: 341.7552\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.6868 - val_loss: 342.6766\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.3919 - val_loss: 343.5875\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.1105 - val_loss: 344.4880\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.8421 - val_loss: 345.3780\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.5862 - val_loss: 346.2570\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 17.3422 - val_loss: 347.1245\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.1098 - val_loss: 347.9808\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.8885 - val_loss: 348.8252\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.6778 - val_loss: 349.6579\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4773 - val_loss: 350.4783\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2866 - val_loss: 351.2866\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.1054 - val_loss: 352.0824\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.9331 - val_loss: 352.8658\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.7695 - val_loss: 353.6366\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.6142 - val_loss: 354.3943\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.4668 - val_loss: 355.1391\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.3270 - val_loss: 355.8711\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.1945 - val_loss: 356.5899\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.0689 - val_loss: 357.2958\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.9498 - val_loss: 357.9883\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.8371 - val_loss: 358.6680\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.7305 - val_loss: 359.3341\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.6296 - val_loss: 359.9872\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5342 - val_loss: 360.6270\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.4440 - val_loss: 361.2533\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.3589 - val_loss: 361.8669\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.2784 - val_loss: 362.4674\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.2025 - val_loss: 363.0547\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.1309 - val_loss: 363.6288\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 14.0634 - val_loss: 364.1901\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.9997 - val_loss: 364.7382\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.9398 - val_loss: 365.2736\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.8833 - val_loss: 365.7966\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.8302 - val_loss: 366.3068\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7801 - val_loss: 366.8044\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7331 - val_loss: 367.2895\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6890 - val_loss: 367.7626\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6475 - val_loss: 368.2234\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6085 - val_loss: 368.6723\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.5719 - val_loss: 369.1089\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5376 - val_loss: 369.5344\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5053 - val_loss: 369.9477\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.4752 - val_loss: 370.3500\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.4469 - val_loss: 370.7408\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.4205 - val_loss: 371.1206\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 13.3957 - val_loss: 371.4893\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.3725 - val_loss: 371.8476\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.3508 - val_loss: 372.1952\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.3305 - val_loss: 372.5324\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.3116 - val_loss: 372.8595\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.2939 - val_loss: 373.1765\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 13.2774 - val_loss: 373.4839\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.2619 - val_loss: 373.7810\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.2476 - val_loss: 374.0691\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.2341 - val_loss: 374.3479\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.2217 - val_loss: 374.6174\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.2100 - val_loss: 374.8785\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.1991 - val_loss: 375.1305\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.1890 - val_loss: 375.3736\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 13.1796 - val_loss: 375.6090\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 13.1709 - val_loss: 375.8362\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.1628 - val_loss: 376.0555\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.1552 - val_loss: 376.2671\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.1482 - val_loss: 376.4711\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.1416 - val_loss: 376.6678\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.1356 - val_loss: 376.8569\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1300 - val_loss: 377.0393\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1248 - val_loss: 377.2154\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.1199 - val_loss: 377.3843\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.1154 - val_loss: 377.5471\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.1113 - val_loss: 377.7032\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.1074 - val_loss: 377.8534\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.1039 - val_loss: 377.9980\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.1006 - val_loss: 378.1367\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 13.0975 - val_loss: 378.2698\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.0947 - val_loss: 378.3975\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.0921 - val_loss: 378.5204\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 13.0897 - val_loss: 378.6378\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.0875 - val_loss: 378.7503\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0855 - val_loss: 378.8581\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0836 - val_loss: 378.9611\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0819 - val_loss: 379.0602\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0802 - val_loss: 379.1548\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0788 - val_loss: 379.2450\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0774 - val_loss: 379.3314\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0762 - val_loss: 379.4143\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0751 - val_loss: 379.4931\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0740 - val_loss: 379.5685\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0731 - val_loss: 379.6404\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0722 - val_loss: 379.7090\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0714 - val_loss: 379.7744\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0707 - val_loss: 379.8366\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0700 - val_loss: 379.8957\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0695 - val_loss: 379.9522\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.0689 - val_loss: 380.0063\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0684 - val_loss: 380.0577\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0680 - val_loss: 380.1060\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0676 - val_loss: 380.1523\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0673 - val_loss: 380.1964\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.0670 - val_loss: 380.2377\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0667 - val_loss: 380.2772\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0665 - val_loss: 380.3148\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0663 - val_loss: 380.3506\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0661 - val_loss: 380.3842\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 13.0660 - val_loss: 380.4157\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0659 - val_loss: 380.4462\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0658 - val_loss: 380.4745\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.0658 - val_loss: 380.5014\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.0657 - val_loss: 380.5271\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.0657 - val_loss: 380.5511\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.0657 - val_loss: 380.5740\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.0657 - val_loss: 380.5953\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.0658 - val_loss: 380.6154\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0658 - val_loss: 380.6344\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0659 - val_loss: 380.6524\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0660 - val_loss: 380.6697\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0661 - val_loss: 380.6857\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0662 - val_loss: 380.7003\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0663 - val_loss: 380.7145\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0665 - val_loss: 380.7276\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0666 - val_loss: 380.7400\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0667 - val_loss: 380.7514\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0669 - val_loss: 380.7622\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0671 - val_loss: 380.7724\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0672 - val_loss: 380.7820\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0674 - val_loss: 380.7906\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0676 - val_loss: 380.7990\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.0678 - val_loss: 380.8066\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0680 - val_loss: 380.8138\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0682 - val_loss: 380.8203\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0684 - val_loss: 380.8265\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 13.0686 - val_loss: 380.8323\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0689 - val_loss: 380.8377\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0691 - val_loss: 380.8425\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0693 - val_loss: 380.8474\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0695 - val_loss: 380.8515\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0698 - val_loss: 380.8553\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0701 - val_loss: 380.8593\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0703 - val_loss: 380.8622\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0705 - val_loss: 380.8652\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0707 - val_loss: 380.8681\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0710 - val_loss: 380.8705\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 13.0712 - val_loss: 380.8730\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0715 - val_loss: 380.8749\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0718 - val_loss: 380.8769\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0720 - val_loss: 380.8786\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.0723 - val_loss: 380.8798\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0725 - val_loss: 380.8812\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0728 - val_loss: 380.8825\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0730 - val_loss: 380.8835\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0733 - val_loss: 380.8842\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0736 - val_loss: 380.8849\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0739 - val_loss: 380.8859\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0741 - val_loss: 380.8862\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0744 - val_loss: 380.8868\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0746 - val_loss: 380.8871\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0749 - val_loss: 380.8873\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0752 - val_loss: 380.8875\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 13.0755 - val_loss: 380.8877\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0757 - val_loss: 380.8878\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0760 - val_loss: 380.8878\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0762 - val_loss: 380.8879\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0765 - val_loss: 380.8875\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0767 - val_loss: 380.8872\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0770 - val_loss: 380.8870\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0773 - val_loss: 380.8869\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0775 - val_loss: 380.8866\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0778 - val_loss: 380.8863\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0780 - val_loss: 380.8859\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0783 - val_loss: 380.8855\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0785 - val_loss: 380.8846\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0788 - val_loss: 380.8842\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0791 - val_loss: 380.8838\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0793 - val_loss: 380.8835\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0796 - val_loss: 380.8830\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0799 - val_loss: 380.8827\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0801 - val_loss: 380.8820\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0803 - val_loss: 380.8817\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0806 - val_loss: 380.8810\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0808 - val_loss: 380.8802\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0811 - val_loss: 380.8798\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0813 - val_loss: 380.8795\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0815 - val_loss: 380.8782\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 13.0818 - val_loss: 380.8777\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 13.0821 - val_loss: 380.8771\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0823 - val_loss: 380.8763\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.0825 - val_loss: 380.8756\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0828 - val_loss: 380.8750\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0830 - val_loss: 380.8745\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0833 - val_loss: 380.8737\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0835 - val_loss: 380.8732\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0837 - val_loss: 380.8728\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.0839 - val_loss: 380.8720\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.0841 - val_loss: 380.8709\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0844 - val_loss: 380.8704\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0846 - val_loss: 380.8700\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0848 - val_loss: 380.8691\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0851 - val_loss: 380.8687\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0853 - val_loss: 380.8680\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0855 - val_loss: 380.8671\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0857 - val_loss: 380.8664\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0859 - val_loss: 380.8660\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0861 - val_loss: 380.8652\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0863 - val_loss: 380.8643\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0866 - val_loss: 380.8638\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0868 - val_loss: 380.8634\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0870 - val_loss: 380.8628\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0872 - val_loss: 380.8619\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0874 - val_loss: 380.8614\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0876 - val_loss: 380.8608\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0878 - val_loss: 380.8602\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0880 - val_loss: 380.8596\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.0882 - val_loss: 380.8591\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 13.0884 - val_loss: 380.8587\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0885 - val_loss: 380.8579\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 342ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.98626751e+01, 6.98542717e+01, 6.98458684e+01, 6.98374650e+01,\n",
       "        6.98290616e+01, 6.98206583e+01, 6.98122549e+01, 6.98038515e+01,\n",
       "        6.97696545e+01, 6.97136321e+01, 6.96576097e+01, 6.96015873e+01,\n",
       "        6.95455649e+01, 6.94895425e+01, 6.94335201e+01, 6.93774977e+01,\n",
       "        6.93214753e+01, 6.92654529e+01, 6.92094304e+01, 6.91534080e+01,\n",
       "        6.90973856e+01, 6.90413632e+01, 6.89853408e+01, 6.89293184e+01,\n",
       "        6.88732960e+01, 6.88172736e+01, 6.87612512e+01, 6.87052288e+01,\n",
       "        6.86492064e+01, 6.85931839e+01, 6.85371615e+01, 6.84811391e+01,\n",
       "        6.84251167e+01, 6.83690943e+01, 6.83130719e+01, 6.82570495e+01,\n",
       "        6.82010271e+01, 6.81450047e+01, 6.80889823e+01, 6.80329598e+01,\n",
       "        6.79769374e+01, 6.79209150e+01, 6.78648926e+01, 6.78088702e+01,\n",
       "        6.77747736e+01, 6.77448016e+01, 6.77148296e+01, 7.06862045e+01,\n",
       "        7.06609944e+01, 7.06357843e+01, 7.06115742e+01, 7.05853642e+01,\n",
       "        7.05615410e+01, 7.05349440e+01, 7.05097339e+01, 7.04845238e+01,\n",
       "        7.04593137e+01, 7.04341036e+01, 7.04088936e+01, 7.03836835e+01,\n",
       "        7.03584734e+01, 7.03326333e+01, 7.03080532e+01, 7.02828431e+01,\n",
       "        7.02576330e+01, 7.02324230e+01, 7.02072129e+01, 7.01820028e+01,\n",
       "        7.01567927e+01, 7.01315826e+01, 7.01063726e+01, 7.00811625e+01,\n",
       "        7.00559524e+01, 7.56191101e+01, 0.00000000e+00, 5.23406863e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.59918988e-01, 9.78886190e-02,\n",
       "        6.99502182e+01, 4.44159657e-02, 2.32655033e-01, 3.87018085e-01,\n",
       "        7.15077221e-01, 1.62875891e-01, 1.13371469e-01, 0.00000000e+00,\n",
       "        3.43400270e-01, 6.67963266e-01, 0.00000000e+00, 5.80880418e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.16635063e-02, 1.56377852e-01,\n",
       "        0.00000000e+00, 5.68655014e-01, 9.91702080e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64.79894958, 64.79054622, 64.78214286, 64.7737395 , 64.76533613,\n",
       "       64.75693277, 64.74852941, 64.74012605, 64.73172269, 64.72331933,\n",
       "       64.71491597, 64.70651261, 64.69810924, 64.68970588, 64.68130252,\n",
       "       64.67289916, 64.6644958 , 64.65609244, 64.64768908, 64.63928571,\n",
       "       64.63088235, 64.62247899, 64.61407563, 64.60567227, 64.59726891,\n",
       "       64.58886555, 64.58046218, 64.57205882, 64.56365546, 64.5552521 ,\n",
       "       64.54684874, 64.53844538, 64.53004202, 64.52163866, 64.51323529,\n",
       "       64.50483193, 64.49642857, 64.48802521, 64.47962185, 64.47121849,\n",
       "       64.46281513, 64.45441176, 64.4460084 , 64.43760504, 64.42920168,\n",
       "       64.42079832, 64.41239496, 64.4039916 , 64.39558824, 64.38718487,\n",
       "       64.37878151, 64.37037815, 64.36197479, 64.35357143, 64.34516807,\n",
       "       64.33676471, 64.32836134, 64.31995798, 64.31155462, 64.30315126,\n",
       "       64.2947479 , 64.28634454, 64.27794118, 64.26953782, 64.26113445,\n",
       "       64.25273109, 64.24432773, 64.23592437, 64.22752101, 64.21911765,\n",
       "       64.21071429, 64.20231092, 64.19390756, 64.1855042 , 64.17710084,\n",
       "       64.16869748, 64.16029412, 64.15189076, 64.14348739, 64.13508403,\n",
       "       64.12668067, 64.11827731, 64.10987395, 64.10147059, 64.09306723,\n",
       "       64.08466387, 64.0762605 , 64.06785714, 64.05945378, 64.05105042,\n",
       "       64.04264706, 64.0342437 , 64.02584034, 64.01743697, 64.00903361,\n",
       "       64.00063025, 63.99222689, 63.98382353, 63.97542017, 63.96701681])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.23031111252639\n",
      "19.728339810657413\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
